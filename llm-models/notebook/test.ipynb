{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da61a54-644e-4edb-822e-e06b70d978ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc7b518-f984-4e6a-9ed0-c074d6c031c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "current = os.getcwd()\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742323d8-0c2c-41a3-ac72-06845baa10b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = nn.ModuleList([None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b402469f-2717-4291-a79e-ca5436396bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.deepseek.model import ExpertMLA, ModelArgs, ExpertType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d63a8b3a-dcd5-4743-8ae8-fa3302dcd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.deepseek import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131bd6c4-824b-4308-a0a2-d06d66915b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/projects/llm-models/llm-models/models/deepseek'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(parent, 'models/deepseek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee9c64d7-8a9f-4bc1-a57e-84d72ec4139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(model)\n",
    "torch.set_default_dtype(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3614934-5d24-4c1c-9755-d34e128bc931",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_expert = model.ModelArgs(expert_type=model.ExpertType(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5e0ba2d-6432-4161-90d1-5881a41f8fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_expert = model.ModelArgs(expert_type=model.ExpertType(2),\n",
    "                             dim=512, inter_dim=1365, moe_inter_dim=256,\n",
    "                             kv_lora_rank=128, qk_nope_head_dim=32, qk_rope_head_dim=16, \n",
    "                             v_head_dim=32, \n",
    "                             n_routed_experts=4, n_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e6f97af-0c8c-477c-8cc7-9eb5a87a4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_mla = model.ExpertMLA(args_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0f13068-5707-4471-b2fa-7ae5e0ef22e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1\n",
      "step4\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step4\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step4\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step4\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step2\n",
      "step3\n"
     ]
    }
   ],
   "source": [
    "expert_model = model.Transformer(args_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a507508-8b40-487a-9a5c-384e0ad51a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExpertMLA(\n",
       "  (wq): Linear()\n",
       "  (wkv_a): Linear()\n",
       "  (kv_norm): RMSNorm()\n",
       "  (wkv_b): Linear()\n",
       "  (wo): Linear()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expert_mla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92488ecb-6390-477a-ae39-9ab54aedab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 16\n",
    "test_seq_size = 12\n",
    "test_input = torch.zeros((test_batch_size*test_seq_size, 1, args_expert.dim), dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "778a7c05-537c-435a-be54-8e0af94a6311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 1, 2048])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f3b8a8-7381-4d2a-a6f0-2e05089422db",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cis = model.precompute_freqs_cis(args_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b5be6b5-ff98-49c4-ad37-d10e606e59b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([192, 1, 16, 4])\n",
      "torch.Size([4, 16, 128])\n"
     ]
    }
   ],
   "source": [
    "output = expert_mla(test_input, freq_cis[:1,:], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4945285-5551-4b5a-a145-4b1622521399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41bcb644-8ac5-4c48-9aec-1e9da02cb3f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1\n",
      "step2\n",
      "step3\n"
     ]
    }
   ],
   "source": [
    "block = model.Block(-1, args_expert, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "499a0d0e-b671-4caa-8b83-e7c1adb67552",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = block(test_input, 0, freq_cis[:1,:], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01a14cc7-4c68-448a-8b32-01c3d4c1fbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([192, 1, 2048])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4d2c78b-99f8-471d-8b8a-ed7e0d155b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert = model.Expert(args_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0470024b-5676-42bd-a972-eb379663fcac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output = expert(test_input, 0, freq_cis[:1,:], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb722696-a193-4e60-9734-122466033506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n",
      "step1\n",
      "step2\n",
      "step3\n"
     ]
    }
   ],
   "source": [
    "moe_attention = model.MoE(args_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ad39553-66b6-4758-a0a5-4b9858cffda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3072, 2048])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moe.get_submodule('experts')[0].get_submodule('block').get_submodule('attn').get_submodule('wq').weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ba6d152-a33b-471c-be77-8c39880e2d09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gate.weight\n",
      "torch.Size([64, 2048])\n",
      "experts.0.block.attn.learnable_k_cache\n",
      "torch.Size([4, 16, 192])\n",
      "experts.0.block.attn.learnable_v_cache\n",
      "torch.Size([4, 16, 128])\n",
      "experts.0.block.attn.wq.weight\n",
      "torch.Size([3072, 2048])\n",
      "experts.0.block.attn.wkv_a.weight\n",
      "torch.Size([576, 2048])\n",
      "experts.0.block.attn.kv_norm.weight\n",
      "torch.Size([512])\n",
      "experts.0.block.attn.wkv_b.weight\n",
      "torch.Size([4096, 512])\n",
      "experts.0.block.attn.wo.weight\n",
      "torch.Size([2048, 2048])\n",
      "experts.0.block.attn_norm.weight\n",
      "torch.Size([2048])\n",
      "experts.1.block.attn.learnable_k_cache\n",
      "torch.Size([4, 16, 192])\n",
      "experts.1.block.attn.learnable_v_cache\n",
      "torch.Size([4, 16, 128])\n",
      "experts.1.block.attn.wq.weight\n",
      "torch.Size([3072, 2048])\n",
      "experts.1.block.attn.wkv_a.weight\n",
      "torch.Size([576, 2048])\n",
      "experts.1.block.attn.kv_norm.weight\n",
      "torch.Size([512])\n",
      "experts.1.block.attn.wkv_b.weight\n",
      "torch.Size([4096, 512])\n",
      "experts.1.block.attn.wo.weight\n",
      "torch.Size([2048, 2048])\n",
      "experts.1.block.attn_norm.weight\n",
      "torch.Size([2048])\n",
      "experts.2.block.attn.learnable_k_cache\n",
      "torch.Size([4, 16, 192])\n",
      "experts.2.block.attn.learnable_v_cache\n",
      "torch.Size([4, 16, 128])\n",
      "experts.2.block.attn.wq.weight\n",
      "torch.Size([3072, 2048])\n",
      "experts.2.block.attn.wkv_a.weight\n",
      "torch.Size([576, 2048])\n",
      "experts.2.block.attn.kv_norm.weight\n",
      "torch.Size([512])\n",
      "experts.2.block.attn.wkv_b.weight\n",
      "torch.Size([4096, 512])\n",
      "experts.2.block.attn.wo.weight\n",
      "torch.Size([2048, 2048])\n",
      "experts.2.block.attn_norm.weight\n",
      "torch.Size([2048])\n",
      "experts.3.block.attn.learnable_k_cache\n",
      "torch.Size([4, 16, 192])\n",
      "experts.3.block.attn.learnable_v_cache\n",
      "torch.Size([4, 16, 128])\n",
      "experts.3.block.attn.wq.weight\n",
      "torch.Size([3072, 2048])\n",
      "experts.3.block.attn.wkv_a.weight\n",
      "torch.Size([576, 2048])\n",
      "experts.3.block.attn.kv_norm.weight\n",
      "torch.Size([512])\n",
      "experts.3.block.attn.wkv_b.weight\n",
      "torch.Size([4096, 512])\n",
      "experts.3.block.attn.wo.weight\n",
      "torch.Size([2048, 2048])\n",
      "experts.3.block.attn_norm.weight\n",
      "torch.Size([2048])\n",
      "shared_experts.w1.weight\n",
      "torch.Size([2816, 2048])\n",
      "shared_experts.w2.weight\n",
      "torch.Size([2048, 2816])\n",
      "shared_experts.w3.weight\n",
      "torch.Size([2816, 2048])\n"
     ]
    }
   ],
   "source": [
    "for k, v in moe_attention.named_parameters():\n",
    "    print(k)\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c687fbe3-077e-45cb-b0c0-aad45ab816ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args_regular = model.ModelArgs(expert_type=model.ExpertType(1),\n",
    "                             dim=512, inter_dim=1365, moe_inter_dim=256,\n",
    "                             kv_lora_rank=128, qk_nope_head_dim=32, qk_rope_head_dim=16, \n",
    "                             v_head_dim=32)\n",
    "moe_regular = model.MoE(args_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f4ad70-facb-4a95-bdec-dd8edad66e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoE(\n",
       "  (gate): Gate()\n",
       "  (experts): ModuleList(\n",
       "    (0-63): 64 x Expert(\n",
       "      (block): Block(\n",
       "        (attn): ExpertMLA(\n",
       "          (wq): Linear()\n",
       "          (wkv_a): Linear()\n",
       "          (kv_norm): RMSNorm()\n",
       "          (wkv_b): Linear()\n",
       "          (wo): Linear()\n",
       "        )\n",
       "        (attn_norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (shared_experts): MLP(\n",
       "    (w1): ColumnParallelLinear()\n",
       "    (w2): RowParallelLinear()\n",
       "    (w3): ColumnParallelLinear()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moe_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9537fc-717d-4bb8-8364-d58ea846312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_model_memory(model: nn.Module) -> tuple[int, str]:\n",
    "    \"\"\"\n",
    "    Computes the total memory size of a torch.nn.Module (parameters and buffers).\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch nn.Module instance.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing (total_bytes, formatted_size_string).\n",
    "    \"\"\"\n",
    "    # 1. Calculate memory for parameters (weights, biases)\n",
    "    param_bytes = sum(p.nelement() * p.element_size() for k, p in model.named_parameters())\n",
    "\n",
    "    # 2. Calculate memory for buffers (running_mean, running_var, etc.)\n",
    "    buffer_bytes = sum(b.nelement() * b.element_size() for b in model.buffers())\n",
    "\n",
    "    total_bytes = param_bytes + buffer_bytes\n",
    "\n",
    "    # Format for readability\n",
    "    if total_bytes > (1024**3):\n",
    "        formatted_size = f\"{total_bytes / (1024**3):.2f} GB\"\n",
    "    elif total_bytes > (1024**2):\n",
    "        formatted_size = f\"{total_bytes / (1024**2):.2f} MB\"\n",
    "    elif total_bytes > 1024:\n",
    "        formatted_size = f\"{total_bytes / 1024:.2f} KB\"\n",
    "    else:\n",
    "        formatted_size = f\"{total_bytes} bytes\"\n",
    "\n",
    "    return total_bytes, formatted_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81621a2f-05d2-48d8-b5f0-518039443063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270008320, '257.50 MB')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_model_memory(moe_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc0ac7a9-2e71-4b09-86fa-05c12e01a61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1666917376, '1.55 GB')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_model_memory(expert_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94d51543-806e-45f8-9404-5a76e65de8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.465185279999998"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "572784640/1e9*27\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d213f9-1a77-4168-bc7a-64f8821b589a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
