{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19fae763-2a14-430b-a20a-64bcd574b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def foo1(x1, x2):\n",
    "    a = torch.neg(x1)\n",
    "    b = torch.maximum(x2, a)\n",
    "    y = torch.cat([b], dim=0)\n",
    "    return y\n",
    "\n",
    "x1 = torch.randint(256, (1, 8), dtype=torch.uint8)\n",
    "x2 = torch.randint(256, (8390, 8), dtype=torch.uint8)\n",
    "\n",
    "compiled_foo1 = torch.compile(foo1)\n",
    "result = compiled_foo1(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6de91d1-5822-4780-abf3-8433af58d687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1221 00:58:21.539000 1856 torch/_inductor/config.py:869] compile_threads set to 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Enable TorchInductor debug logging\n",
    "os.environ[\"TORCH_COMPILE_DEBUG\"] = \"1\"\n",
    "os.environ[\"TORCHINDUCTOR_DEBUG\"] = \"1\"\n",
    "os.environ[\"TORCH_LOGS\"] = \"inductor,graph_breaks\"\n",
    "\n",
    "# Import torch after setting env\n",
    "import torch\n",
    "\n",
    "# Optional: make sure TorchInductor debug is on\n",
    "torch._inductor.config.debug = True\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79d8dec-7e6c-434a-88b0-602567f8f068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1221 00:58:26.065000 1856 torch/_inductor/codecache.py:1586] [0/0] fx graph cache miss for key fdgyh7sb34wvavgig3vojpykntjr4m4vlmj4tf5za6kunwx2ghfr\n",
      "I1221 00:58:26.067000 1856 torch/_inductor/compile_fx.py:1203] [0/0] Step 3: torchinductor compiling FORWARDS graph 0\n",
      "I1221 00:58:26.147000 1856 torch/_inductor/memory.py:880] [0/0] Reordering for peak memory -- 1 nodes\n",
      "I1221 00:58:26.150000 1856 torch/_inductor/memory.py:904] [0/0] Baseline peak memory: 0\n",
      "I1221 00:58:26.151000 1856 torch/_inductor/memory.py:922] [0/0] topological_sort_lpmf peak memory: 0\n",
      "I1221 00:58:26.154000 1856 torch/_inductor/memory.py:922] [0/0] topological_sort_bfs peak memory: 0\n",
      "I1221 00:58:26.156000 1856 torch/_inductor/memory.py:922] [0/0] topological_sort_dfs peak memory: 0\n",
      "DEBUG:filelock:Attempting to acquire lock 126300909403840 on /tmp/torchinductor_ubuntu/locks/ciny7qzbfkbikvf547rmf3ebwsf4sv2urkimwfyuh7jd6wylwhqs.lock\n",
      "DEBUG:filelock:Lock 126300909403840 acquired on /tmp/torchinductor_ubuntu/locks/ciny7qzbfkbikvf547rmf3ebwsf4sv2urkimwfyuh7jd6wylwhqs.lock\n",
      "DEBUG:filelock:Attempting to release lock 126300909403840 on /tmp/torchinductor_ubuntu/locks/ciny7qzbfkbikvf547rmf3ebwsf4sv2urkimwfyuh7jd6wylwhqs.lock\n",
      "DEBUG:filelock:Lock 126300909403840 released on /tmp/torchinductor_ubuntu/locks/ciny7qzbfkbikvf547rmf3ebwsf4sv2urkimwfyuh7jd6wylwhqs.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 126300903673344 on /tmp/torchinductor_ubuntu/precompiled_headers/locks/cntrnr4jctzdcy6os4tppls4yazwwpk4dl7qtyittjo5ta4qpeyc.lock\n",
      "DEBUG:filelock:Lock 126300903673344 acquired on /tmp/torchinductor_ubuntu/precompiled_headers/locks/cntrnr4jctzdcy6os4tppls4yazwwpk4dl7qtyittjo5ta4qpeyc.lock\n",
      "DEBUG:filelock:Attempting to release lock 126300903673344 on /tmp/torchinductor_ubuntu/precompiled_headers/locks/cntrnr4jctzdcy6os4tppls4yazwwpk4dl7qtyittjo5ta4qpeyc.lock\n",
      "DEBUG:filelock:Lock 126300903673344 released on /tmp/torchinductor_ubuntu/precompiled_headers/locks/cntrnr4jctzdcy6os4tppls4yazwwpk4dl7qtyittjo5ta4qpeyc.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 126300905586416 on /tmp/torchinductor_ubuntu/locks/clzhgkdmojquo2j4fxbtzaxxwtc763i7qs67hzctztug3ydebw4a.lock\n",
      "DEBUG:filelock:Lock 126300905586416 acquired on /tmp/torchinductor_ubuntu/locks/clzhgkdmojquo2j4fxbtzaxxwtc763i7qs67hzctztug3ydebw4a.lock\n",
      "DEBUG:filelock:Attempting to release lock 126300905586416 on /tmp/torchinductor_ubuntu/locks/clzhgkdmojquo2j4fxbtzaxxwtc763i7qs67hzctztug3ydebw4a.lock\n",
      "DEBUG:filelock:Lock 126300905586416 released on /tmp/torchinductor_ubuntu/locks/clzhgkdmojquo2j4fxbtzaxxwtc763i7qs67hzctztug3ydebw4a.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 126300903675792 on /tmp/torchinductor_ubuntu/locks/clzhgkdmojquo2j4fxbtzaxxwtc763i7qs67hzctztug3ydebw4a.lock\n",
      "DEBUG:filelock:Lock 126300903675792 acquired on /tmp/torchinductor_ubuntu/locks/clzhgkdmojquo2j4fxbtzaxxwtc763i7qs67hzctztug3ydebw4a.lock\n",
      "DEBUG:filelock:Attempting to release lock 126300903675792 on /tmp/torchinductor_ubuntu/locks/clzhgkdmojquo2j4fxbtzaxxwtc763i7qs67hzctztug3ydebw4a.lock\n",
      "DEBUG:filelock:Lock 126300903675792 released on /tmp/torchinductor_ubuntu/locks/clzhgkdmojquo2j4fxbtzaxxwtc763i7qs67hzctztug3ydebw4a.lock\n",
      "DEBUG:filelock:Attempting to acquire lock 126300909574128 on /tmp/torchinductor_ubuntu/zv/czvxk4xxbfv2eyjzaremumspy5gbgg3jkzcqsb5id2towf6r3uze.debug.lock\n",
      "DEBUG:filelock:Lock 126300909574128 acquired on /tmp/torchinductor_ubuntu/zv/czvxk4xxbfv2eyjzaremumspy5gbgg3jkzcqsb5id2towf6r3uze.debug.lock\n",
      "DEBUG:filelock:Attempting to release lock 126300909574128 on /tmp/torchinductor_ubuntu/zv/czvxk4xxbfv2eyjzaremumspy5gbgg3jkzcqsb5id2towf6r3uze.debug.lock\n",
      "DEBUG:filelock:Lock 126300909574128 released on /tmp/torchinductor_ubuntu/zv/czvxk4xxbfv2eyjzaremumspy5gbgg3jkzcqsb5id2towf6r3uze.debug.lock\n",
      "I1221 00:58:28.144000 1856 torch/_inductor/compile_fx.py:1094] [0/0] Overview info of inductor aten mms: \n",
      "I1221 00:58:28.145000 1856 torch/_inductor/compile_fx.py:1095] [0/0] Name                           | B                    | M                    | N                    | K                    | Count               \n",
      "I1221 00:58:28.146000 1856 torch/_inductor/compile_fx.py:1100] [0/0] ----------------------------------------------------------------------------------------------------------------------------------\n",
      "I1221 00:58:28.147000 1856 torch/_inductor/compile_fx.py:1109] [0/0] Step 3: torchinductor done compiling FORWARDS graph 0\n",
      "W1221 00:58:28.148000 1856 torch/_inductor/debug.py:507] [0/0] model__0_inference_0 debug trace: /home/ubuntu/projects/llm-models/llm-models/notebook/torch_compile_debug/run_2025_12_21_00_58_25_135480-pid_1856/torchinductor/model__0_inference_0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def foo1(x1, x2):\n",
    "    a = torch.neg(x1)\n",
    "    b = torch.maximum(x2, a)\n",
    "    y = torch.cat([b], dim=0)\n",
    "    return y\n",
    "\n",
    "x1 = torch.randint(256, (1, 8), dtype=torch.uint8)\n",
    "x2 = torch.randint(256, (8390, 8), dtype=torch.uint8)\n",
    "\n",
    "compiled_foo1 = torch.compile(foo1, backend=\"inductor\")\n",
    "result = compiled_foo1(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1651d3b6-c671-4123-982e-3de7d693332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_foo1 = torch.compile(foo1)\n",
    "result = compiled_foo1(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6653f6-67a0-48c0-a2cc-9328670d24de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
