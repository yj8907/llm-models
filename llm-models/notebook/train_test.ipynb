{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a5e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "import os\n",
    "from typing import Iterator\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_from_disk, Dataset as HFDataset # Rename to avoid clash\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4e43e1-c8ae-4d73-92f5-d6ee5d32d167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "import deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e05893-495d-48aa-bd37-d9e2bbc59ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 0.0 MB\n",
      "Reserved: 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Allocated:\", torch.cuda.memory_allocated() / 1024**2, \"MB\")\n",
    "print(\"Reserved:\", torch.cuda.memory_reserved() / 1024**2, \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd25c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, importlib\n",
    "current = os.getcwd()\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb02f6ba-d643-4a07-a6c6-9e4b35af9562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/projects/llm-models/llm-models'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58dc61ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.deepseek.data' from '/home/ubuntu/projects/llm-models/llm-models/models/deepseek/data.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.deepseek import model\n",
    "importlib.reload(model)\n",
    "\n",
    "from models.deepseek import train\n",
    "importlib.reload(train)\n",
    "\n",
    "from models.deepseek import data\n",
    "importlib.reload(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78f56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(data)\n",
    "\n",
    "from torch.utils.data import IterableDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2fc0706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/projects/llm-models/llm-models/notebook'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad85232d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'models.deepseek.data' has no attribute 'TinyStoriesDataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tinydataset = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTinyStoriesDataset\u001b[49m(data_dir=\u001b[33m'\u001b[39m\u001b[33m../../data\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'models.deepseek.data' has no attribute 'TinyStoriesDataset'"
     ]
    }
   ],
   "source": [
    "tinydataset = data.TinyStoriesDataset(data_dir='../../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f4e3558",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tinydataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dataloader = train.DataLoader(\u001b[43mtinydataset\u001b[49m, batch_size=\u001b[32m2\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'tinydataset' is not defined"
     ]
    }
   ],
   "source": [
    "dataloader = train.DataLoader(tinydataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf85d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = model.ModelArgs(expert_type=model.ExpertType(2),\n",
    "                             dim=512, inter_dim=1365, moe_inter_dim=256,\n",
    "                             kv_lora_rank=128, qk_nope_head_dim=32, qk_rope_head_dim=16, \n",
    "                             v_head_dim=32, \n",
    "                             n_routed_experts=16, n_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cc67c82-99c9-49e1-9489-4c7dada2c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = model.ModelArgs(expert_type=model.ExpertType(2),\n",
    "                             dim=128, inter_dim=341, moe_inter_dim=64,\n",
    "                             kv_lora_rank=32, qk_nope_head_dim=8, qk_rope_head_dim=4, \n",
    "                             v_head_dim=8, \n",
    "                             n_routed_experts=16, n_layers=4,\n",
    "                                original_seq_len=data.CONTEXT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0679f0bd-282e-4f77-a5ae-a11ab1d9ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = model.ModelArgs(expert_type=model.ExpertType(1),\n",
    "                             dim=128, inter_dim=341, moe_inter_dim=64,\n",
    "                             kv_lora_rank=32, qk_nope_head_dim=8, qk_rope_head_dim=4, \n",
    "                             v_head_dim=8, n_dense_layers=100,\n",
    "                             n_routed_experts=16, n_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f454f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = train.TrainingArgs(\n",
    "    model_args=model_args,\n",
    "    batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    max_steps=100000,\n",
    "    learning_rate=3e-4,\n",
    "    checkpoint_dir=\"./checkpoints\",\n",
    "    data_dir=\"./data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3d3069f-2873-423c-b731-3fc68a2b6485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "trying to initialize the default process group twice!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mMASTER_ADDR\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33mlocalhost\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      4\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mMASTER_PORT\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33m12356\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnccl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:81\u001b[39m, in \u001b[36m_exception_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     83\u001b[39m         msg_dict = _get_msg_dict(func.\u001b[34m__name__\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:95\u001b[39m, in \u001b[36m_time_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _WaitCounter(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpytorch.wait_counter.c10d.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m).guard():\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         func_return = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func_return\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1646\u001b[39m, in \u001b[36minit_process_group\u001b[39m\u001b[34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options, device_id)\u001b[39m\n\u001b[32m   1643\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _default_pg_init_method\n\u001b[32m   1645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m GroupMember.WORLD \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mtrying to initialize the default process group twice!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1648\u001b[39m set_pytorch_distributed_envs_from_justknobs()\n\u001b[32m   1650\u001b[39m \u001b[38;5;66;03m# Depending on the import order, some trace_rules functions may be evaluated\u001b[39;00m\n\u001b[32m   1651\u001b[39m \u001b[38;5;66;03m# during the import phase. In such a case, these functions may not correctly\u001b[39;00m\n\u001b[32m   1652\u001b[39m \u001b[38;5;66;03m# add the distributed related rules due to import circular dependency.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1656\u001b[39m \u001b[38;5;66;03m# Since this API must be called before all distributed code being compiled,\u001b[39;00m\n\u001b[32m   1657\u001b[39m \u001b[38;5;66;03m# clearing the cache here should be safe.\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: trying to initialize the default process group twice!"
     ]
    }
   ],
   "source": [
    "import torch.distributed as dist\n",
    "\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12356'\n",
    "dist.init_process_group(backend='nccl', rank=0, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "77dae5e1-0c53-4cfb-9ff5-c4d5e657a97d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 29,794,944\n",
      "Trainable parameters: 29,794,944\n",
      "Loading *tokenized* TinyStories dataset split from: './processed_tinystories/train'...\n",
      "Tokenized dataset loaded. Total chunks: 459757\n",
      "Loading *tokenized* TinyStories dataset split from: './processed_tinystories/validation'...\n",
      "Tokenized dataset loaded. Total chunks: 4619\n"
     ]
    }
   ],
   "source": [
    "trainer = train.Trainer(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c18ad07d-8d80-4e48-9d71-f96f989b6ad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:229\u001b[39m, in \u001b[36mTrainer.train_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "trainer.train_step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45576d5f-a508-4f1c-8a09-9ca7ab0156ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, batch in enumerate(trainer.train_loader):\n",
    "    break\n",
    "    \n",
    "x, y = batch\n",
    "x = x.to(trainer.device, non_blocking=True)\n",
    "y = y.to(trainer.device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a3fc63-b2c7-47c5-b37a-b36fd694d839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "102d8954-cf78-4e89-a63d-03e6a06ac0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch._dynamo as dynamo\n",
    "explanation = dynamo.explain(trainer.model)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb6d1958-5649-420d-97d3-0964f0d27325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Graph Break Report ===\n",
      "Total Graphs: 0\n",
      "Total Breaks: -1\n"
     ]
    }
   ],
   "source": [
    "# 3. Manually print the findings\n",
    "print(\"\\n=== Graph Break Report ===\")\n",
    "print(f\"Total Graphs: {explanation.graph_count}\")\n",
    "print(f\"Total Breaks: {explanation.graph_break_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c04f3-c52c-4ba3-a762-2676f4eab392",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5042b90f-8011-43d4-9db8-4e8a1a5d9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the specific reasons for the breaks\n",
    "for reason in explanation.break_reasons:\n",
    "    print(f\"Reason: {reason.reason}\")\n",
    "    print(f\"Source: {reason.user_stack[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "140060d5-73e0-46b8-919b-f095e24f1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.randint(0, 3000, x.shape)\n",
    "yy = torch.randint(0, 3000, y.shape)\n",
    "\n",
    "xx = xx.to(trainer.device, non_blocking=True)\n",
    "yy = yy.to(trainer.device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbb92cc8-80c9-4b9e-8052-e3abdbede3fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'compile_debug' from 'torch._inductor.debug' (/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/_inductor/debug.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdebug\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_debug\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Wrap your model/function with compile_debug\u001b[39;00m\n\u001b[32m      4\u001b[39m compile_debug(trainer.model)(xx)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'compile_debug' from 'torch._inductor.debug' (/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/_inductor/debug.py)"
     ]
    }
   ],
   "source": [
    "from torch._inductor.debug import compile_debug\n",
    "\n",
    "# Wrap your model/function with compile_debug\n",
    "compile_debug(trainer.model)(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd0372c3-3b45-493d-af47-607f2e00e8d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m y = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/model.py:995\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, tokens, start_pos)\u001b[39m\n\u001b[32m    993\u001b[39m freqs_cis = \u001b[38;5;28mself\u001b[39m.freqs_cis[start_pos:start_pos+seqlen] \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m--> \u001b[39m\u001b[32m995\u001b[39m     h = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    997\u001b[39m \u001b[38;5;66;03m# this is not inference mode. \u001b[39;00m\n\u001b[32m    998\u001b[39m h = \u001b[38;5;28mself\u001b[39m.norm(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/model.py:938\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x, start_pos, freqs_cis, mask)\u001b[39m\n\u001b[32m    925\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor, start_pos: \u001b[38;5;28mint\u001b[39m, freqs_cis: torch.Tensor, mask: Optional[torch.Tensor]) -> torch.Tensor:\n\u001b[32m    926\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    927\u001b[39m \u001b[33;03m    Forward pass for the Transformer block.\u001b[39;00m\n\u001b[32m    928\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    936\u001b[39m \u001b[33;03m        torch.Tensor: Output tensor after block computation.\u001b[39;00m\n\u001b[32m    937\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m     x = x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    939\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.learnable_attention:\n\u001b[32m    940\u001b[39m         x = x + \u001b[38;5;28mself\u001b[39m.ffn(\u001b[38;5;28mself\u001b[39m.ffn_norm(x))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/model.py:544\u001b[39m, in \u001b[36mMLA.forward\u001b[39m\u001b[34m(self, x, start_pos, freqs_cis, mask)\u001b[39m\n\u001b[32m    541\u001b[39m     scores = (torch.einsum(\u001b[33m\"\u001b[39m\u001b[33mbshc,btc->bsht\u001b[39m\u001b[33m\"\u001b[39m, q_nope, \u001b[38;5;28mself\u001b[39m.kv_norm(kv_lora)) + \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    542\u001b[39m               torch.einsum(\u001b[33m\"\u001b[39m\u001b[33mbshr,btr->bsht\u001b[39m\u001b[33m\"\u001b[39m, q_pe, k_pe.squeeze(\u001b[32m2\u001b[39m))) * \u001b[38;5;28mself\u001b[39m.softmax_scale \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m     \u001b[43mscores\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m.\u001b[49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    545\u001b[39m scores = scores.softmax(dim=-\u001b[32m1\u001b[39m, dtype=torch.float32).type_as(x)\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m attn_impl == \u001b[33m\"\u001b[39m\u001b[33mnaive\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "y = trainer.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5fdb834-ebef-4be8-9911-85d933758179",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = trainer.model(x, start_pos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4c83491-70a3-406d-87aa-7306690775ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b386b9e1-ea10-49a2-a70d-34b11823a5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 102400])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.view(-1, logits.size(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b857a17f-215f-443c-bb0a-bcef405181fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): ParallelEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x Block(\n",
       "      (attn): MLA(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MLP(\n",
       "        (w1): ColumnParallelLinear()\n",
       "        (w2): RowParallelLinear()\n",
       "        (w3): ColumnParallelLinear()\n",
       "      )\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (attn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (head): ColumnParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d14d54ce-e0e5-4a00-8d62-da9dc7451d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/llm-models/llm-models/models/deepseek/train.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.args.use_amp, dtype=torch.bfloat16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 | Loss: 11.5201 | LR: 1.35e-06 | Tokens/sec: 438974\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:291\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    288\u001b[39m     param_group[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] = lr\n\u001b[32m    290\u001b[39m \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m running_loss += loss\n\u001b[32m    294\u001b[39m \u001b[38;5;66;03m# Update weights after accumulation steps\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:221\u001b[39m, in \u001b[36mTrainer.train_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Forward pass with mixed precision\u001b[39;00m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.amp.autocast(enabled=\u001b[38;5;28mself\u001b[39m.args.use_amp, dtype=torch.bfloat16):\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# For training, we need to modify the model to return loss\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m     loss = F.cross_entropy(\n\u001b[32m    223\u001b[39m         logits.view(-\u001b[32m1\u001b[39m, logits.size(-\u001b[32m1\u001b[39m)),\n\u001b[32m    224\u001b[39m         y.view(-\u001b[32m1\u001b[39m),\n\u001b[32m    225\u001b[39m         ignore_index=-\u001b[32m1\u001b[39m\n\u001b[32m    226\u001b[39m     )\n\u001b[32m    227\u001b[39m     loss = loss / \u001b[38;5;28mself\u001b[39m.args.gradient_accumulation_steps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/model.py:1006\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, tokens, start_pos)\u001b[39m\n\u001b[32m   1004\u001b[39m     mask = torch.full((seqlen, seqlen), \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-inf\u001b[39m\u001b[33m\"\u001b[39m), device=tokens.device).triu_(\u001b[32m1\u001b[39m)\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m-> \u001b[39m\u001b[32m1006\u001b[39m     h = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqs_cis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[38;5;66;03m# this is not inference mode. \u001b[39;00m\n\u001b[32m   1009\u001b[39m h = \u001b[38;5;28mself\u001b[39m.norm(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/model.py:949\u001b[39m, in \u001b[36mBlock.forward\u001b[39m\u001b[34m(self, x, start_pos, freqs_cis, mask)\u001b[39m\n\u001b[32m    947\u001b[39m x = x + \u001b[38;5;28mself\u001b[39m.attn(\u001b[38;5;28mself\u001b[39m.attn_norm(x), start_pos, freqs_cis, mask)\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.learnable_attention:\n\u001b[32m--> \u001b[39m\u001b[32m949\u001b[39m     x = x + \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mffn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/model.py:884\u001b[39m, in \u001b[36mMoE.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    882\u001b[39m weights, indices = \u001b[38;5;28mself\u001b[39m.gate(x)\n\u001b[32m    883\u001b[39m y = torch.zeros_like(x)\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m counts = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbincount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminlength\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_routed_experts\u001b[49m\u001b[43m)\u001b[49m.tolist()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.experts_start_idx, \u001b[38;5;28mself\u001b[39m.experts_end_idx):\n\u001b[32m    886\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m counts[i] == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83bdd795-c503-495f-9623-9012d9606323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.args.gradient_accumulation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76eace4e-6494-41af-bc66-8a58e96853a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "156835c8-c282-46f3-b887-5687619aaf61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddcc05c7-80dd-4be4-8c90-5d0ab7aaa265",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.args.max_steps=100\n",
    "import time\n",
    "time.time()\n",
    "from torch.profiler import profile, ProfilerActivity, record_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27031b05-cf6f-47aa-9fa8-74e029ff03c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train(backend='inductor', run_profile=False):\n",
    "    \n",
    "    print('compiling')\n",
    "    trainer.model.compile(backend=backend, dynamic=True)\n",
    "    print('compiled')\n",
    "    running_loss = 0.0\n",
    "    start_time = time.time()\n",
    "\n",
    "    if run_profile:\n",
    "        print('prof start')\n",
    "        trainer.prof.start()\n",
    "\n",
    "    print('prof started')\n",
    "    for step, batch in enumerate(trainer.train_loader):\n",
    "        print(step)\n",
    "        trainer.prof.step()\n",
    "        if step + 1 > 24:\n",
    "            break\n",
    "        # Update learning rate\n",
    "        lr = trainer.get_lr(trainer.global_step)\n",
    "        for param_group in trainer.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        # Training step\n",
    "        loss = trainer.train_step(batch)\n",
    "        running_loss += loss\n",
    "        \n",
    "        # Update weights after accumulation steps\n",
    "        if (step + 1) % trainer.args.gradient_accumulation_steps == 0:\n",
    "            # Gradient clipping\n",
    "            \n",
    "            trainer.scaler.unscale_(trainer.optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                trainer.model.parameters(),\n",
    "                trainer.args.grad_clip\n",
    "            )\n",
    "            \n",
    "            # Optimizer step\n",
    "            with record_function(\"## optimizer ##\"):\n",
    "                trainer.scaler.step(trainer.optimizer)\n",
    "                trainer.scaler.update()\n",
    "                trainer.optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            trainer.global_step += 1\n",
    "            trainer.tokens_seen += (\n",
    "                trainer.args.batch_size * \n",
    "                trainer.args.gradient_accumulation_steps * \n",
    "                trainer.args.model_args.max_seq_len * \n",
    "                trainer.world_size\n",
    "            )\n",
    "            \n",
    "            # Logging\n",
    "            if trainer.global_step % trainer.args.log_interval == 0 and trainer.is_main_process:\n",
    "                avg_loss = running_loss / trainer.args.log_interval\n",
    "                elapsed = time.time() - start_time\n",
    "                tokens_per_sec = trainer.tokens_seen / elapsed\n",
    "                \n",
    "                print(f\"Step {trainer.global_step} | \"\n",
    "                      f\"Loss: {avg_loss:.4f} | \"\n",
    "                      f\"LR: {lr:.2e} | \"\n",
    "                      f\"Tokens/sec: {tokens_per_sec:.0f}\")\n",
    "                \n",
    "                running_loss = 0.0\n",
    "\n",
    "            if trainer.global_step +1 == 80:\n",
    "                return\n",
    "\n",
    "            # Evaluation\n",
    "            if trainer.global_step % trainer.args.eval_interval == 0:\n",
    "                val_loss = trainer.evaluate()\n",
    "                if trainer.is_main_process:\n",
    "                    print(f\"Validation loss: {val_loss:.4f}\")\n",
    "                    \n",
    "                    if val_loss < trainer.best_val_loss:\n",
    "                        trainer.best_val_loss = val_loss\n",
    "                        trainer.save_checkpoint('best')\n",
    "            \n",
    "            # Checkpointing\n",
    "            if trainer.global_step % trainer.args.save_interval == 0 and trainer.is_main_process:\n",
    "                trainer.save_checkpoint(f'step_{trainer.global_step}')\n",
    "            \n",
    "            # Check if training is complete\n",
    "            if trainer.global_step >= trainer.args.max_steps:\n",
    "                if trainer.is_main_process:\n",
    "                    print(\"Training complete!\")\n",
    "                    trainer.save_checkpoint('final')\n",
    "                return\n",
    "\n",
    "    # trainer.prof.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3e78285-a68e-4eed-a47f-61c2919d7cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_OF_MEM_EVENTS_PER_SNAPSHOT: int = 100000\n",
    "\n",
    "# Start recording memory snapshot history, initialized with a buffer\n",
    "# capacity of 100,000 memory events, via the `max_entries` field.\n",
    "torch.cuda.memory._record_memory_history(\n",
    "   max_entries=MAX_NUM_OF_MEM_EVENTS_PER_SNAPSHOT\n",
    ")\n",
    "\n",
    "test_train('inductor')\n",
    "\n",
    "file_prefix = 'test'\n",
    "try:\n",
    "   torch.cuda.memory._dump_snapshot(f\"{file_prefix}.pickle\")\n",
    "except Exception as e:\n",
    "   logger.error(f\"Failed to capture memory snapshot {e}\")\n",
    "\n",
    "# Stop recording memory snapshot history.\n",
    "torch.cuda.memory._record_memory_history(enabled=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9231660-4e9f-4a50-a430-3698139e9f46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling\n",
      "compiled\n",
      "prof start\n",
      "prof started\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0] failed while attempting to run meta for aten.add_.Tensor\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0] Traceback (most recent call last):\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]   File \"/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py\", line 2755, in _dispatch_impl\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]     r = func(*args, **kwargs)\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]         ^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]   File \"/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/_ops.py\", line 841, in __call__\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]     return self._op(*args, **kwargs)\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]   File \"/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/_meta_registrations.py\", line 4193, in meta_binop_inplace_alpha\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]     check_inplace_broadcast(self.shape, other.shape)\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]   File \"/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/_meta_registrations.py\", line 97, in check_inplace_broadcast\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]     broadcasted_shape = tuple(_broadcast_shapes(self_shape, *args_shape))\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]   File \"/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/_refs/__init__.py\", line 436, in _broadcast_shapes\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]     torch._check(\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]   File \"/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/__init__.py\", line 1695, in _check\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]     _check_with(RuntimeError, cond, message)\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]   File \"/home/ubuntu/projects/llm-dev/lib/python3.12/site-packages/torch/__init__.py\", line 1677, in _check_with\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0]     raise error_type(message_evaluated)\n",
      "[rank0]:E1228 19:41:52.856000 3149 torch/_subclasses/fake_tensor.py:2759] [0/0] RuntimeError: Attempting to broadcast a dimension of length 4096 at -1! Mismatching argument at index 1 had torch.Size([4096, 1, 4096]); but expected shape should be broadcastable to [4, 1024, 16, 1024]\n"
     ]
    },
    {
     "ename": "TorchRuntimeError",
     "evalue": "Dynamo failed to run FX node with fake tensors: call_function <built-in function iadd>(*(FakeTensor(..., device='cuda:0', size=(4, 1024, 16, 1024),\n           grad_fn=<MulBackward0>), FakeTensor(..., size=(4096, 1, 4096))), **{}): got RuntimeError('Attempting to broadcast a dimension of length 4096 at -1! Mismatching argument at index 1 had torch.Size([4096, 1, 4096]); but expected shape should be broadcastable to [4, 1024, 16, 1024]')\n\nfrom user code:\n   File \"/home/ubuntu/projects/llm-models/llm-models/models/deepseek/model.py\", line 995, in forward\n    h = layer(h, start_pos, freqs_cis, self.mask)\n  File \"/home/ubuntu/projects/llm-models/llm-models/models/deepseek/model.py\", line 938, in forward\n    x = x + self.attn(self.attn_norm(x), start_pos, freqs_cis, mask)\n  File \"/home/ubuntu/projects/llm-models/llm-models/models/deepseek/model.py\", line 544, in forward\n    scores += mask.unsqueeze(1)\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTorchRuntimeError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_train\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minductor\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_profile\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mtest_train\u001b[39m\u001b[34m(backend, run_profile)\u001b[39m\n\u001b[32m     22\u001b[39m     param_group[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] = lr\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m loss = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m running_loss += loss\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Update weights after accumulation steps\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:252\u001b[39m, in \u001b[36mTrainer.train_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.amp.autocast(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m,enabled=\u001b[38;5;28mself\u001b[39m.args.use_amp, dtype=torch.bfloat16):\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# For training, we need to modify the model to return loss\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m record_function(\u001b[33m\"\u001b[39m\u001b[33m## forward ##\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m         logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    253\u001b[39m         loss = F.cross_entropy(\n\u001b[32m    254\u001b[39m             logits.view(-\u001b[32m1\u001b[39m, logits.size(-\u001b[32m1\u001b[39m)),\n\u001b[32m    255\u001b[39m             y.view(-\u001b[32m1\u001b[39m),\n\u001b[32m    256\u001b[39m             ignore_index=-\u001b[32m1\u001b[39m\n\u001b[32m    257\u001b[39m         )\n\u001b[32m    258\u001b[39m         loss = loss / \u001b[38;5;28mself\u001b[39m.args.gradient_accumulation_steps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m   1772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compiled_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1775\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:832\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    829\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1874\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1868\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1869\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1870\u001b[39m             )\n\u001b[32m   1872\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1873\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1874\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1876\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1877\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1624\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1622\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1623\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1625\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1627\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1628\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:688\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    685\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m     result = \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_package\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_frame_box\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_box\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.caching_precompile \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._package \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    710\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpackage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DynamoCache\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1433\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip, package, convert_frame_box)\u001b[39m\n\u001b[32m   1431\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1433\u001b[39m     guarded_code, tracer_output = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m   1436\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m   1437\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1442\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m   1443\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m   1444\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_utils_internal.py:92\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# This is not needed but we have it here to avoid having profile_compile_time\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m# in stack traces when profiling is not enabled.\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     95\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     96\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1117\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1111\u001b[39m     stack.enter_context(\n\u001b[32m   1112\u001b[39m         torch._dynamo.callback_handler.install_callbacks(\n\u001b[32m   1113\u001b[39m             CallbackTrigger.DYNAMO, \u001b[38;5;28mstr\u001b[39m(CompileContext.current_compile_id())\n\u001b[32m   1114\u001b[39m         )\n\u001b[32m   1115\u001b[39m     )\n\u001b[32m   1116\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m-> \u001b[39m\u001b[32m1117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m   1120\u001b[39m     ConvertFrameReturn(),\n\u001b[32m   1121\u001b[39m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1122\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1151\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks)\u001b[39m\n\u001b[32m   1149\u001b[39m out_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1151\u001b[39m     dynamo_output = \u001b[43mcompile_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuiltins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrestart_reasons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.SkipFrame \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m one_graph:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1032\u001b[39m, in \u001b[36mcompile_frame\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, restart_reasons, export, export_constraints, frame_state, distributed_state, package)\u001b[39m\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1031\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcompile_attempt_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1032\u001b[39m         bytecode, tracer_output = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1033\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m tracer_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1034\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m DynamoOutput(\n\u001b[32m   1035\u001b[39m             tracer_output=tracer_output,\n\u001b[32m   1036\u001b[39m             bytecode=bytecode,\n\u001b[32m   1037\u001b[39m             last_attempt_start_time=last_attempt_start_time,\n\u001b[32m   1038\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/bytecode_transformation.py:1592\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1589\u001b[39m \u001b[38;5;66;03m# propagate line nums again for added instructions\u001b[39;00m\n\u001b[32m   1590\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m tracer_output = \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1593\u001b[39m _, bytecode = clean_and_assemble_instructions(instructions, keys, code_options)\n\u001b[32m   1594\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m bytecode, tracer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:1004\u001b[39m, in \u001b[36mcompile_frame.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m    999\u001b[39m     instructions: \u001b[38;5;28mlist\u001b[39m[Instruction], code_options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mobject\u001b[39m]\n\u001b[32m   1000\u001b[39m ) -> DynamoTracerOutput:\n\u001b[32m   1001\u001b[39m     tf_mode_stack: \u001b[38;5;28mlist\u001b[39m[torch.overrides.TorchFunctionMode] = (\n\u001b[32m   1002\u001b[39m         torch.overrides._get_current_function_mode_stack()\n\u001b[32m   1003\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m     tracer_output = \u001b[43mtrace_frame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbuiltins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtf_mode_stack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mspeculation_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexport_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistributed_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1023\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m tracer_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1024\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tracer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:312\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    310\u001b[39m exit_stack.enter_context(torch_function_mode_stack_state_mgr)\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    314\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:815\u001b[39m, in \u001b[36mtrace_frame\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, tf_mode_stack, one_graph, speculation_log, instructions, code_options, export, export_constraints, frame_state, distributed_state, package)\u001b[39m\n\u001b[32m    812\u001b[39m         tracer.output.call_cleanup_hooks()\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m815\u001b[39m     \u001b[43mrun_tracer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    816\u001b[39m     tracer_output = DynamoTracerOutput(tracer)\n\u001b[32m    817\u001b[39m     output = tracer_output.output_graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/convert_frame.py:797\u001b[39m, in \u001b[36mtrace_frame.<locals>.run_tracer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    795\u001b[39m     tracer.output.mark_bytecode_tracing_start()\n\u001b[32m    796\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m797\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    799\u001b[39m     speculation_log.clear()  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1487\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1485\u001b[39m \u001b[38;5;28mself\u001b[39m.start_point = \u001b[38;5;28mself\u001b[39m.instruction_pointer\n\u001b[32m   1486\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1487\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1488\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1348\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1345\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:904\u001b[39m, in \u001b[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation.reason)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.active_generic_context_managers:\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3411\u001b[39m, in \u001b[36mInstructionTranslatorBase.CALL\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3409\u001b[39m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push=\u001b[32m1\u001b[39m)\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: Instruction) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3411\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3405\u001b[39m, in \u001b[36mInstructionTranslatorBase._call\u001b[39m\u001b[34m(self, inst, call_kw)\u001b[39m\n\u001b[32m   3400\u001b[39m     kwargs = {}\n\u001b[32m   3402\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3403\u001b[39m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[32m   3404\u001b[39m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3405\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3406\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   3407\u001b[39m     \u001b[38;5;28mself\u001b[39m.kw_names = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1266\u001b[39m, in \u001b[36mInstructionTranslatorBase.call_function\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   1264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[32m   1265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/lazy.py:212\u001b[39m, in \u001b[36m_create_realize_and_forward.<locals>.realize_and_forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(\u001b[38;5;28mgetattr\u001b[39m(VariableTracker, name))\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrealize_and_forward\u001b[39m(\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mself\u001b[39m: LazyVariableTracker, *args: Any, **kwargs: Any\n\u001b[32m    211\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:1010\u001b[39m, in \u001b[36mUnspecializedNNModuleVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1002\u001b[39m ctx = (\n\u001b[32m   1003\u001b[39m     record_nn_module_stack(\n\u001b[32m   1004\u001b[39m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(mod)), \u001b[38;5;28mself\u001b[39m.get_nn_module_stack_source(), tx, mod\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[32m   1008\u001b[39m )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvariables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUserFunctionVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:598\u001b[39m, in \u001b[36mUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    596\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch._dynamo.side_effects.allow_side_effects_under_checkpoint(tx):\n\u001b[32m    597\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().call_function(tx, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:342\u001b[39m, in \u001b[36mBaseUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_function\u001b[39m(\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    338\u001b[39m     tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    339\u001b[39m     args: \u001b[33m\"\u001b[39m\u001b[33mlist[VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    340\u001b[39m     kwargs: \u001b[33m\"\u001b[39m\u001b[33mdict[str, VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    341\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mVariableTracker\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_user_function_return\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1288\u001b[39m, in \u001b[36mInstructionTranslatorBase.inline_user_function_return\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inline_generator_function(fn, args, kwargs)\n\u001b[32m   1287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInliningInstructionTranslator\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:4112\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call\u001b[39m\u001b[34m(cls, parent, func, args, kwargs)\u001b[39m\n\u001b[32m   4110\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m patch.dict(counters, {\u001b[33m\"\u001b[39m\u001b[33munimplemented\u001b[39m\u001b[33m\"\u001b[39m: counters[\u001b[33m\"\u001b[39m\u001b[33minline_call\u001b[39m\u001b[33m\"\u001b[39m]}):\n\u001b[32m   4111\u001b[39m     tracer = \u001b[38;5;28mcls\u001b[39m.build_inline_tracer(parent, func, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_call_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:4315\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   4313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4314\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m strict_ctx:\n\u001b[32m-> \u001b[39m\u001b[32m4315\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4316\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   4317\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObserved exception DURING INLING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1487\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1485\u001b[39m \u001b[38;5;28mself\u001b[39m.start_point = \u001b[38;5;28mself\u001b[39m.instruction_pointer\n\u001b[32m   1486\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1487\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1488\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1348\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1345\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:904\u001b[39m, in \u001b[36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    902\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_graph_break(\u001b[38;5;28mself\u001b[39m, inst, speculation.reason)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m excp:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.active_generic_context_managers:\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# We don't support graph break under GenericContextWrappingVariable,\u001b[39;00m\n\u001b[32m    908\u001b[39m         \u001b[38;5;66;03m# If there is, we roll back to the checkpoint and fall back.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3411\u001b[39m, in \u001b[36mInstructionTranslatorBase.CALL\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3409\u001b[39m \u001b[38;5;129m@break_graph_if_unsupported\u001b[39m(push=\u001b[32m1\u001b[39m)\n\u001b[32m   3410\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mCALL\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: Instruction) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3411\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3405\u001b[39m, in \u001b[36mInstructionTranslatorBase._call\u001b[39m\u001b[34m(self, inst, call_kw)\u001b[39m\n\u001b[32m   3400\u001b[39m     kwargs = {}\n\u001b[32m   3402\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3403\u001b[39m     \u001b[38;5;66;03m# if call_function fails, need to set kw_names to None, otherwise\u001b[39;00m\n\u001b[32m   3404\u001b[39m     \u001b[38;5;66;03m# a subsequent call may have self.kw_names set to an old value\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3405\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3406\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   3407\u001b[39m     \u001b[38;5;28mself\u001b[39m.kw_names = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1266\u001b[39m, in \u001b[36mInstructionTranslatorBase.call_function\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   1264\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inner_fn \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(inner_fn) \u001b[38;5;129;01mand\u001b[39;00m is_forbidden(inner_fn):\n\u001b[32m   1265\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt to trace forbidden callable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1266\u001b[39m \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/lazy.py:212\u001b[39m, in \u001b[36m_create_realize_and_forward.<locals>.realize_and_forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(\u001b[38;5;28mgetattr\u001b[39m(VariableTracker, name))\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrealize_and_forward\u001b[39m(\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mself\u001b[39m: LazyVariableTracker, *args: Any, **kwargs: Any\n\u001b[32m    211\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrealize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/nn_module.py:1010\u001b[39m, in \u001b[36mUnspecializedNNModuleVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1002\u001b[39m ctx = (\n\u001b[32m   1003\u001b[39m     record_nn_module_stack(\n\u001b[32m   1004\u001b[39m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(mod)), \u001b[38;5;28mself\u001b[39m.get_nn_module_stack_source(), tx, mod\n\u001b[32m   (...)\u001b[39m\u001b[32m   1007\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[32m   1008\u001b[39m )\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[32m-> \u001b[39m\u001b[32m1010\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvariables\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUserFunctionVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:598\u001b[39m, in \u001b[36mUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    596\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch._dynamo.side_effects.allow_side_effects_under_checkpoint(tx):\n\u001b[32m    597\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().call_function(tx, args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m598\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/functions.py:342\u001b[39m, in \u001b[36mBaseUserFunctionVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_function\u001b[39m(\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    338\u001b[39m     tx: \u001b[33m\"\u001b[39m\u001b[33mInstructionTranslator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    339\u001b[39m     args: \u001b[33m\"\u001b[39m\u001b[33mlist[VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    340\u001b[39m     kwargs: \u001b[33m\"\u001b[39m\u001b[33mdict[str, VariableTracker]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    341\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mVariableTracker\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_user_function_return\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1288\u001b[39m, in \u001b[36mInstructionTranslatorBase.inline_user_function_return\u001b[39m\u001b[34m(self, fn, args, kwargs)\u001b[39m\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inline_generator_function(fn, args, kwargs)\n\u001b[32m   1287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInliningInstructionTranslator\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:4112\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call\u001b[39m\u001b[34m(cls, parent, func, args, kwargs)\u001b[39m\n\u001b[32m   4110\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m patch.dict(counters, {\u001b[33m\"\u001b[39m\u001b[33munimplemented\u001b[39m\u001b[33m\"\u001b[39m: counters[\u001b[33m\"\u001b[39m\u001b[33minline_call\u001b[39m\u001b[33m\"\u001b[39m]}):\n\u001b[32m   4111\u001b[39m     tracer = \u001b[38;5;28mcls\u001b[39m.build_inline_tracer(parent, func, args, kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43minline_call_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:4315\u001b[39m, in \u001b[36mInliningInstructionTranslator.inline_call_\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   4313\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4314\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m strict_ctx:\n\u001b[32m-> \u001b[39m\u001b[32m4315\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4316\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.ObservedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   4317\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mObserved exception DURING INLING \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1487\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1485\u001b[39m \u001b[38;5;28mself\u001b[39m.start_point = \u001b[38;5;28mself\u001b[39m.instruction_pointer\n\u001b[32m   1486\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1487\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1488\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1489\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:1348\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1345\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:3351\u001b[39m, in \u001b[36mInstructionTranslatorBase.BINARY_OP\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mBINARY_OP\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst: Instruction) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3350\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m inst.arg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3351\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_binary_op_lookup\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/symbolic_convert.py:462\u001b[39m, in \u001b[36mstack_op.<locals>.impl\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimpl\u001b[39m(\u001b[38;5;28mself\u001b[39m: InstructionTranslator, inst: Instruction) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[38;5;28mself\u001b[39m.push(\u001b[43mfn_var\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpopn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1347\u001b[39m, in \u001b[36mBuiltinVariable.call_function\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handler:\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28mself\u001b[39m.call_function_handler_cache[key] = handler = \u001b[38;5;28mself\u001b[39m._make_handler(\n\u001b[32m   1345\u001b[39m         \u001b[38;5;28mself\u001b[39m.fn, [\u001b[38;5;28mtype\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args], \u001b[38;5;28mbool\u001b[39m(kwargs)\n\u001b[32m   1346\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1347\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/builtin.py:1307\u001b[39m, in \u001b[36mBuiltinVariable._handle_insert_op_in_graph\u001b[39m\u001b[34m(self, tx, args, kwargs)\u001b[39m\n\u001b[32m   1303\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m operator.truediv \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   1304\u001b[39m             args[\u001b[32m0\u001b[39m], variables.UnspecializedPythonVariable\n\u001b[32m   1305\u001b[39m         ):\n\u001b[32m   1306\u001b[39m             args[\u001b[32m0\u001b[39m] = args[\u001b[32m0\u001b[39m].as_python_constant()\n\u001b[32m-> \u001b[39m\u001b[32m1307\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_fx_proxy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m   1310\u001b[39m     unimplemented_v2(\n\u001b[32m   1311\u001b[39m         gb_type=\u001b[33m\"\u001b[39m\u001b[33munimplemented builtin op on tensor arguments\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1312\u001b[39m         context=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpartial tensor op: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1313\u001b[39m         explanation=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDynamo does not know how to trace builtin operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.fn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with tensor arguments\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1314\u001b[39m         hints=[*graph_break_hints.SUPPORTABLE],\n\u001b[32m   1315\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2645\u001b[39m, in \u001b[36mwrap_fx_proxy\u001b[39m\u001b[34m(tx, proxy, example_value, subclass_type, **options)\u001b[39m\n\u001b[32m   2637\u001b[39m kwargs = {\n\u001b[32m   2638\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtx\u001b[39m\u001b[33m\"\u001b[39m: tx,\n\u001b[32m   2639\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mproxy\u001b[39m\u001b[33m\"\u001b[39m: proxy,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2642\u001b[39m     **options,\n\u001b[32m   2643\u001b[39m }\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m subclass_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_fx_proxy_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTensorVariable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2646\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2647\u001b[39m     result = wrap_fx_proxy_cls(target_cls=TensorWithTFOverrideVariable, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2711\u001b[39m, in \u001b[36mwrap_fx_proxy_cls\u001b[39m\u001b[34m(target_cls, tx, proxy, example_value, subclass_type, **options)\u001b[39m\n\u001b[32m   2707\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_fx_proxy_cls\u001b[39m(\n\u001b[32m   2708\u001b[39m     target_cls, tx, proxy, example_value=\u001b[38;5;28;01mNone\u001b[39;00m, subclass_type=\u001b[38;5;28;01mNone\u001b[39;00m, **options\n\u001b[32m   2709\u001b[39m ):\n\u001b[32m   2710\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m example_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2711\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrap_fx_proxy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2712\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtarget_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\n\u001b[32m   2713\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2714\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(example_value, torch.Tensor):\n\u001b[32m   2715\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _wrap_fx_preexisting_tensor(\n\u001b[32m   2716\u001b[39m             target_cls, tx, proxy, example_value, subclass_type, **options\n\u001b[32m   2717\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/variables/builder.py:2809\u001b[39m, in \u001b[36m_wrap_fx_proxy\u001b[39m\u001b[34m(target_cls, tx, proxy, example_value, subclass_type, **options)\u001b[39m\n\u001b[32m   2804\u001b[39m \u001b[38;5;66;03m# See NOTE: [Deferring tensor pack/unpack hooks until runtime]\u001b[39;00m\n\u001b[32m   2805\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch._dynamo.utils._disable_saved_tensors_hooks_during_tracing():\n\u001b[32m   2806\u001b[39m     \u001b[38;5;66;03m# with preserve_rng_state():\u001b[39;00m\n\u001b[32m   2807\u001b[39m     \u001b[38;5;66;03m# only allow_non_graph_fake in this instance because we handle the non-fake\u001b[39;00m\n\u001b[32m   2808\u001b[39m     \u001b[38;5;66;03m# cases properly below.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2809\u001b[39m     example_value = \u001b[43mget_fake_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_non_graph_fake\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2811\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m handle_traced_output(\n\u001b[32m   2812\u001b[39m     example_value, tx, proxy, options, subclass_type, target_cls\n\u001b[32m   2813\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/utils.py:3478\u001b[39m, in \u001b[36mget_fake_value\u001b[39m\u001b[34m(node, tx, allow_non_graph_fake)\u001b[39m\n\u001b[32m   3470\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cause, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33margument\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(cause):\n\u001b[32m   3471\u001b[39m         unimplemented_v2(\n\u001b[32m   3472\u001b[39m             gb_type=\u001b[33m\"\u001b[39m\u001b[33mTypeError when making fake tensor call\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3473\u001b[39m             context=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTypeError \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode.target\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcause\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   3474\u001b[39m             explanation=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3475\u001b[39m             hints=[],\n\u001b[32m   3476\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m3478\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m TorchRuntimeError(\u001b[38;5;28mstr\u001b[39m(e)).with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_non_graph_fake:\n\u001b[32m   3481\u001b[39m     _ = pytree.tree_map_only(\n\u001b[32m   3482\u001b[39m         torch.Tensor, functools.partial(ensure_graph_fake, tx=tx), ret_val\n\u001b[32m   3483\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/utils.py:3376\u001b[39m, in \u001b[36mget_fake_value\u001b[39m\u001b[34m(node, tx, allow_non_graph_fake)\u001b[39m\n\u001b[32m   3374\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3375\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m fake_mode, enable_python_dispatcher():\n\u001b[32m-> \u001b[39m\u001b[32m3376\u001b[39m         ret_val = \u001b[43mwrap_fake_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3377\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3378\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3379\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n\u001b[32m   3380\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/utils.py:2864\u001b[39m, in \u001b[36mwrap_fake_exception\u001b[39m\u001b[34m(fn)\u001b[39m\n\u001b[32m   2862\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_fake_exception\u001b[39m(fn: Callable[[], Any]) -> Any:\n\u001b[32m   2863\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2864\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2865\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m UnsupportedFakeTensorException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2866\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m unimplemented_v2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/utils.py:3377\u001b[39m, in \u001b[36mget_fake_value.<locals>.<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   3374\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3375\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m fake_mode, enable_python_dispatcher():\n\u001b[32m   3376\u001b[39m         ret_val = wrap_fake_exception(\n\u001b[32m-> \u001b[39m\u001b[32m3377\u001b[39m             \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnnmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3378\u001b[39m         )\n\u001b[32m   3379\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported:\n\u001b[32m   3380\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/utils.py:3587\u001b[39m, in \u001b[36mrun_node\u001b[39m\u001b[34m(tracer, node, args, kwargs, nnmodule)\u001b[39m\n\u001b[32m   3585\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   3586\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3587\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(make_error_message(e)).with_traceback(\n\u001b[32m   3588\u001b[39m             e.__traceback__\n\u001b[32m   3589\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   3591\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(op)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_dynamo/utils.py:3546\u001b[39m, in \u001b[36mrun_node\u001b[39m\u001b[34m(tracer, node, args, kwargs, nnmodule)\u001b[39m\n\u001b[32m   3544\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   3545\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m op == \u001b[33m\"\u001b[39m\u001b[33mcall_function\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m3546\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m   3547\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m op == \u001b[33m\"\u001b[39m\u001b[33mcall_method\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3548\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(args[\u001b[32m0\u001b[39m], node.target):  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/utils/_stats.py:28\u001b[39m, in \u001b[36mcount.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     26\u001b[39m     simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m     27\u001b[39m simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] = simple_call_counter[fn.\u001b[34m__qualname__\u001b[39m] + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1376\u001b[39m, in \u001b[36mFakeTensorMode.__torch_dispatch__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1372\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m   1373\u001b[39m     torch._C._get_dispatch_mode(torch._C._TorchDispatchModeKey.FAKE) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1374\u001b[39m ), func\n\u001b[32m   1375\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   1378\u001b[39m     log.exception(\u001b[33m\"\u001b[39m\u001b[33mfake tensor raised TypeError\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2096\u001b[39m, in \u001b[36mFakeTensorMode.dispatch\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   2093\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m   2095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache_enabled:\n\u001b[32m-> \u001b[39m\u001b[32m2096\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cached_dispatch_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2098\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dispatch_impl(func, types, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:1511\u001b[39m, in \u001b[36mFakeTensorMode._cached_dispatch_impl\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m   1510\u001b[39m \u001b[38;5;66;03m# We don't have a cache entry.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1513\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1514\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_cache_key(func, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_subclasses/fake_tensor.py:2755\u001b[39m, in \u001b[36mFakeTensorMode._dispatch_impl\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m   2753\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2754\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m in_kernel_invocation_manager(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2755\u001b[39m         r = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2756\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m not_implemented_error:\n\u001b[32m   2757\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m maybe_run_unsafe_fallback(not_implemented_error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_ops.py:841\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_meta_registrations.py:4193\u001b[39m, in \u001b[36mmeta_binop_inplace_alpha\u001b[39m\u001b[34m(self, other, alpha)\u001b[39m\n\u001b[32m   4188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4189\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPromotion of book.add/sub_(others) in in-place ops are not possible due to element size change.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4190\u001b[39m     )\n\u001b[32m   4192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, torch.Tensor):\n\u001b[32m-> \u001b[39m\u001b[32m4193\u001b[39m     \u001b[43mcheck_inplace_broadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4194\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_meta_registrations.py:97\u001b[39m, in \u001b[36mcheck_inplace_broadcast\u001b[39m\u001b[34m(self_shape, *args_shape)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_inplace_broadcast\u001b[39m(self_shape, *args_shape):\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     broadcasted_shape = \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_shape\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     98\u001b[39m     torch._check(\n\u001b[32m     99\u001b[39m         broadcasted_shape == self_shape,\n\u001b[32m    100\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33moutput with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mself_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt match the broadcast shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbroadcasted_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    101\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/_refs/__init__.py:436\u001b[39m, in \u001b[36m_broadcast_shapes\u001b[39m\u001b[34m(*_shapes)\u001b[39m\n\u001b[32m    433\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    434\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    435\u001b[39m             \u001b[38;5;66;03m# If broadcasting is undecided we pick non-broadcast path and add runtime assertion.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m             \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcommon_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mAttempting to broadcast a dimension of length \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m at \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m! \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    439\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMismatching argument at index \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43marg_idx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m had \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mshape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m; but expected shape \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    440\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshould be broadcastable to \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcommon_shape\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m common_shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/__init__.py:1695\u001b[39m, in \u001b[36m_check\u001b[39m\u001b[34m(cond, message)\u001b[39m\n\u001b[32m   1680\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check\u001b[39m(cond, message=\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   1681\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Throws error containing an optional message if the specified condition\u001b[39;00m\n\u001b[32m   1682\u001b[39m \u001b[33;03m    is False.\u001b[39;00m\n\u001b[32m   1683\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1693\u001b[39m \u001b[33;03m            message. Default: ``None``\u001b[39;00m\n\u001b[32m   1694\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1695\u001b[39m     \u001b[43m_check_with\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/__init__.py:1677\u001b[39m, in \u001b[36m_check_with\u001b[39m\u001b[34m(error_type, cond, message)\u001b[39m\n\u001b[32m   1673\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmessage must be a callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1675\u001b[39m     message_evaluated = \u001b[38;5;28mstr\u001b[39m(message())\n\u001b[32m-> \u001b[39m\u001b[32m1677\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error_type(message_evaluated)\n",
      "\u001b[31mTorchRuntimeError\u001b[39m: Dynamo failed to run FX node with fake tensors: call_function <built-in function iadd>(*(FakeTensor(..., device='cuda:0', size=(4, 1024, 16, 1024),\n           grad_fn=<MulBackward0>), FakeTensor(..., size=(4096, 1, 4096))), **{}): got RuntimeError('Attempting to broadcast a dimension of length 4096 at -1! Mismatching argument at index 1 had torch.Size([4096, 1, 4096]); but expected shape should be broadcastable to [4, 1024, 16, 1024]')\n\nfrom user code:\n   File \"/home/ubuntu/projects/llm-models/llm-models/models/deepseek/model.py\", line 995, in forward\n    h = layer(h, start_pos, freqs_cis, self.mask)\n  File \"/home/ubuntu/projects/llm-models/llm-models/models/deepseek/model.py\", line 938, in forward\n    x = x + self.attn(self.attn_norm(x), start_pos, freqs_cis, mask)\n  File \"/home/ubuntu/projects/llm-models/llm-models/models/deepseek/model.py\", line 544, in forward\n    scores += mask.unsqueeze(1)\n\nSet TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n"
     ]
    }
   ],
   "source": [
    "test_train('inductor', run_profile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1370f7fb-58f6-42ba-b664-5d8d0baccbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.prof.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a203d4cf-4b12-412f-aa44-76028d97bdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d10cab0-2814-4a4a-8288-3769691207f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "with_stack=True required for memory profiling.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m file_prefix = \u001b[33m'\u001b[39m\u001b[33mmemory_profile_1\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprof\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_memory_timeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfile_prefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.html\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda:0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/profiler/profiler.py:425\u001b[39m, in \u001b[36m_KinetoProfile.export_memory_timeline\u001b[39m\u001b[34m(self, path, device)\u001b[39m\n\u001b[32m    422\u001b[39m         device = \u001b[33m\"\u001b[39m\u001b[33mcuda:0\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;66;03m# Construct the memory timeline plot data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m \u001b[38;5;28mself\u001b[39m.mem_tl = MemoryProfileTimeline(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_memory_profile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    427\u001b[39m \u001b[38;5;66;03m# Depending on the file suffix, save the data as json.gz or json.\u001b[39;00m\n\u001b[32m    428\u001b[39m \u001b[38;5;66;03m# For html, we can embed the image into an HTML file.\u001b[39;00m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path.endswith(\u001b[33m\"\u001b[39m\u001b[33m.html\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/profiler/profiler.py:390\u001b[39m, in \u001b[36m_KinetoProfile._memory_profile\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    388\u001b[39m missing = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=True\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m required \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, i)]\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(missing)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m required for memory profiling.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.profiler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.profiler.kineto_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m MemoryProfile(\u001b[38;5;28mself\u001b[39m.profiler.kineto_results)\n",
      "\u001b[31mValueError\u001b[39m: with_stack=True required for memory profiling."
     ]
    }
   ],
   "source": [
    "file_prefix = 'memory_profile_1'\n",
    "trainer.prof.export_memory_timeline(f\"{file_prefix}.html\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bd25dbf-38b0-439f-8ca3-a07cd40d581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                          ## forward ##         0.00%       0.000us         0.00%       0.000us       0.000us        3.781s       232.98%        3.781s     157.526ms           0 B           0 B           0 B           0 B            24  \n",
      "                                              aten::bmm         1.29%      92.633ms         1.74%     125.139ms      30.815us     361.384ms        22.27%     361.397ms      88.992us           0 B           0 B           0 B           0 B          4061  \n",
      "## Call CompiledFxGraph f3dkngadwmxlaapgp22cdimat3lu...         0.00%       0.000us         0.00%       0.000us       0.000us     310.905ms        19.16%     310.905ms     719.687us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph f6ypersqgcfrdtngal7ad4lkogpy...         0.00%       0.000us         0.00%       0.000us       0.000us     251.419ms        15.49%     251.419ms     581.988us           0 B           0 B           0 B           0 B           432  \n",
      "                                            aten::copy_         0.18%      12.826ms         1.43%     102.638ms      58.483us     250.561ms        15.44%     250.561ms     142.770us           0 B           0 B           0 B           0 B          1755  \n",
      "## Call CompiledFxGraph fbckvypgoyh5wlguxzkr73oq4ueu...         0.00%       0.000us         0.00%       0.000us       0.000us     228.185ms        14.06%     228.185ms       3.169ms           0 B           0 B           0 B           0 B            72  \n",
      "                                               aten::mm         1.65%     118.432ms         2.36%     169.594ms      37.086us     187.200ms        11.54%     187.207ms      40.937us           0 B           0 B           0 B           0 B          4573  \n",
      "## Call CompiledFxGraph fnoewiyynwx3wzjela47bplx2bny...         0.00%       0.000us         0.00%       0.000us       0.000us     182.696ms        11.26%     182.696ms       2.537ms           0 B           0 B           0 B           0 B            72  \n",
      "                       aten::_log_softmax_backward_data         0.00%     347.896us         0.01%     558.841us      23.285us     162.187ms         9.99%     162.187ms       6.758ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     162.187ms         9.99%     162.187ms       6.758ms           0 B           0 B           0 B           0 B            24  \n",
      "                                     aten::_log_softmax         0.01%     606.029us         0.01%     949.788us      39.574us     157.043ms         9.68%     157.043ms       6.543ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     157.043ms         9.68%     157.043ms       6.543ms           0 B           0 B           0 B           0 B            24  \n",
      "       InductorBenchmarker.benchmark_gpu (dynamo_timed)         0.00%       0.000us         0.00%       0.000us       0.000us     147.921ms         9.12%     147.921ms      13.447ms           0 B           0 B           0 B           0 B            11  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     124.260ms         7.66%     124.260ms       5.177ms           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     122.793ms         7.57%     122.793ms       5.116ms           0 B           0 B           0 B           0 B            24  \n",
      "                                            aten::fill_         0.35%      25.466ms         0.81%      57.954ms      13.576us     115.364ms         7.11%     115.364ms      27.024us           0 B           0 B           0 B           0 B          4269  \n",
      "triton_per_fused__softmax__to_copy_add_exp_mul_permu...         0.03%       1.811ms         0.04%       2.667ms      27.784us     107.435ms         6.62%     107.435ms       1.119ms           0 B           0 B           0 B           0 B            96  \n",
      "triton_per_fused__softmax__to_copy_add_exp_mul_permu...         0.00%       0.000us         0.00%       0.000us       0.000us     107.435ms         6.62%     107.435ms       1.119ms           0 B           0 B           0 B           0 B            96  \n",
      "## Call CompiledFxGraph fdkbgrpms2f5t2d5j54k3qxedfco...         0.00%       0.000us         0.00%       0.000us       0.000us      90.911ms         5.60%      90.911ms       3.788ms           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      81.559ms         5.03%      81.559ms       1.599ms           0 B           0 B           0 B           0 B            51  \n",
      "## Call CompiledFxGraph f645cim5xmpvm2377llczkw4xgxg...         0.00%       0.000us         0.00%       0.000us       0.000us      79.637ms         4.91%      79.637ms       3.318ms           0 B           0 B           0 B           0 B            24  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.02%       1.495ms         0.03%       2.221ms      23.138us      78.568ms         4.84%      78.568ms     818.415us           0 B           0 B           0 B           0 B            96  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.00%       0.000us         0.00%       0.000us       0.000us      78.568ms         4.84%      78.568ms     818.415us           0 B           0 B           0 B           0 B            96  \n",
      "## Call CompiledFxGraph fffrru2g3xvxsfxkqu75k4uerzlt...         0.00%       0.000us         0.00%       0.000us       0.000us      68.656ms         4.23%      68.656ms       2.861ms           0 B           0 B           0 B           0 B            24  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      65.726ms         4.05%      65.726ms     105.330us           0 B           0 B           0 B           0 B           624  \n",
      "          ampere_bf16_s16816gemm_bf16_64x64_ldg8_f2f_nn         0.00%       0.000us         0.00%       0.000us       0.000us      63.894ms         3.94%      63.894ms     332.781us           0 B           0 B           0 B           0 B           192  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      63.158ms         3.89%      63.158ms      90.744us           0 B           0 B           0 B           0 B           696  \n",
      "ampere_bf16_s16816gemm_bf16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      57.414ms         3.54%      57.414ms     299.029us           0 B           0 B           0 B           0 B           192  \n",
      "ampere_bf16_s1688gemm_bf16_128x128_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us      52.290ms         3.22%      52.290ms       2.179ms           0 B           0 B           0 B           0 B            24  \n",
      "## Call CompiledFxGraph fvingb54prth3cicubokrz6if6r2...         0.00%       0.000us         0.00%       0.000us       0.000us      52.290ms         3.22%      52.290ms       2.179ms           0 B           0 B           0 B           0 B            24  \n",
      "ampere_bf16_s16816gemm_bf16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      49.401ms         3.04%      49.401ms       2.058ms           0 B           0 B           0 B           0 B            24  \n",
      "                                 aten::_index_put_impl_         1.19%      85.785ms         4.46%     320.688ms     159.071us      46.214ms         2.85%      58.088ms      28.813us           0 B      -1.81 KB           0 B    -218.25 MB          2016  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us      41.422ms         2.55%      41.422ms       1.726ms           0 B           0 B           0 B           0 B            24  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      32.710ms         2.02%      32.710ms     113.577us           0 B           0 B           0 B           0 B           288  \n",
      "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us      31.223ms         1.92%      31.223ms      10.408ms           0 B           0 B           0 B           0 B             3  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      30.769ms         1.90%      30.769ms      13.578us           0 B           0 B           0 B           0 B          2266  \n",
      "ampere_bf16_s16816gemm_bf16_64x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us      28.470ms         1.75%      28.470ms     296.566us           0 B           0 B           0 B           0 B            96  \n",
      "void cutlass::Kernel2<cutlass_75_tensorop_bf16_s1688...         0.00%       0.000us         0.00%       0.000us       0.000us      28.075ms         1.73%      28.075ms     233.955us           0 B           0 B           0 B           0 B           120  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.21%      14.775ms         0.30%      21.353ms      24.945us      26.371ms         1.63%      26.371ms      30.808us           0 B           0 B           0 B           0 B           856  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.00%       0.000us         0.00%       0.000us       0.000us      26.371ms         1.63%      26.371ms      30.808us           0 B           0 B           0 B           0 B           856  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us      24.131ms         1.49%      24.131ms       9.858us           0 B           0 B           0 B           0 B          2448  \n",
      "                                             aten::add_         0.64%      45.954ms         1.17%      83.955ms      16.099us      18.792ms         1.16%      18.792ms       3.604us          80 B      -1.52 KB           0 B           0 B          5215  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.869ms         0.98%      15.869ms       4.145us           0 B           0 B           0 B           0 B          3828  \n",
      "                                              aten::mul         1.09%      78.023ms         2.04%     146.954ms      34.741us      12.674ms         0.78%      13.814ms       3.266us       1.20 KB       1.21 KB       2.36 GB       2.36 GB          4230  \n",
      "## Call CompiledFxGraph fwq7bmxvx3unoa3vs5dubkrjrvoi...         0.00%       0.000us         0.00%       0.000us       0.000us      11.591ms         0.71%      11.591ms     160.993us           0 B           0 B           0 B           0 B            72  \n",
      "ampere_bf16_s1688gemm_bf16_64x128_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us      11.118ms         0.69%      11.118ms       8.740us           0 B           0 B           0 B           0 B          1272  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us      10.659ms         0.66%      10.659ms       8.380us           0 B           0 B           0 B           0 B          1272  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      10.109ms         0.62%      10.109ms       8.596us           0 B           0 B           0 B           0 B          1176  \n",
      "                                            aten::index         0.64%      46.138ms         1.05%      75.614ms      43.758us      10.035ms         0.62%      10.035ms       5.807us           0 B           0 B       1.27 GB       1.27 GB          1728  \n",
      "triton_per_fused__fused_rms_norm_backward__to_copy_a...         0.17%      12.437ms         0.25%      17.734ms      23.645us       7.580ms         0.47%       7.580ms      10.106us           0 B           0 B           0 B           0 B           750  \n",
      "triton_per_fused__fused_rms_norm_backward__to_copy_a...         0.00%       0.000us         0.00%       0.000us       0.000us       7.580ms         0.47%       7.580ms      10.106us           0 B           0 B           0 B           0 B           750  \n",
      "triton_per_fused__softmax__to_copy_exp_mul_permute_p...         0.10%       7.162ms         0.15%      10.970ms      25.394us       7.149ms         0.44%       7.149ms      16.549us           0 B           0 B           0 B           0 B           432  \n",
      "triton_per_fused__softmax__to_copy_exp_mul_permute_p...         0.00%       0.000us         0.00%       0.000us       0.000us       7.149ms         0.44%       7.149ms      16.549us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph f5k6hqiihurixgxoy2de5vpckw5n...         0.00%       0.000us         0.00%       0.000us       0.000us       6.728ms         0.41%       6.728ms     280.325us           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::vectorized_gather_kernel<16, long>(...         0.00%       0.000us         0.00%       0.000us       0.000us       6.726ms         0.41%       6.726ms       5.189us           0 B           0 B           0 B           0 B          1296  \n",
      "## Call CompiledFxGraph fdm6uat3bajwoljdrckudcw6tjbp...         0.00%       0.000us         0.00%       0.000us       0.000us       6.201ms         0.38%       6.201ms      86.126us           0 B           0 B           0 B           0 B            72  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       6.187ms         0.38%       6.187ms      14.322us           0 B           0 B           0 B           0 B           432  \n",
      "ampere_bf16_s1688gemm_bf16_64x128_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us       6.037ms         0.37%       6.037ms      11.433us           0 B           0 B           0 B           0 B           528  \n",
      "                                          aten::nonzero         0.33%      23.541ms         0.76%      54.649ms     126.502us       5.987ms         0.37%       5.987ms      13.858us           0 B           0 B      27.00 MB           0 B           432  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.951ms         0.37%       5.951ms       7.514us           0 B           0 B           0 B           0 B           792  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       5.729ms         0.35%       5.729ms       1.164us           0 B           0 B           0 B           0 B          4920  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.280ms         0.33%       5.280ms      12.223us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph fctgmlmsbw224kqs77mhhq76ztq5...         0.00%       0.000us         0.00%       0.000us       0.000us       5.124ms         0.32%       5.124ms      71.171us           0 B           0 B           0 B           0 B            72  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       4.783ms         0.29%       4.783ms      11.071us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph fp4iuldgh7qj4cb4w4sp4av7iyaj...         0.00%       0.000us         0.00%       0.000us       0.000us       4.404ms         0.27%       4.404ms      61.167us           0 B           0 B           0 B           0 B            72  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.342ms         0.27%       4.342ms       5.025us           0 B           0 B           0 B           0 B           864  \n",
      "                                        aten::remainder         0.38%      27.265ms         0.53%      38.386ms      23.180us       4.263ms         0.26%       4.263ms       2.574us         624 B         624 B      51.75 MB      51.75 MB          1656  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.263ms         0.26%       4.263ms       2.574us           0 B           0 B           0 B           0 B          1656  \n",
      "            triton_poi_fused_embedding_dense_backward_2         0.00%     273.195us         0.01%     451.108us      18.796us       3.881ms         0.24%       3.881ms     161.721us           0 B           0 B           0 B           0 B            24  \n",
      "            triton_poi_fused_embedding_dense_backward_2         0.00%       0.000us         0.00%       0.000us       0.000us       3.881ms         0.24%       3.881ms     161.721us           0 B           0 B           0 B           0 B            24  \n",
      "triton_poi_fused__to_copy_cat_permute_slice_squeeze_...         0.12%       8.784ms         0.19%      13.842ms      21.494us       3.875ms         0.24%       3.875ms       6.017us           0 B           0 B           0 B           0 B           644  \n",
      "triton_poi_fused__to_copy_cat_permute_slice_squeeze_...         0.00%       0.000us         0.00%       0.000us       0.000us       3.875ms         0.24%       3.875ms       6.017us           0 B           0 B           0 B           0 B           644  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us       3.741ms         0.23%       3.741ms       3.056us           0 B           0 B           0 B           0 B          1224  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.718ms         0.23%       3.718ms       2.980us           0 B           0 B           0 B           0 B          1248  \n",
      "void cublasLt::splitKreduce_kernel<32, 16, int, __nv...         0.00%       0.000us         0.00%       0.000us       0.000us       3.406ms         0.21%       3.406ms       2.252us           0 B           0 B           0 B           0 B          1512  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.309ms         0.20%       3.309ms       7.661us           0 B           0 B           0 B           0 B           432  \n",
      "triton_red_fused__fused_rms_norm_backward__to_copy_m...         0.07%       5.218ms         0.11%       7.983ms      18.478us       3.292ms         0.20%       3.292ms       7.620us           0 B           0 B           0 B           0 B           432  \n",
      "triton_red_fused__fused_rms_norm_backward__to_copy_m...         0.00%       0.000us         0.00%       0.000us       0.000us       3.292ms         0.20%       3.292ms       7.620us           0 B           0 B           0 B           0 B           432  \n",
      "triton_poi_fused__to_copy_clone_permute_slice_squeez...         0.11%       7.792ms         0.17%      12.369ms      19.207us       3.206ms         0.20%       3.206ms       4.978us           0 B           0 B           0 B           0 B           644  \n",
      "triton_poi_fused__to_copy_clone_permute_slice_squeez...         0.00%       0.000us         0.00%       0.000us       0.000us       3.206ms         0.20%       3.206ms       4.978us           0 B           0 B           0 B           0 B           644  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       2.981ms         0.18%       2.981ms       3.764us           0 B           0 B           0 B           0 B           792  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.945ms         0.18%       2.945ms       1.566us           0 B           0 B           0 B           0 B          1880  \n",
      "                                             aten::topk         0.07%       4.792ms         0.10%       7.098ms      93.400us       2.928ms         0.18%       2.928ms      38.524us           0 B           0 B      20.25 MB      20.25 MB            76  \n",
      "                                             aten::div_         0.22%      15.645ms         0.35%      25.088ms      20.497us       2.847ms         0.18%       2.847ms       2.326us         992 B         992 B           0 B           0 B          1224  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.847ms         0.18%       2.847ms       2.326us           0 B           0 B           0 B           0 B          1224  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.818ms         0.17%       2.818ms       3.727us           0 B           0 B           0 B           0 B           756  \n",
      "            triton_poi_fused_embedding_dense_backward_0         0.00%     338.316us         0.01%     634.632us      26.443us       2.571ms         0.16%       2.571ms     107.124us           0 B           0 B           0 B           0 B            24  \n",
      "            triton_poi_fused_embedding_dense_backward_0         0.00%       0.000us         0.00%       0.000us       0.000us       2.571ms         0.16%       2.571ms     107.124us           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.556ms         0.16%       2.556ms       1.543us           0 B           0 B           0 B           0 B          1656  \n",
      "                                              aten::sum         0.09%       6.659ms         0.14%       9.998ms      23.143us       2.288ms         0.14%       2.288ms       5.296us           0 B           0 B       3.38 MB       3.38 MB           432  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       2.288ms         0.14%       2.288ms       5.296us           0 B           0 B           0 B           0 B           432  \n",
      "void at::native::sbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us       2.165ms         0.13%       2.165ms      30.072us           0 B           0 B           0 B           0 B            72  \n",
      "                                    aten::_foreach_mul_         0.02%       1.239ms         0.03%       1.816ms     151.365us       2.161ms         0.13%       2.161ms     180.062us           0 B           0 B           0 B           0 B            12  \n",
      "triton_poi_fused__to_copy__unsafe_view_split_with_si...         0.10%       7.161ms         0.16%      11.156ms      21.128us       2.069ms         0.13%       2.069ms       3.919us           0 B           0 B           0 B           0 B           528  \n",
      "triton_poi_fused__to_copy__unsafe_view_split_with_si...         0.00%       0.000us         0.00%       0.000us       0.000us       2.069ms         0.13%       2.069ms       3.919us           0 B           0 B           0 B           0 B           528  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.054ms         0.13%       2.054ms       4.754us           0 B           0 B           0 B           0 B           432  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.988ms         0.12%       1.988ms      10.352us           0 B           0 B           0 B           0 B           192  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us       1.931ms         0.12%       1.931ms       1.578us           0 B           0 B           0 B           0 B          1224  \n",
      "            triton_poi_fused__unsafe_view_add_squeeze_5         0.07%       5.001ms         0.11%       7.819ms      18.100us       1.894ms         0.12%       1.894ms       4.385us           0 B           0 B           0 B           0 B           432  \n",
      "            triton_poi_fused__unsafe_view_add_squeeze_5         0.00%       0.000us         0.00%       0.000us       0.000us       1.894ms         0.12%       1.894ms       4.385us           0 B           0 B           0 B           0 B           432  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 7.188s\n",
      "Self CUDA time total: 1.623s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(trainer.prof.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc2147df-1535-4cff-b152-f4e0fc0df571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import depyf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a461993f-4408-421b-9eae-87436db5ba9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'depyf' has no attribute 'save_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdepyf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_code\u001b[49m()\n",
      "\u001b[31mAttributeError\u001b[39m: module 'depyf' has no attribute 'save_code'"
     ]
    }
   ],
   "source": [
    "depyf.save_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0153daae-ab7c-4acc-a3d5-3cda8e2fd283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              aten::bmm         3.23%      80.284ms         4.43%     109.930ms      27.264us     362.544ms        23.11%     362.836ms      89.989us           0 B           0 B           0 B           0 B          4032  \n",
      "## Call CompiledFxGraph fe2dw25r4rvtemqmwyujb2x6u35c...         0.00%       0.000us         0.00%       0.000us       0.000us     251.557ms        16.04%     251.557ms     582.307us           0 B           0 B           0 B           0 B           432  \n",
      "                                            aten::copy_         0.50%      12.459ms         4.21%     104.640ms      60.138us     250.592ms        15.98%     250.592ms     144.019us           0 B           0 B           0 B           0 B          1740  \n",
      "## Call CompiledFxGraph fbckvypgoyh5wlguxzkr73oq4ueu...         0.00%       0.000us         0.00%       0.000us       0.000us     226.961ms        14.47%     226.961ms       3.152ms           0 B           0 B           0 B           0 B            72  \n",
      "                                               aten::mm         4.20%     104.229ms         6.01%     149.338ms      32.923us     186.044ms        11.86%     186.044ms      41.015us           0 B           0 B           0 B           0 B          4536  \n",
      "## Call CompiledFxGraph fnoewiyynwx3wzjela47bplx2bny...         0.00%       0.000us         0.00%       0.000us       0.000us     183.988ms        11.73%     183.988ms       2.555ms           0 B           0 B           0 B           0 B            72  \n",
      "                       aten::_log_softmax_backward_data         0.01%     343.808us         0.02%     544.783us      22.699us     162.182ms        10.34%     162.182ms       6.758ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     162.182ms        10.34%     162.182ms       6.758ms           0 B           0 B           0 B           0 B            24  \n",
      "                                     aten::_log_softmax         0.02%     573.269us         0.04%     907.455us      37.811us     157.058ms        10.01%     157.058ms       6.544ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     157.058ms        10.01%     157.058ms       6.544ms           0 B           0 B           0 B           0 B            24  \n",
      "## Call CompiledFxGraph fcic4wlffpggccscxm4q75zmwntb...         0.00%       0.000us         0.00%       0.000us       0.000us     136.954ms         8.73%     136.954ms     317.023us           0 B           0 B           0 B           0 B           432  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     124.278ms         7.92%     124.278ms       5.178ms           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     122.804ms         7.83%     122.804ms       5.117ms           0 B           0 B           0 B           0 B            24  \n",
      "triton_per_fused__softmax__to_copy_add_exp_mul_permu...         0.07%       1.749ms         0.12%       3.047ms      31.735us     107.425ms         6.85%     107.425ms       1.119ms           0 B           0 B           0 B           0 B            96  \n",
      "triton_per_fused__softmax__to_copy_add_exp_mul_permu...         0.00%       0.000us         0.00%       0.000us       0.000us     107.425ms         6.85%     107.425ms       1.119ms           0 B           0 B           0 B           0 B            96  \n",
      "## Call CompiledFxGraph fdkbgrpms2f5t2d5j54k3qxedfco...         0.00%       0.000us         0.00%       0.000us       0.000us      90.644ms         5.78%      90.644ms       3.777ms           0 B           0 B           0 B           0 B            24  \n",
      "                                            aten::fill_         0.53%      13.142ms         1.16%      28.787ms      14.372us      84.585ms         5.39%      84.585ms      42.229us           0 B           0 B           0 B           0 B          2003  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      81.566ms         5.20%      81.566ms       1.599ms           0 B           0 B           0 B           0 B            51  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.06%       1.466ms         0.09%       2.207ms      22.991us      78.554ms         5.01%      78.554ms     818.268us           0 B           0 B           0 B           0 B            96  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.00%       0.000us         0.00%       0.000us       0.000us      78.554ms         5.01%      78.554ms     818.268us           0 B           0 B           0 B           0 B            96  \n",
      "## Call CompiledFxGraph f645cim5xmpvm2377llczkw4xgxg...         0.00%       0.000us         0.00%       0.000us       0.000us      78.108ms         4.98%      78.108ms       3.255ms           0 B           0 B           0 B           0 B            24  \n",
      "## Call CompiledFxGraph fffrru2g3xvxsfxkqu75k4uerzlt...         0.00%       0.000us         0.00%       0.000us       0.000us      70.553ms         4.50%      70.553ms       2.940ms           0 B           0 B           0 B           0 B            24  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      65.863ms         4.20%      65.863ms     105.549us           0 B           0 B           0 B           0 B           624  \n",
      "          ampere_bf16_s16816gemm_bf16_64x64_ldg8_f2f_nn         0.00%       0.000us         0.00%       0.000us       0.000us      64.043ms         4.08%      64.043ms     333.558us           0 B           0 B           0 B           0 B           192  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      63.777ms         4.07%      63.777ms      91.633us           0 B           0 B           0 B           0 B           696  \n",
      "ampere_bf16_s16816gemm_bf16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      57.512ms         3.67%      57.512ms     299.541us           0 B           0 B           0 B           0 B           192  \n",
      "ampere_bf16_s1688gemm_bf16_128x128_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us      51.368ms         3.27%      51.368ms       2.140ms           0 B           0 B           0 B           0 B            24  \n",
      "## Call CompiledFxGraph fvingb54prth3cicubokrz6if6r2...         0.00%       0.000us         0.00%       0.000us       0.000us      51.368ms         3.27%      51.368ms       2.140ms           0 B           0 B           0 B           0 B            24  \n",
      "ampere_bf16_s16816gemm_bf16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      49.194ms         3.14%      49.194ms       2.050ms           0 B           0 B           0 B           0 B            24  \n",
      "                                 aten::_index_put_impl_         3.33%      82.615ms        12.99%     322.557ms     159.998us      46.102ms         2.94%      57.864ms      28.703us           0 B      -2.63 KB           0 B    -218.25 MB          2016  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us      41.365ms         2.64%      41.365ms       1.724ms           0 B           0 B           0 B           0 B            24  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      32.634ms         2.08%      32.634ms     113.312us           0 B           0 B           0 B           0 B           288  \n",
      "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us      31.638ms         2.02%      31.638ms      10.546ms           0 B           0 B           0 B           0 B             3  \n",
      "ampere_bf16_s16816gemm_bf16_64x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us      28.493ms         1.82%      28.493ms     296.798us           0 B           0 B           0 B           0 B            96  \n",
      "void cutlass::Kernel2<cutlass_75_tensorop_bf16_s1688...         0.00%       0.000us         0.00%       0.000us       0.000us      28.100ms         1.79%      28.100ms     234.171us           0 B           0 B           0 B           0 B           120  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us      24.091ms         1.54%      24.091ms       9.841us           0 B           0 B           0 B           0 B          2448  \n",
      "                                             aten::add_         1.81%      45.039ms         3.31%      82.316ms      15.806us      18.751ms         1.20%      18.751ms       3.600us         132 B      -1.46 KB           0 B           0 B          5208  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.870ms         1.01%      15.870ms       4.146us           0 B           0 B           0 B           0 B          3828  \n",
      "                                              aten::mul         2.62%      64.979ms         4.81%     119.572ms      28.449us      12.783ms         0.81%      13.915ms       3.311us       1.70 KB       1.70 KB       2.36 GB       2.36 GB          4203  \n",
      "## Call CompiledFxGraph fwq7bmxvx3unoa3vs5dubkrjrvoi...         0.00%       0.000us         0.00%       0.000us       0.000us      11.714ms         0.75%      11.714ms     162.690us           0 B           0 B           0 B           0 B            72  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.35%       8.611ms         0.47%      11.759ms      27.220us      11.491ms         0.73%      11.491ms      26.599us           0 B           0 B           0 B           0 B           432  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.00%       0.000us         0.00%       0.000us       0.000us      11.491ms         0.73%      11.491ms      26.599us           0 B           0 B           0 B           0 B           432  \n",
      "ampere_bf16_s1688gemm_bf16_64x128_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us      11.147ms         0.71%      11.147ms       8.763us           0 B           0 B           0 B           0 B          1272  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us      10.589ms         0.68%      10.589ms       8.325us           0 B           0 B           0 B           0 B          1272  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      10.145ms         0.65%      10.145ms       8.627us           0 B           0 B           0 B           0 B          1176  \n",
      "                                            aten::index         1.88%      46.670ms         3.08%      76.584ms      44.319us       9.987ms         0.64%       9.987ms       5.780us           0 B           0 B       1.27 GB       1.27 GB          1728  \n",
      "triton_per_fused__softmax__to_copy_exp_mul_permute_p...         0.28%       7.031ms         0.42%      10.401ms      24.076us       7.103ms         0.45%       7.103ms      16.443us           0 B           0 B           0 B           0 B           432  \n",
      "triton_per_fused__softmax__to_copy_exp_mul_permute_p...         0.00%       0.000us         0.00%       0.000us       0.000us       7.103ms         0.45%       7.103ms      16.443us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph f5k6hqiihurixgxoy2de5vpckw5n...         0.00%       0.000us         0.00%       0.000us       0.000us       6.726ms         0.43%       6.726ms     280.237us           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::vectorized_gather_kernel<16, long>(...         0.00%       0.000us         0.00%       0.000us       0.000us       6.694ms         0.43%       6.694ms       5.165us           0 B           0 B           0 B           0 B          1296  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       6.260ms         0.40%       6.260ms      14.491us           0 B           0 B           0 B           0 B           432  \n",
      "ampere_bf16_s1688gemm_bf16_64x128_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us       6.060ms         0.39%       6.060ms      11.476us           0 B           0 B           0 B           0 B           528  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.947ms         0.38%       5.947ms       7.509us           0 B           0 B           0 B           0 B           792  \n",
      "                                          aten::nonzero         0.91%      22.517ms         2.17%      53.825ms     124.594us       5.942ms         0.38%       5.942ms      13.754us           0 B           0 B      27.00 MB        -512 B           432  \n",
      "## Call CompiledFxGraph fdm6uat3bajwoljdrckudcw6tjbp...         0.00%       0.000us         0.00%       0.000us       0.000us       5.936ms         0.38%       5.936ms      82.438us           0 B           0 B           0 B           0 B            72  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       5.843ms         0.37%       5.843ms       1.188us           0 B           0 B           0 B           0 B          4920  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.307ms         0.34%       5.307ms      12.286us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph fctgmlmsbw224kqs77mhhq76ztq5...         0.00%       0.000us         0.00%       0.000us       0.000us       5.136ms         0.33%       5.136ms      71.327us           0 B           0 B           0 B           0 B            72  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       4.800ms         0.31%       4.800ms      11.111us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph fp4iuldgh7qj4cb4w4sp4av7iyaj...         0.00%       0.000us         0.00%       0.000us       0.000us       4.627ms         0.29%       4.627ms      64.260us           0 B           0 B           0 B           0 B            72  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.393ms         0.28%       4.393ms       5.085us           0 B           0 B           0 B           0 B           864  \n",
      "                                        aten::remainder         1.12%      27.770ms         1.57%      38.948ms      23.519us       4.227ms         0.27%       4.227ms       2.552us         960 B         960 B      51.75 MB      51.75 MB          1656  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.227ms         0.27%       4.227ms       2.552us           0 B           0 B           0 B           0 B          1656  \n",
      "triton_per_fused__fused_rms_norm_backward__to_copy_a...         0.32%       7.934ms         0.44%      11.000ms      25.464us       4.120ms         0.26%       4.120ms       9.537us           0 B           0 B           0 B           0 B           432  \n",
      "triton_per_fused__fused_rms_norm_backward__to_copy_a...         0.00%       0.000us         0.00%       0.000us       0.000us       4.120ms         0.26%       4.120ms       9.537us           0 B           0 B           0 B           0 B           432  \n",
      "            triton_poi_fused_embedding_dense_backward_2         0.01%     241.056us         0.02%     420.457us      17.519us       3.878ms         0.25%       3.878ms     161.589us           0 B           0 B           0 B           0 B            24  \n",
      "            triton_poi_fused_embedding_dense_backward_2         0.00%       0.000us         0.00%       0.000us       0.000us       3.878ms         0.25%       3.878ms     161.589us           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.798ms         0.24%       3.798ms       3.043us           0 B           0 B           0 B           0 B          1248  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us       3.669ms         0.23%       3.669ms       2.997us           0 B           0 B           0 B           0 B          1224  \n",
      "void cublasLt::splitKreduce_kernel<32, 16, int, __nv...         0.00%       0.000us         0.00%       0.000us       0.000us       3.403ms         0.22%       3.403ms       2.251us           0 B           0 B           0 B           0 B          1512  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.294ms         0.21%       3.294ms       7.624us           0 B           0 B           0 B           0 B           432  \n",
      "                                             aten::topk         0.11%       2.778ms         0.20%       4.975ms      69.098us       2.976ms         0.19%       2.976ms      41.333us           0 B           0 B      20.25 MB      20.25 MB            72  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       2.957ms         0.19%       2.957ms       3.734us           0 B           0 B           0 B           0 B           792  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.933ms         0.19%       2.933ms       1.560us           0 B           0 B           0 B           0 B          1880  \n",
      "                                             aten::div_         0.65%      16.171ms         1.03%      25.691ms      20.989us       2.808ms         0.18%       2.808ms       2.294us       1.16 KB       1.16 KB           0 B           0 B          1224  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.808ms         0.18%       2.808ms       2.294us           0 B           0 B           0 B           0 B          1224  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.789ms         0.18%       2.789ms       3.690us           0 B           0 B           0 B           0 B           756  \n",
      "triton_red_fused__fused_rms_norm_backward__to_copy_m...         0.21%       5.166ms         0.32%       8.047ms      18.628us       2.773ms         0.18%       2.773ms       6.420us           0 B           0 B           0 B           0 B           432  \n",
      "triton_red_fused__fused_rms_norm_backward__to_copy_m...         0.00%       0.000us         0.00%       0.000us       0.000us       2.773ms         0.18%       2.773ms       6.420us           0 B           0 B           0 B           0 B           432  \n",
      "            triton_poi_fused_embedding_dense_backward_0         0.02%     383.515us         0.03%     673.096us      28.046us       2.574ms         0.16%       2.574ms     107.229us           0 B           0 B           0 B           0 B            24  \n",
      "            triton_poi_fused_embedding_dense_backward_0         0.00%       0.000us         0.00%       0.000us       0.000us       2.574ms         0.16%       2.574ms     107.229us           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.532ms         0.16%       2.532ms       1.529us           0 B           0 B           0 B           0 B          1656  \n",
      "                                              aten::sum         0.26%       6.506ms         0.39%       9.621ms      22.270us       2.288ms         0.15%       2.288ms       5.295us           0 B           0 B       3.38 MB       3.38 MB           432  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       2.288ms         0.15%       2.288ms       5.295us           0 B           0 B           0 B           0 B           432  \n",
      "void at::native::sbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us       2.208ms         0.14%       2.208ms      30.661us           0 B           0 B           0 B           0 B            72  \n",
      "                                    aten::_foreach_mul_         0.06%       1.614ms         0.09%       2.196ms     183.029us       2.169ms         0.14%       2.169ms     180.781us           0 B           0 B           0 B           0 B            12  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.056ms         0.13%       2.056ms       4.758us           0 B           0 B           0 B           0 B           432  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.019ms         0.13%       2.019ms      10.516us           0 B           0 B           0 B           0 B           192  \n",
      "triton_poi_fused__to_copy__unsafe_view_split_with_si...         0.28%       6.874ms         0.44%      11.028ms      20.886us       2.010ms         0.13%       2.010ms       3.807us           0 B           0 B           0 B           0 B           528  \n",
      "triton_poi_fused__to_copy__unsafe_view_split_with_si...         0.00%       0.000us         0.00%       0.000us       0.000us       2.010ms         0.13%       2.010ms       3.807us           0 B           0 B           0 B           0 B           528  \n",
      "            triton_poi_fused__unsafe_view_add_squeeze_5         0.20%       4.921ms         0.42%      10.404ms      24.084us       1.877ms         0.12%       1.881ms       4.354us           0 B           0 B           0 B           0 B           432  \n",
      "            triton_poi_fused__unsafe_view_add_squeeze_5         0.00%       0.000us         0.00%       0.000us       0.000us       1.877ms         0.12%       1.877ms       4.344us           0 B           0 B           0 B           0 B           432  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us       1.875ms         0.12%       1.875ms       1.532us           0 B           0 B           0 B           0 B          1224  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.832ms         0.12%       1.832ms       4.241us           0 B           0 B           0 B           0 B           432  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       1.745ms         0.11%       1.745ms       4.040us           0 B           0 B           0 B           0 B           432  \n",
      "void at::native::(anonymous namespace)::write_indice...         0.00%       0.000us         0.00%       0.000us       0.000us       1.661ms         0.11%       1.661ms       3.845us           0 B           0 B           0 B           0 B           432  \n",
      "triton_poi_fused__to_copy__unsafe_view_cat_split_wit...         0.27%       6.590ms         0.42%      10.439ms      24.164us       1.625ms         0.10%       1.625ms       3.761us           0 B           0 B           0 B           0 B           432  \n",
      "triton_poi_fused__to_copy__unsafe_view_cat_split_wit...         0.00%       0.000us         0.00%       0.000us       0.000us       1.625ms         0.10%       1.625ms       3.761us           0 B           0 B           0 B           0 B           432  \n",
      "triton_poi_fused__to_copy_cat_permute_slice_squeeze_...         0.25%       6.196ms         0.39%       9.779ms      22.636us       1.617ms         0.10%       1.617ms       3.743us           0 B           0 B           0 B           0 B           432  \n",
      "triton_poi_fused__to_copy_cat_permute_slice_squeeze_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.617ms         0.10%       1.617ms       3.743us           0 B           0 B           0 B           0 B           432  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 2.484s\n",
      "Self CUDA time total: 1.569s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True,\n",
    "            profile_memory=True) as prof_inductor:\n",
    "    test_train('inductor')\n",
    "\n",
    "print(prof_inductor.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84e492cd-323d-4786-b33d-92605ca770dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                              aten::bmm         1.88%      85.357ms         2.55%     115.821ms      28.605us     362.953ms        23.14%     362.953ms      89.640us           0 B           0 B           0 B           0 B          4049  \n",
      "                                            aten::copy_         0.30%      13.632ms         2.33%     105.877ms      58.723us     250.610ms        15.98%     250.610ms     138.996us           0 B           0 B           0 B           0 B          1803  \n",
      "## Call CompiledFxGraph fe2dw25r4rvtemqmwyujb2x6u35c...         0.00%       0.000us         0.00%       0.000us       0.000us     243.298ms        15.51%     243.298ms     563.190us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph fbckvypgoyh5wlguxzkr73oq4ueu...         0.00%       0.000us         0.00%       0.000us       0.000us     227.594ms        14.51%     227.594ms       3.161ms           0 B           0 B           0 B           0 B            72  \n",
      "                                               aten::mm         2.48%     112.987ms         3.50%     159.307ms      34.943us     185.819ms        11.85%     185.819ms      40.759us           0 B           0 B           0 B           0 B          4559  \n",
      "## Call CompiledFxGraph fnoewiyynwx3wzjela47bplx2bny...         0.00%       0.000us         0.00%       0.000us       0.000us     183.005ms        11.67%     183.005ms       2.542ms           0 B           0 B           0 B           0 B            72  \n",
      "                       aten::_log_softmax_backward_data         0.01%     365.627us         0.01%     581.571us      24.232us     162.160ms        10.34%     162.160ms       6.757ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     162.160ms        10.34%     162.160ms       6.757ms           0 B           0 B           0 B           0 B            24  \n",
      "                                     aten::_log_softmax         0.01%     549.611us         0.02%     879.335us      36.639us     157.043ms        10.01%     157.043ms       6.543ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     157.043ms        10.01%     157.043ms       6.543ms           0 B           0 B           0 B           0 B            24  \n",
      "           _recursive_joint_graph_passes (dynamo_timed)         0.00%       0.000us         0.00%       0.000us       0.000us     152.663ms         9.73%     152.663ms     152.663ms           0 B           0 B           0 B           0 B             1  \n",
      "## Call CompiledFxGraph fcic4wlffpggccscxm4q75zmwntb...         0.00%       0.000us         0.00%       0.000us       0.000us     137.785ms         8.78%     137.785ms     318.946us           0 B           0 B           0 B           0 B           432  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     124.265ms         7.92%     124.265ms       5.178ms           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     122.802ms         7.83%     122.802ms       5.117ms           0 B           0 B           0 B           0 B            24  \n",
      "triton_per_fused__softmax__to_copy_add_exp_mul_permu...         0.04%       1.804ms         0.06%       2.647ms      27.571us     107.482ms         6.85%     107.482ms       1.120ms           0 B           0 B           0 B           0 B            96  \n",
      "triton_per_fused__softmax__to_copy_add_exp_mul_permu...         0.00%       0.000us         0.00%       0.000us       0.000us     107.482ms         6.85%     107.482ms       1.120ms           0 B           0 B           0 B           0 B            96  \n",
      "## Call CompiledFxGraph fdkbgrpms2f5t2d5j54k3qxedfco...         0.00%       0.000us         0.00%       0.000us       0.000us      90.614ms         5.78%      90.614ms       3.776ms           0 B           0 B           0 B           0 B            24  \n",
      "                                            aten::fill_         0.26%      11.843ms         0.57%      25.895ms      14.959us      84.066ms         5.36%      84.066ms      48.565us           0 B           0 B           0 B           0 B          1731  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      81.569ms         5.20%      81.569ms       1.599ms           0 B           0 B           0 B           0 B            51  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.03%       1.487ms         0.05%       2.256ms      23.501us      78.604ms         5.01%      78.604ms     818.790us           0 B           0 B           0 B           0 B            96  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.00%       0.000us         0.00%       0.000us       0.000us      78.604ms         5.01%      78.604ms     818.790us           0 B           0 B           0 B           0 B            96  \n",
      "## Call CompiledFxGraph f645cim5xmpvm2377llczkw4xgxg...         0.00%       0.000us         0.00%       0.000us       0.000us      78.273ms         4.99%      78.273ms       3.261ms           0 B           0 B           0 B           0 B            24  \n",
      "## Call CompiledFxGraph fffrru2g3xvxsfxkqu75k4uerzlt...         0.00%       0.000us         0.00%       0.000us       0.000us      68.876ms         4.39%      68.876ms       2.870ms           0 B           0 B           0 B           0 B            24  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      65.933ms         4.20%      65.933ms     105.663us           0 B           0 B           0 B           0 B           624  \n",
      "          ampere_bf16_s16816gemm_bf16_64x64_ldg8_f2f_nn         0.00%       0.000us         0.00%       0.000us       0.000us      63.982ms         4.08%      63.982ms     333.240us           0 B           0 B           0 B           0 B           192  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      63.761ms         4.07%      63.761ms      91.611us           0 B           0 B           0 B           0 B           696  \n",
      "ampere_bf16_s16816gemm_bf16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      57.504ms         3.67%      57.504ms     299.500us           0 B           0 B           0 B           0 B           192  \n",
      "ampere_bf16_s1688gemm_bf16_128x128_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us      51.219ms         3.27%      51.219ms       2.134ms           0 B           0 B           0 B           0 B            24  \n",
      "## Call CompiledFxGraph fvingb54prth3cicubokrz6if6r2...         0.00%       0.000us         0.00%       0.000us       0.000us      51.219ms         3.27%      51.219ms       2.134ms           0 B           0 B           0 B           0 B            24  \n",
      "ampere_bf16_s16816gemm_bf16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      49.177ms         3.14%      49.177ms       2.049ms           0 B           0 B           0 B           0 B            24  \n",
      "                                 aten::_index_put_impl_         1.83%      83.324ms         7.09%     322.498ms     159.969us      46.093ms         2.94%      57.850ms      28.696us           0 B      -2.32 KB           0 B    -218.25 MB          2016  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us      41.353ms         2.64%      41.353ms       1.723ms           0 B           0 B           0 B           0 B            24  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      33.029ms         2.11%      33.029ms     114.685us           0 B           0 B           0 B           0 B           288  \n",
      "ampere_bf16_s16816gemm_bf16_64x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us      28.511ms         1.82%      28.511ms     296.986us           0 B           0 B           0 B           0 B            96  \n",
      "void cutlass::Kernel2<cutlass_75_tensorop_bf16_s1688...         0.00%       0.000us         0.00%       0.000us       0.000us      28.107ms         1.79%      28.107ms     234.227us           0 B           0 B           0 B           0 B           120  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us      24.074ms         1.53%      24.074ms       9.834us           0 B           0 B           0 B           0 B          2448  \n",
      "                                             aten::add_         0.97%      43.928ms         1.80%      81.797ms      15.697us      18.744ms         1.20%      18.746ms       3.597us          80 B      -1.52 KB           0 B           0 B          5211  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      15.853ms         1.01%      15.853ms       4.141us           0 B           0 B           0 B           0 B          3828  \n",
      "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us      15.696ms         1.00%      15.696ms       5.232ms           0 B           0 B           0 B           0 B             3  \n",
      "                                              aten::mul         1.50%      68.060ms         2.68%     122.118ms      28.959us      12.772ms         0.81%      13.906ms       3.298us       1.52 KB       1.52 KB       2.36 GB       2.36 GB          4217  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.23%      10.441ms         0.30%      13.700ms      31.712us      11.515ms         0.73%      11.515ms      26.654us           0 B           0 B           0 B           0 B           432  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.00%       0.000us         0.00%       0.000us       0.000us      11.515ms         0.73%      11.515ms      26.654us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph fwq7bmxvx3unoa3vs5dubkrjrvoi...         0.00%       0.000us         0.00%       0.000us       0.000us      11.340ms         0.72%      11.340ms     157.501us           0 B           0 B           0 B           0 B            72  \n",
      "ampere_bf16_s1688gemm_bf16_64x128_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us      11.170ms         0.71%      11.170ms       8.781us           0 B           0 B           0 B           0 B          1272  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us      10.529ms         0.67%      10.529ms       8.277us           0 B           0 B           0 B           0 B          1272  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      10.112ms         0.64%      10.112ms       8.599us           0 B           0 B           0 B           0 B          1176  \n",
      "                                            aten::index         1.04%      47.266ms         1.75%      79.779ms      46.115us       9.998ms         0.64%       9.998ms       5.779us           0 B           0 B       1.27 GB       1.27 GB          1730  \n",
      "triton_per_fused__softmax__to_copy_exp_mul_permute_p...         0.15%       7.013ms         0.23%      10.363ms      23.987us       7.110ms         0.45%       7.110ms      16.458us           0 B           0 B           0 B           0 B           432  \n",
      "triton_per_fused__softmax__to_copy_exp_mul_permute_p...         0.00%       0.000us         0.00%       0.000us       0.000us       7.110ms         0.45%       7.110ms      16.458us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph f5k6hqiihurixgxoy2de5vpckw5n...         0.00%       0.000us         0.00%       0.000us       0.000us       6.720ms         0.43%       6.720ms     280.002us           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::vectorized_gather_kernel<16, long>(...         0.00%       0.000us         0.00%       0.000us       0.000us       6.706ms         0.43%       6.706ms       5.174us           0 B           0 B           0 B           0 B          1296  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       6.264ms         0.40%       6.264ms      14.501us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph fdm6uat3bajwoljdrckudcw6tjbp...         0.00%       0.000us         0.00%       0.000us       0.000us       6.132ms         0.39%       6.132ms      85.164us           0 B           0 B           0 B           0 B            72  \n",
      "ampere_bf16_s1688gemm_bf16_64x128_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us       6.080ms         0.39%       6.080ms      11.516us           0 B           0 B           0 B           0 B           528  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.958ms         0.38%       5.958ms       7.523us           0 B           0 B           0 B           0 B           792  \n",
      "                                          aten::nonzero         0.51%      23.008ms         1.27%      57.664ms     133.482us       5.916ms         0.38%       5.943ms      13.758us           0 B           0 B      27.00 MB           0 B           432  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       5.835ms         0.37%       5.835ms       1.186us           0 B           0 B           0 B           0 B          4920  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       5.305ms         0.34%       5.305ms      12.280us           0 B           0 B           0 B           0 B           432  \n",
      "## Call CompiledFxGraph fctgmlmsbw224kqs77mhhq76ztq5...         0.00%       0.000us         0.00%       0.000us       0.000us       5.130ms         0.33%       5.130ms      71.252us           0 B           0 B           0 B           0 B            72  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       4.805ms         0.31%       4.805ms      11.123us           0 B           0 B           0 B           0 B           432  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       4.389ms         0.28%       4.389ms       5.080us           0 B           0 B           0 B           0 B           864  \n",
      "## Call CompiledFxGraph fp4iuldgh7qj4cb4w4sp4av7iyaj...         0.00%       0.000us         0.00%       0.000us       0.000us       4.275ms         0.27%       4.275ms      59.380us           0 B           0 B           0 B           0 B            72  \n",
      "                                        aten::remainder         0.63%      28.478ms         0.87%      39.418ms      23.803us       4.229ms         0.27%       4.229ms       2.554us         824 B         824 B      51.75 MB      51.75 MB          1656  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.229ms         0.27%       4.229ms       2.554us           0 B           0 B           0 B           0 B          1656  \n",
      "triton_per_fused__fused_rms_norm_backward__to_copy_a...         0.17%       7.926ms         0.24%      11.053ms      25.585us       4.165ms         0.27%       4.165ms       9.642us           0 B           0 B           0 B           0 B           432  \n",
      "triton_per_fused__fused_rms_norm_backward__to_copy_a...         0.00%       0.000us         0.00%       0.000us       0.000us       4.165ms         0.27%       4.165ms       9.642us           0 B           0 B           0 B           0 B           432  \n",
      "            triton_poi_fused_embedding_dense_backward_2         0.01%     238.763us         0.01%     436.814us      18.201us       3.877ms         0.25%       3.877ms     161.537us           0 B           0 B           0 B           0 B            24  \n",
      "            triton_poi_fused_embedding_dense_backward_2         0.00%       0.000us         0.00%       0.000us       0.000us       3.877ms         0.25%       3.877ms     161.537us           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.793ms         0.24%       3.793ms       3.039us           0 B           0 B           0 B           0 B          1248  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us       3.663ms         0.23%       3.663ms       2.993us           0 B           0 B           0 B           0 B          1224  \n",
      "void cublasLt::splitKreduce_kernel<32, 16, int, __nv...         0.00%       0.000us         0.00%       0.000us       0.000us       3.392ms         0.22%       3.392ms       2.243us           0 B           0 B           0 B           0 B          1512  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.292ms         0.21%       3.292ms       7.621us           0 B           0 B           0 B           0 B           432  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       2.968ms         0.19%       2.968ms       3.747us           0 B           0 B           0 B           0 B           792  \n",
      "                                             aten::topk         0.10%       4.587ms         0.15%       6.943ms      92.569us       2.950ms         0.19%       2.950ms      39.331us           0 B           0 B      20.25 MB      20.25 MB            75  \n",
      "                                             aten::div_         0.36%      16.540ms         0.58%      26.173ms      21.383us       2.801ms         0.18%       2.801ms       2.288us       1.12 KB       1.12 KB           0 B           0 B          1224  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.801ms         0.18%       2.801ms       2.288us           0 B           0 B           0 B           0 B          1224  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.794ms         0.18%       2.794ms       3.696us           0 B           0 B           0 B           0 B           756  \n",
      "triton_red_fused__fused_rms_norm_backward__to_copy_m...         0.12%       5.274ms         0.22%      10.156ms      23.509us       2.781ms         0.18%       2.781ms       6.438us           0 B           0 B           0 B           0 B           432  \n",
      "triton_red_fused__fused_rms_norm_backward__to_copy_m...         0.00%       0.000us         0.00%       0.000us       0.000us       2.781ms         0.18%       2.781ms       6.438us           0 B           0 B           0 B           0 B           432  \n",
      "            triton_poi_fused_embedding_dense_backward_0         0.01%     350.760us         0.01%     632.356us      26.348us       2.571ms         0.16%       2.571ms     107.118us           0 B           0 B           0 B           0 B            24  \n",
      "            triton_poi_fused_embedding_dense_backward_0         0.00%       0.000us         0.00%       0.000us       0.000us       2.571ms         0.16%       2.571ms     107.118us           0 B           0 B           0 B           0 B            24  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.529ms         0.16%       2.529ms       1.527us           0 B           0 B           0 B           0 B          1656  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.410ms         0.15%       2.410ms       1.498us           0 B           0 B           0 B           0 B          1608  \n",
      "                                              aten::sum         0.14%       6.547ms         0.21%       9.440ms      21.853us       2.296ms         0.15%       2.296ms       5.315us           0 B           0 B       3.38 MB       3.38 MB           432  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       2.296ms         0.15%       2.296ms       5.315us           0 B           0 B           0 B           0 B           432  \n",
      "void at::native::sbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us       2.180ms         0.14%       2.180ms      30.283us           0 B           0 B           0 B           0 B            72  \n",
      "                                    aten::_foreach_mul_         0.03%       1.372ms         0.04%       1.950ms     162.502us       2.170ms         0.14%       2.170ms     180.829us           0 B           0 B           0 B           0 B            12  \n",
      "triton_poi_fused__to_copy__unsafe_view_split_with_si...         0.16%       7.088ms         0.25%      11.333ms      21.464us       2.070ms         0.13%       2.070ms       3.921us           0 B           0 B           0 B           0 B           528  \n",
      "triton_poi_fused__to_copy__unsafe_view_split_with_si...         0.00%       0.000us         0.00%       0.000us       0.000us       2.070ms         0.13%       2.070ms       3.921us           0 B           0 B           0 B           0 B           528  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.062ms         0.13%       2.062ms       4.773us           0 B           0 B           0 B           0 B           432  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.015ms         0.13%       2.015ms      10.494us           0 B           0 B           0 B           0 B           192  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us       1.875ms         0.12%       1.875ms       1.532us           0 B           0 B           0 B           0 B          1224  \n",
      "            triton_poi_fused__unsafe_view_add_squeeze_5         0.11%       4.877ms         0.17%       7.823ms      18.109us       1.873ms         0.12%       1.873ms       4.336us           0 B           0 B           0 B           0 B           432  \n",
      "            triton_poi_fused__unsafe_view_add_squeeze_5         0.00%       0.000us         0.00%       0.000us       0.000us       1.873ms         0.12%       1.873ms       4.336us           0 B           0 B           0 B           0 B           432  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.851ms         0.12%       1.851ms       4.059us           0 B           0 B           0 B           0 B           456  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       1.746ms         0.11%       1.746ms       4.041us           0 B           0 B           0 B           0 B           432  \n",
      "void at::native::(anonymous namespace)::write_indice...         0.00%       0.000us         0.00%       0.000us       0.000us       1.658ms         0.11%       1.658ms       3.838us           0 B           0 B           0 B           0 B           432  \n",
      "triton_poi_fused__to_copy_cat_permute_slice_squeeze_...         0.14%       6.190ms         0.22%       9.891ms      22.895us       1.647ms         0.11%       1.647ms       3.812us           0 B           0 B           0 B           0 B           432  \n",
      "triton_poi_fused__to_copy_cat_permute_slice_squeeze_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.647ms         0.11%       1.647ms       3.812us           0 B           0 B           0 B           0 B           432  \n",
      "triton_poi_fused__to_copy__unsafe_view_cat_split_wit...         0.14%       6.593ms         0.23%      10.532ms      24.379us       1.614ms         0.10%       1.614ms       3.737us           0 B           0 B           0 B           0 B           432  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 4.551s\n",
      "Self CUDA time total: 1.568s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True,\n",
    "            profile_memory=True) as prof_inductor:\n",
    "    test_train('inductor')\n",
    "\n",
    "print(prof_inductor.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa750ff-1f80-4c3e-bbb3-e94b0cbecfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::copy_         3.54%     212.499ms         9.56%     573.137ms      53.479us     471.169ms        26.52%     472.052ms      44.047us           0 B           0 B           0 B           0 B         10717  \n",
      "                                              aten::bmm         2.20%     132.064ms         2.67%     160.118ms      39.380us     241.520ms        13.59%     243.118ms      59.793us           0 B           0 B      42.30 GB      42.30 GB          4066  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     220.649ms        12.42%     220.649ms     223.329us           0 B           0 B           0 B           0 B           988  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     212.835ms        11.98%     212.835ms     101.884us           0 B           0 B           0 B           0 B          2089  \n",
      "                                              aten::mul         2.24%     134.402ms         3.49%     209.241ms      31.230us     209.566ms        11.79%     210.743ms      31.454us       1.25 KB       1.28 KB      57.56 GB      57.55 GB          6700  \n",
      "                                               aten::mm         4.77%     286.119ms         6.62%     396.804ms      71.976us     132.552ms         7.46%     138.728ms      25.164us           0 B           0 B      23.90 GB      23.90 GB          5513  \n",
      "                                     aten::_log_softmax         0.01%     592.705us         0.02%       1.027ms      42.779us     117.757ms         6.63%     124.297ms       5.179ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     117.757ms         6.63%     117.757ms       6.542ms           0 B           0 B           0 B           0 B            18  \n",
      "                           aten::_softmax_backward_data         0.20%      12.142ms         0.67%      40.371ms      67.285us     115.586ms         6.50%     242.221ms     403.701us           0 B           0 B      27.40 GB      -3.37 GB           600  \n",
      "                       aten::_log_softmax_backward_data         0.01%     447.680us         0.01%     618.501us      25.771us     108.120ms         6.08%     108.120ms       4.505ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     108.120ms         6.08%     108.120ms       6.758ms           0 B           0 B           0 B           0 B            16  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     101.044ms         5.69%     101.044ms     962.324us           0 B           0 B           0 B           0 B           105  \n",
      "void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us     100.643ms         5.66%     100.643ms       1.677ms           0 B           0 B           0 B           0 B            60  \n",
      "                                         aten::_softmax         0.54%      32.293ms         0.90%      54.123ms      88.291us      98.708ms         5.55%     111.774ms     182.340us           0 B           0 B      27.39 GB      24.02 GB           613  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      86.202ms         4.85%      86.202ms       1.134ms           0 B           0 B           0 B           0 B            76  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      82.040ms         4.62%      82.040ms     109.387us           0 B           0 B           0 B           0 B           750  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      78.852ms         4.44%      78.852ms      21.010us           0 B           0 B           0 B           0 B          3753  \n",
      "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us      66.985ms         3.77%      66.985ms      33.492ms           0 B           0 B           0 B           0 B             2  \n",
      "                                              aten::add         0.54%      32.535ms         0.83%      49.752ms      49.554us      66.491ms         3.74%      67.323ms      67.055us           0 B           0 B      12.80 GB      12.80 GB          1004  \n",
      "                                             aten::add_         1.26%      75.846ms         1.81%     108.690ms      17.065us      61.562ms         3.46%      62.179ms       9.763us          68 B      -1.53 KB           0 B           0 B          6369  \n",
      "                                            aten::fill_         0.44%      26.181ms         0.68%      40.892ms      17.298us      57.619ms         3.24%      57.625ms      24.376us           0 B           0 B           0 B           0 B          2364  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      54.433ms         3.06%      54.433ms     672.007us           0 B           0 B           0 B           0 B            81  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      48.729ms         2.74%      48.729ms      87.959us           0 B           0 B           0 B           0 B           554  \n",
      "          ampere_bf16_s16816gemm_bf16_64x64_ldg8_f2f_nn         0.00%       0.000us         0.00%       0.000us       0.000us      44.261ms         2.49%      44.261ms     325.452us           0 B           0 B           0 B           0 B           136  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      41.658ms         2.34%      41.658ms     105.463us           0 B           0 B           0 B           0 B           395  \n",
      "ampere_bf16_s16816gemm_bf16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      40.625ms         2.29%      40.625ms     298.710us           0 B           0 B           0 B           0 B           136  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      39.597ms         2.23%      39.597ms      89.993us           0 B           0 B           0 B           0 B           440  \n",
      "ampere_bf16_s1688gemm_bf16_128x128_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us      37.121ms         2.09%      37.121ms       2.062ms           0 B           0 B           0 B           0 B            18  \n",
      "ampere_bf16_s16816gemm_bf16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      32.771ms         1.84%      32.771ms       2.048ms           0 B           0 B           0 B           0 B            16  \n",
      "                                 aten::_index_put_impl_         2.28%     136.453ms         6.94%     416.085ms     206.391us      29.643ms         1.67%      37.161ms      18.433us           0 B      -1.93 KB           0 B    -218.25 MB          2016  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us      27.611ms         1.55%      27.611ms       1.726ms           0 B           0 B           0 B           0 B            16  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      22.568ms         1.27%      22.568ms      23.831us           0 B           0 B           0 B           0 B           947  \n",
      "void cutlass::Kernel2<cutlass_75_tensorop_bf16_s1688...         0.00%       0.000us         0.00%       0.000us       0.000us      22.255ms         1.25%      22.255ms     234.259us           0 B           0 B           0 B           0 B            95  \n",
      "                                  Lazy Function Loading         0.21%      12.633ms         0.21%      12.633ms      27.110us      21.240ms         1.20%      21.240ms      45.580us           0 B           0 B           0 B           0 B           466  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      20.505ms         1.15%      20.505ms     104.619us           0 B           0 B           0 B           0 B           196  \n",
      "ampere_bf16_s16816gemm_bf16_64x64_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us      17.484ms         0.98%      17.484ms     291.394us           0 B           0 B           0 B           0 B            60  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us      16.225ms         0.91%      16.225ms       9.647us           0 B           0 B           0 B           0 B          1682  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      15.840ms         0.89%      15.840ms      57.600us           0 B           0 B           0 B           0 B           275  \n",
      "void (anonymous namespace)::softmax_warp_backward<fl...         0.00%       0.000us         0.00%       0.000us       0.000us      14.860ms         0.84%      14.860ms      54.037us           0 B           0 B           0 B           0 B           275  \n",
      "                         aten::_fused_rms_norm_backward         0.33%      19.821ms         0.80%      47.968ms      57.105us      13.773ms         0.78%      14.624ms      17.410us           0 B           0 B     696.41 MB     -72.00 MB           840  \n",
      "void (anonymous namespace)::softmax_warp_forward<flo...         0.00%       0.000us         0.00%       0.000us       0.000us      12.381ms         0.70%      12.381ms      36.740us           0 B           0 B           0 B           0 B           337  \n",
      "                                              aten::cat         0.57%      34.177ms         0.77%      45.978ms      30.754us      11.949ms         0.67%      11.966ms       8.004us           0 B           0 B       2.63 GB       2.63 GB          1495  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      11.713ms         0.66%      11.713ms      11.597us           0 B           0 B           0 B           0 B          1010  \n",
      "void at::native::(anonymous namespace)::GammaBetaBac...         0.00%       0.000us         0.00%       0.000us       0.000us       9.242ms         0.52%       9.242ms      17.406us           0 B           0 B           0 B           0 B           531  \n",
      "                                  aten::_fused_rms_norm         1.10%      66.127ms         2.53%     151.782ms     117.206us       8.173ms         0.46%       9.873ms       7.624us           0 B           0 B     823.88 MB    -156.00 MB          1295  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us       8.173ms         0.46%       8.173ms       8.197us           0 B           0 B           0 B           0 B           997  \n",
      "ampere_bf16_s1688gemm_bf16_64x128_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us       7.493ms         0.42%       7.493ms       9.977us           0 B           0 B           0 B           0 B           751  \n",
      "                                            aten::index         0.95%      56.934ms         1.34%      80.594ms      46.640us       7.443ms         0.42%       7.450ms       4.311us           0 B           0 B       1.27 GB       1.27 GB          1728  \n",
      "ampere_bf16_s1688gemm_bf16_64x128_sliced1x2_ldg8_f2f...         0.00%       0.000us         0.00%       0.000us       0.000us       7.124ms         0.40%       7.124ms       8.817us           0 B           0 B           0 B           0 B           808  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       7.120ms         0.40%       7.120ms       5.046us           0 B           0 B           0 B           0 B          1411  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       7.097ms         0.40%       7.097ms       8.291us           0 B           0 B           0 B           0 B           856  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us       6.693ms         0.38%       6.693ms       8.283us           0 B           0 B           0 B           0 B           808  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       5.955ms         0.34%       5.955ms       5.399us           0 B           0 B           0 B           0 B          1103  \n",
      "void at::native::vectorized_gather_kernel<16, long>(...         0.00%       0.000us         0.00%       0.000us       0.000us       5.011ms         0.28%       5.011ms       5.165us           0 B           0 B           0 B           0 B           970  \n",
      "                                          aten::nonzero         0.44%      26.574ms         0.95%      57.075ms     132.119us       4.632ms         0.26%       4.735ms      10.960us           0 B           0 B      27.00 MB           0 B           432  \n",
      "void at::native::(anonymous namespace)::layer_norm_g...         0.00%       0.000us         0.00%       0.000us       0.000us       4.530ms         0.25%       4.530ms       8.531us           0 B           0 B           0 B           0 B           531  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       4.265ms         0.24%       4.265ms       7.522us           0 B           0 B           0 B           0 B           567  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       4.215ms         0.24%       4.215ms      12.508us           0 B           0 B           0 B           0 B           337  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       3.856ms         0.22%       3.856ms      14.022us           0 B           0 B           0 B           0 B           275  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us       3.700ms         0.21%       3.700ms       1.125us           0 B           0 B           0 B           0 B          3290  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       3.477ms         0.20%       3.477ms      10.318us           0 B           0 B           0 B           0 B           337  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.261ms         0.18%       3.261ms       2.666us           0 B           0 B           0 B           0 B          1223  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.118ms         0.18%       3.118ms       2.087us           0 B           0 B           0 B           0 B          1494  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.070ms         0.17%       3.070ms       5.008us           0 B           0 B           0 B           0 B           613  \n",
      "                                        aten::remainder         0.80%      47.805ms         0.97%      58.087ms      35.077us       2.703ms         0.15%       2.703ms       1.632us         680 B         680 B      51.75 MB      51.75 MB          1656  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.703ms         0.15%       2.703ms       2.557us           0 B           0 B           0 B           0 B          1057  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.636ms         0.15%       2.636ms       5.572us           0 B           0 B           0 B           0 B           473  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.539ms         0.14%       2.539ms       7.535us           0 B           0 B           0 B           0 B           337  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       2.431ms         0.14%       2.431ms       5.871us           0 B           0 B           0 B           0 B           414  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us       2.418ms         0.14%       2.418ms       3.038us           0 B           0 B           0 B           0 B           796  \n",
      "                                             aten::topk         0.21%      12.528ms         0.62%      37.047ms     481.131us       2.321ms         0.13%       2.484ms      32.265us           0 B           0 B      20.25 MB      20.25 MB            77  \n",
      "void cublasLt::splitKreduce_kernel<32, 16, int, __nv...         0.00%       0.000us         0.00%       0.000us       0.000us       2.144ms         0.12%       2.144ms       2.238us           0 B           0 B           0 B           0 B           958  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       1.880ms         0.11%       1.880ms       3.723us           0 B           0 B           0 B           0 B           505  \n",
      "                                             aten::div_         0.47%      27.958ms         0.61%      36.289ms      29.648us       1.794ms         0.10%       1.794ms       1.466us       1.02 KB       1.02 KB           0 B           0 B          1224  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.794ms         0.10%       1.794ms       2.298us           0 B           0 B           0 B           0 B           781  \n",
      "void at::native::sbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us       1.725ms         0.10%       1.725ms      30.256us           0 B           0 B           0 B           0 B            57  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.613ms         0.09%       1.613ms       1.526us           0 B           0 B           0 B           0 B          1057  \n",
      "                         aten::embedding_dense_backward         0.20%      11.823ms         0.33%      19.909ms     829.527us       1.563ms         0.09%       2.374ms      98.918us           0 B           0 B     600.00 MB     -58.15 MB            24  \n",
      "                                              aten::sum         0.31%      18.606ms         0.38%      22.894ms      52.995us       1.456ms         0.08%       1.456ms       3.371us           0 B           0 B       3.38 MB       3.38 MB           432  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.456ms         0.08%       1.456ms       5.276us           0 B           0 B           0 B           0 B           276  \n",
      "                                    aten::_foreach_mul_         0.15%       8.906ms         0.19%      11.391ms     949.255us       1.441ms         0.08%       1.917ms     159.709us           0 B           0 B           0 B           0 B            12  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us       1.425ms         0.08%       1.425ms      10.480us           0 B           0 B           0 B           0 B           136  \n",
      "void at::native::(anonymous namespace)::write_indice...         0.00%       0.000us         0.00%       0.000us       0.000us       1.300ms         0.07%       1.300ms       3.845us           0 B           0 B           0 B           0 B           338  \n",
      "void at_cuda_detail::cub::detail::select::DeviceSele...         0.00%       0.000us         0.00%       0.000us       0.000us       1.248ms         0.07%       1.248ms       3.692us           0 B           0 B           0 B           0 B           338  \n",
      "void at_cuda_detail::cub::detail::radix_sort::Device...         0.00%       0.000us         0.00%       0.000us       0.000us       1.217ms         0.07%       1.217ms       1.529us           0 B           0 B           0 B           0 B           796  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.117ms         0.06%       1.117ms       4.858us           0 B           0 B           0 B           0 B           230  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us       1.116ms         0.06%       1.116ms       4.042us           0 B           0 B           0 B           0 B           276  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     975.165us         0.05%     975.165us      97.516us           0 B           0 B           0 B           0 B            10  \n",
      "                                           aten::arange         0.35%      21.207ms         1.07%      64.124ms      25.670us     950.942us         0.05%       1.902ms       0.761us           0 B           0 B      78.00 MB           0 B          2498  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us     950.942us         0.05%     950.942us       1.195us           0 B           0 B           0 B           0 B           796  \n",
      "void cutlass::Kernel2<cutlass_75_tensorop_bf16_s1688...         0.00%       0.000us         0.00%       0.000us       0.000us     936.482us         0.05%     936.482us      24.644us           0 B           0 B           0 B           0 B            38  \n",
      "                                aten::_foreach_addcdiv_         0.01%     798.745us         0.02%       1.145ms     190.785us     923.804us         0.05%       1.384ms     230.703us           0 B           0 B           0 B           0 B             6  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     923.804us         0.05%     923.804us     115.476us           0 B           0 B           0 B           0 B             8  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us     805.752us         0.05%     805.752us       7.674us           0 B           0 B           0 B           0 B           105  \n",
      "                                aten::_foreach_addcmul_         0.06%       3.486ms         0.08%       4.600ms     766.718us     730.431us         0.04%       1.097ms     182.837us           0 B           0 B           0 B           0 B             6  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     730.431us         0.04%     730.431us      91.304us           0 B           0 B           0 B           0 B             8  \n",
      "                                   aten::_foreach_lerp_         0.02%       1.316ms         0.03%       1.839ms     306.562us     716.382us         0.04%       1.070ms     178.351us           0 B           0 B           0 B           0 B             6  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     716.382us         0.04%     716.382us     119.397us           0 B           0 B           0 B           0 B             6  \n",
      "                                               aten::eq         0.34%      20.503ms         0.42%      25.286ms      58.533us     655.932us         0.04%     657.500us       1.522us           0 B           0 B      10.12 MB      10.12 MB           432  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     655.932us         0.04%     655.932us       1.941us           0 B           0 B           0 B           0 B           338  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 5.996s\n",
      "Self CUDA time total: 1.777s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, record_function\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True,\n",
    "            profile_memory=True) as prof_eager:\n",
    "    test_train('eager')\n",
    "\n",
    "print(prof_eager.key_averages().table(sort_by=\"self_cuda_time_total\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4820353a-c2be-42b9-86fd-fab8b8023e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "avgs = prof_inductor.key_averages()\n",
    "\n",
    "data_to_print = []\n",
    "for evt in avgs:\n",
    "    data_to_print.append(evt.__dict__)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad93b2b8-a468-4323-b0bf-cedf2d6496c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_print = pd.DataFrame(data_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3a4e3e2-a0ef-4d03-b62a-c00cd0e284e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'count', 'node_id', 'is_async', 'is_remote', 'use_device',\n",
       "       'cpu_time_total', 'device_time_total', 'self_cpu_time_total',\n",
       "       'self_device_time_total', 'input_shapes', 'overload_name', 'stack',\n",
       "       'scope', 'cpu_memory_usage', 'device_memory_usage',\n",
       "       'self_cpu_memory_usage', 'self_device_memory_usage', 'cpu_children',\n",
       "       'cpu_parent', 'device_type', 'is_legacy', 'flops',\n",
       "       'is_user_annotation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_print.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dda9b8a9-1b30-4358-9fb0-922adacbb77b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['aten::empty_strided', 0.0, 61057961984],\n",
       "       ['aten::nll_loss_backward', 275.1339999999618, 40265318400],\n",
       "       ['## Call CompiledFxGraph fnoewiyynwx3wzjela47bplx2bny6edpp5rrhvetmp53cdzwa3tj ##',\n",
       "        0.0, 20413087744],\n",
       "       ['aten::_log_softmax', 157057.79300000006, 20132659200],\n",
       "       ['## Call CompiledFxGraph fvingb54prth3cicubokrz6if6r2fwc6l2igx73frkvw3p4ju3om ##',\n",
       "        0.0, 20132659200],\n",
       "       ['aten::_log_softmax_backward_data', 162181.84599999932,\n",
       "        20132659200],\n",
       "       ['## Call CompiledFxGraph fffrru2g3xvxsfxkqu75k4uerzltzs3m3r5ovkz3qiprlekdbcfx ##',\n",
       "        0.0, 7028539392],\n",
       "       ['## Call CompiledFxGraph fe2dw25r4rvtemqmwyujb2x6u35c34covu4sfukjwcvvzkldo3n2 ##',\n",
       "        0.0, 5593890816],\n",
       "       ['aten::mul', 12783.020999987377, 2528683520],\n",
       "       ['aten::index', 9987.224999997532, 1362493440],\n",
       "       ['aten::empty', 0.0, 1360178688],\n",
       "       ['## Call CompiledFxGraph f5k6hqiihurixgxoy2de5vpckw5nbbhv5alpsnuext4atlmj42vb ##',\n",
       "        0.0, 629669888],\n",
       "       ['## Call CompiledFxGraph fdkbgrpms2f5t2d5j54k3qxedfcomflh5clfbvrlgbohzlyeow3t ##',\n",
       "        0.0, 629145600],\n",
       "       ['## Call CompiledFxGraph fwq7bmxvx3unoa3vs5dubkrjrvoitezsseh2zvclpddqvvvmi7lc ##',\n",
       "        0.0, 301989888],\n",
       "       ['aten::add', 638.5309999992605, 154535424],\n",
       "       ['## Call CompiledFxGraph fp4iuldgh7qj4cb4w4sp4av7iyajnx4xdzx4wuvehtnhjqmmlqxo ##',\n",
       "        0.0, 90832896],\n",
       "       ['## Call CompiledFxGraph f2gwcspqzvom6tqizru2oaiyglsrdhh2mvfrwxwultkaeru63c5g ##',\n",
       "        0.0, 75497472],\n",
       "       ['aten::resize_', 0.0, 68419584],\n",
       "       ['aten::remainder', 4226.680000006687, 54263808],\n",
       "       ['## Call CompiledFxGraph fqyocsbiqfw7ftgoio2e7zcbk7jlgrt65rnqqvfchr47344nvzk4 ##',\n",
       "        0.0, 25559040],\n",
       "       ['## Call CompiledFxGraph fgpnt6ridlpt3xyzerrevzfyadeaapircz5xfuzdxpoitofynmtz ##',\n",
       "        0.0, 25165824],\n",
       "       ['aten::topk', 2975.9619999963325, 21233664],\n",
       "       ['aten::eq', 836.6119999976363, 10616832],\n",
       "       ['aten::sum', 2287.616000000504, 3538944],\n",
       "       ['Buffer Flush', 0.0, 1351680],\n",
       "       ['cudaPointerGetAttributes', 0.0, 983552],\n",
       "       ['aten::nll_loss_forward', 436.0939999993425, 24576],\n",
       "       ['aten::div', 78.07699999888428, 24576],\n",
       "       ['aten::clamp', 4.7679999999236315, 1536],\n",
       "       ['aten::cat', 13.856999999145046, 1536]], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_print[['key','self_device_time_total', 'self_device_memory_usage']].sort_values('self_device_memory_usage', ascending=False).head(30).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d1ad6eb-3764-4efb-86d0-2c6e318a85ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.11087872)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_print['self_device_memory_usage'].sum()/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d12cc953-e9bc-489e-8c6e-71bac7a40fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "       InductorBenchmarker.benchmark_gpu (dynamo_timed)         0.00%       0.000us         0.00%       0.000us       0.000us        3.189s       153.52%        3.189s      18.542ms           0 B           0 B           0 B           0 B           172  \n",
      "       InductorBenchmarker.benchmark_gpu (dynamo_timed)         6.57%        1.609s        14.27%        3.496s      20.323ms       0.000us         0.00%        1.064s       6.187ms           0 B           0 B       8.12 MB     -37.31 GB           172  \n",
      "autograd::engine::evaluate_function: CompiledFunctio...         0.06%      14.130ms        32.12%        7.868s       9.643ms       0.000us         0.00%     796.063ms     975.567us           0 B           0 B     -49.14 GB     -19.53 GB           816  \n",
      "                               CompiledFunctionBackward         0.38%      94.181ms        32.06%        7.852s       9.623ms       0.000us         0.00%     795.930ms     975.404us           0 B           0 B     -29.69 GB           0 B           816  \n",
      "CachingAutotuner.benchmark_all_configs (dynamo_timed...         0.13%      33.046ms         9.64%        2.361s      42.931ms       0.000us         0.00%     651.317ms      11.842ms           0 B           0 B           0 B           0 B            55  \n",
      "## Call CompiledFxGraph fbckvypgoyh5wlguxzkr73oq4ueu...         0.00%       0.000us         0.00%       0.000us       0.000us     620.432ms        29.87%     620.432ms      11.931ms           0 B           0 B           0 B           0 B            52  \n",
      "                                            aten::fill_         1.15%     281.216ms         2.21%     542.265ms      13.936us     540.872ms        26.04%     540.894ms      13.900us           0 B           0 B           0 B           0 B         38912  \n",
      "                                            aten::zero_         1.06%     258.887ms         3.02%     739.775ms      19.620us       0.000us         0.00%     536.525ms      14.230us           0 B           0 B           0 B           0 B         37705  \n",
      "           _recursive_joint_graph_passes (dynamo_timed)         0.00%       0.000us         0.00%       0.000us       0.000us     494.902ms        23.82%     494.902ms      98.980ms           0 B           0 B           0 B           0 B             5  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     473.090ms        22.77%     473.090ms      13.466us           0 B           0 B           0 B           0 B         35131  \n",
      "## Call CompiledFxGraph f645cim5xmpvm2377llczkw4xgxg...         0.00%       0.000us         0.00%       0.000us       0.000us     469.229ms        22.59%     469.229ms      27.602ms           0 B           0 B           0 B           0 B            17  \n",
      "## Call CompiledFxGraph fffrru2g3xvxsfxkqu75k4uerzlt...         0.00%       0.000us         0.00%       0.000us       0.000us     465.765ms        22.42%     465.765ms      25.876ms           0 B           0 B           0 B           0 B            18  \n",
      "                                       CompiledFunction         0.27%      67.076ms         6.25%        1.531s       1.876ms       0.000us         0.00%     438.586ms     537.483us           0 B           0 B      50.53 GB           0 B           816  \n",
      "                                              aten::bmm         0.83%     202.233ms         1.31%     320.859ms      60.517us     429.810ms        20.69%     431.770ms      81.435us           0 B           0 B      21.64 GB      21.64 GB          5302  \n",
      "                  _compile.compile_inner (dynamo_timed)         0.05%      12.289ms        55.10%       13.496s        1.227s       0.000us         0.00%     414.151ms      37.650ms          32 B      -4.95 KB       8.12 MB           0 B            11  \n",
      "                       compile_attempt_0 (dynamo_timed)         0.20%      49.980ms        41.39%       10.138s     921.670ms       0.000us         0.00%     414.139ms      37.649ms      14.90 KB      19.81 KB       8.12 MB           0 B            11  \n",
      "          OutputGraph.call_user_compiler (dynamo_timed)         1.80%     440.982ms        48.96%       11.992s        1.332s       0.000us         0.00%     414.139ms      46.015ms      -4.98 KB           0 B       8.12 MB           0 B             9  \n",
      "          create_aot_dispatcher_function (dynamo_timed)         0.47%     114.911ms        46.52%       11.394s        1.266s       0.000us         0.00%     414.139ms      46.015ms      -4.98 KB     -44.58 KB       8.12 MB           0 B             9  \n",
      "           _recursive_joint_graph_passes (dynamo_timed)         3.76%     920.970ms         9.55%        2.339s     259.879ms       0.000us         0.00%     413.797ms      45.977ms      -4.98 KB      -5.04 KB       8.12 MB     -29.00 KB             9  \n",
      "                        pad_mm_benchmark (dynamo_timed)         0.37%      90.356ms         5.26%        1.288s      15.334ms       0.000us         0.00%     413.726ms       4.925ms           0 B           0 B       8.12 MB    -297.09 MB            84  \n",
      "## Call CompiledFxGraph fe2dw25r4rvtemqmwyujb2x6u35c...         0.00%       0.000us         0.00%       0.000us       0.000us     346.602ms        16.68%     346.602ms       1.100ms           0 B           0 B           0 B           0 B           315  \n",
      "                             Torch-Compiled Region: 2/1         0.05%      11.486ms        20.75%        5.082s      70.589ms       0.000us         0.00%     310.267ms       4.309ms          16 B           0 B      25.47 GB     -72.00 MB            72  \n",
      "## Call CompiledFxGraph fcic4wlffpggccscxm4q75zmwntb...         0.00%       0.000us         0.00%       0.000us       0.000us     274.982ms        13.24%     274.982ms     881.352us           0 B           0 B           0 B           0 B           312  \n",
      "## Call CompiledFxGraph fbckvypgoyh5wlguxzkr73oq4ueu...         0.28%      68.379ms         2.59%     635.325ms       8.824ms       0.000us         0.00%     270.908ms       3.763ms           0 B           0 B     -19.02 GB     -19.09 GB            72  \n",
      "                                            aten::copy_         0.38%      93.039ms         0.90%     220.671ms      33.939us     250.601ms        12.06%     255.726ms      39.330us           0 B           0 B           0 B           0 B          6502  \n",
      "## Call CompiledFxGraph fnoewiyynwx3wzjela47bplx2bny...         0.00%       0.000us         0.00%       0.000us       0.000us     220.682ms        10.62%     220.682ms       4.164ms           0 B           0 B           0 B           0 B            53  \n",
      "                               aten::cross_entropy_loss         0.00%     239.907us         0.13%      32.888ms       1.370ms       0.000us         0.00%     210.213ms       8.759ms           0 B           0 B      56.25 GB           0 B            24  \n",
      "                                               aten::to         0.18%      44.854ms         2.13%     521.947ms     148.407us       0.000us         0.00%     185.670ms      52.792us      11.16 KB           0 B      56.25 GB           0 B          3517  \n",
      "                                         aten::_to_copy         0.47%     115.279ms         1.95%     477.093ms     418.870us       0.000us         0.00%     185.670ms     163.011us      11.16 KB           0 B      56.25 GB           0 B          1139  \n",
      "                             Torch-Compiled Region: 3/0         0.29%      69.831ms        15.76%        3.861s      53.618ms       0.000us         0.00%     175.874ms       2.443ms           8 B      -9.00 KB       6.38 GB   -1017.51 MB            72  \n",
      "                                               aten::mm         1.51%     370.623ms         2.46%     603.608ms      92.154us     164.849ms         7.94%     169.586ms      25.891us           0 B           0 B       1.71 GB       1.71 GB          6550  \n",
      "## Call CompiledFxGraph f645cim5xmpvm2377llczkw4xgxg...         0.12%      28.371ms         1.91%     468.796ms      19.533ms       0.000us         0.00%     154.246ms       6.427ms           0 B           0 B      -6.54 GB      -6.56 GB            24  \n",
      "## Call CompiledFxGraph fp4iuldgh7qj4cb4w4sp4av7iyaj...         0.00%       0.000us         0.00%       0.000us       0.000us     147.310ms         7.09%     147.310ms       2.779ms           0 B           0 B           0 B           0 B            53  \n",
      "                             Torch-Compiled Region: 2/0         0.01%       1.686ms         2.15%     527.608ms      21.984ms       0.000us         0.00%     137.299ms       5.721ms           0 B           0 B       6.57 GB           0 B            24  \n",
      "## Call CompiledFxGraph fffrru2g3xvxsfxkqu75k4uerzlt...         0.09%      21.476ms         2.13%     521.173ms      21.716ms       0.000us         0.00%     137.299ms       5.721ms           0 B           0 B       6.57 GB       6.54 GB            24  \n",
      "## Call CompiledFxGraph f5k6hqiihurixgxoy2de5vpckw5n...         0.02%       3.963ms         0.59%     143.359ms       5.973ms       0.000us         0.00%     127.765ms       5.324ms           0 B           0 B     600.00 MB     600.00 MB            24  \n",
      "## Call CompiledFxGraph fnoewiyynwx3wzjela47bplx2bny...         0.18%      43.671ms         0.71%     174.003ms       2.417ms       0.000us         0.00%     126.742ms       1.760ms           0 B           0 B      19.09 GB      19.02 GB            72  \n",
      "## Call CompiledFxGraph fcic4wlffpggccscxm4q75zmwntb...         0.72%     175.444ms         2.17%     530.753ms       1.229ms       0.000us         0.00%     124.984ms     289.315us           0 B           0 B      -5.15 GB      -5.57 GB           432  \n",
      "autograd::engine::evaluate_function: LogSoftmaxBackw...         0.00%     196.471us         0.00%       1.074ms      44.745us       0.000us         0.00%     121.604ms       5.067ms           0 B           0 B     -18.75 GB     -37.50 GB            24  \n",
      "                                    LogSoftmaxBackward0         0.00%     215.787us         0.00%     877.418us      36.559us       0.000us         0.00%     121.604ms       5.067ms           0 B           0 B      18.75 GB           0 B            24  \n",
      "                       aten::_log_softmax_backward_data         0.00%     473.121us         0.00%     661.631us      27.568us     121.604ms         5.85%     121.604ms       5.067ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     121.604ms         5.85%     121.604ms       6.756ms           0 B           0 B           0 B           0 B            18  \n",
      "                                      aten::log_softmax         0.00%     314.778us         0.08%      18.835ms     784.790us       0.000us         0.00%     117.782ms       4.908ms           0 B           0 B      18.75 GB           0 B            24  \n",
      "                                     aten::_log_softmax         0.06%      14.937ms         0.08%      18.500ms     770.819us     111.238ms         5.35%     117.782ms       4.908ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us     111.238ms         5.35%     111.238ms       6.543ms           0 B           0 B           0 B           0 B            17  \n",
      "## Call CompiledFxGraph f5k6hqiihurixgxoy2de5vpckw5n...         0.00%       0.000us         0.00%       0.000us       0.000us     109.852ms         5.29%     109.852ms       6.462ms           0 B           0 B           0 B           0 B            17  \n",
      "## Call CompiledFxGraph fdm6uat3bajwoljdrckudcw6tjbp...         0.00%       0.000us         0.00%       0.000us       0.000us     109.592ms         5.28%     109.592ms       2.108ms           0 B           0 B           0 B           0 B            52  \n",
      "autograd::engine::evaluate_function: ToCopyBackward0...         0.00%     869.872us         0.10%      24.731ms     588.838us       0.000us         0.00%      93.250ms       2.220ms           0 B           0 B     -18.75 GB     -37.50 GB            42  \n",
      "                                        ToCopyBackward0         0.00%     213.316us         0.10%      23.861ms     568.126us       0.000us         0.00%      93.250ms       2.220ms           0 B           0 B      18.75 GB           0 B            42  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      93.250ms         4.49%      93.250ms       5.181ms           0 B           0 B           0 B           0 B            18  \n",
      "                                         aten::nll_loss         0.00%     273.086us         0.10%      25.657ms     534.527us       0.000us         0.00%      92.759ms       1.932ms           0 B           0 B      37.50 GB           0 B            48  \n",
      "                                      aten::nll_loss_nd         0.00%     132.067us         0.06%      13.813ms     575.559us       0.000us         0.00%      92.431ms       3.851ms           0 B           0 B      37.50 GB           0 B            24  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      86.987ms         4.19%      86.987ms       5.117ms           0 B           0 B           0 B           0 B            17  \n",
      "                             Torch-Compiled Region: 5/0         0.10%      24.300ms         2.19%     537.029ms       1.243ms       0.000us         0.00%      85.631ms     198.220us           0 B           0 B       5.61 GB           0 B           432  \n",
      "## Call CompiledFxGraph fe2dw25r4rvtemqmwyujb2x6u35c...         0.64%     156.882ms         1.92%     470.867ms       1.090ms       0.000us         0.00%      85.631ms     198.220us           0 B           0 B       5.61 GB       5.18 GB           432  \n",
      "triton_per_fused__softmax__to_copy_add_exp_mul_permu...         0.01%       1.883ms         0.01%       2.480ms      25.834us      79.451ms         3.82%      79.451ms     827.611us           0 B           0 B           0 B           0 B            96  \n",
      "triton_per_fused__softmax__to_copy_add_exp_mul_permu...         0.00%       0.000us         0.00%       0.000us       0.000us      79.451ms         3.82%      79.451ms       1.119ms           0 B           0 B           0 B           0 B            71  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      78.861ms         3.80%      78.861ms     113.796us           0 B           0 B           0 B           0 B           693  \n",
      "          ampere_bf16_s16816gemm_bf16_64x64_ldg8_f2f_nn         0.00%       0.000us         0.00%       0.000us       0.000us      73.069ms         3.52%      73.069ms     329.140us           0 B           0 B           0 B           0 B           222  \n",
      "                              Optimizer.step#AdamW.step         0.00%       0.000us         0.00%       0.000us       0.000us      68.632ms         3.30%      68.632ms      34.316ms           0 B           0 B           0 B           0 B             2  \n",
      "## Call CompiledFxGraph fdkbgrpms2f5t2d5j54k3qxedfco...         0.00%       0.000us         0.00%       0.000us       0.000us      67.938ms         3.27%      67.938ms       3.774ms           0 B           0 B           0 B           0 B            18  \n",
      "## Call CompiledFxGraph fdkbgrpms2f5t2d5j54k3qxedfco...         0.01%       2.180ms         0.03%       6.287ms     261.961us       0.000us         0.00%      67.895ms       2.829ms           0 B           0 B     608.12 MB     600.00 MB            24  \n",
      "                                            aten::clone         0.30%      74.573ms         0.88%     215.600ms      46.556us       0.000us         0.00%      62.194ms      13.430us     128.78 KB           0 B      12.57 GB           0 B          4631  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      61.761ms         2.97%      61.761ms      16.304us           0 B           0 B           0 B           0 B          3788  \n",
      "autograd::engine::evaluate_function: NllLossBackward...         0.00%     367.956us         0.01%       2.453ms     102.191us       0.000us         0.00%      61.339ms       2.556ms           0 B           0 B     -24.00 KB     -37.50 GB            24  \n",
      "                                       NllLossBackward0         0.00%     188.209us         0.01%       2.085ms      86.860us       0.000us         0.00%      61.339ms       2.556ms           0 B           0 B      37.50 GB           0 B            24  \n",
      "                                aten::nll_loss_backward         0.00%     524.154us         0.01%       1.896ms      79.018us     201.056us         0.01%      61.339ms       2.556ms           0 B           0 B      37.50 GB      37.50 GB            24  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      61.166ms         2.94%      61.166ms       1.529ms           0 B           0 B           0 B           0 B            40  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.01%       1.674ms         0.01%       2.238ms      23.308us      56.464ms         2.72%      56.464ms     588.165us           0 B           0 B           0 B           0 B            96  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.00%       0.000us         0.00%       0.000us       0.000us      56.464ms         2.72%      56.464ms     818.316us           0 B           0 B           0 B           0 B            69  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      52.188ms         2.51%      52.188ms     131.456us           0 B           0 B           0 B           0 B           397  \n",
      "## Call CompiledFxGraph fctgmlmsbw224kqs77mhhq76ztq5...         0.00%       0.000us         0.00%       0.000us       0.000us      50.897ms         2.45%      50.897ms     978.791us           0 B           0 B           0 B           0 B            52  \n",
      "void cutlass::Kernel2<cutlass_75_tensorop_bf16_s1688...         0.00%       0.000us         0.00%       0.000us       0.000us      49.341ms         2.38%      49.341ms     171.919us           0 B           0 B           0 B           0 B           287  \n",
      "                                  cudaStreamIsCapturing         0.08%      19.797ms         0.08%      19.797ms       0.553us      47.586ms         2.29%      47.586ms       1.329us           0 B           0 B           0 B           0 B         35813  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      47.248ms         2.27%      47.248ms     104.996us           0 B           0 B           0 B           0 B           450  \n",
      "                                 aten::_index_put_impl_         0.58%     140.925ms         1.78%     435.174ms     215.860us      33.436ms         1.61%      42.019ms      20.843us           0 B      -2.99 KB           0 B    -218.25 MB          2016  \n",
      "ampere_bf16_s16816gemm_bf16_256x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      41.916ms         2.02%      41.916ms     299.401us           0 B           0 B           0 B           0 B           140  \n",
      "    autograd::engine::evaluate_function: IndexBackward0         0.08%      19.523ms         2.03%     496.307ms     405.479us       0.000us         0.00%      41.435ms      33.852us           0 B           0 B    -802.12 MB      -1.58 GB          1224  \n",
      "                                         IndexBackward0         0.05%      11.532ms         1.90%     465.038ms     379.933us       0.000us         0.00%      38.932ms      31.807us           0 B           0 B     812.25 MB           0 B          1224  \n",
      "                             Torch-Compiled Region: 9/0         0.00%     960.880us         0.03%       6.176ms     257.344us       0.000us         0.00%      38.245ms       1.594ms           0 B           0 B      18.75 GB           0 B            24  \n",
      "## Call CompiledFxGraph fvingb54prth3cicubokrz6if6r2...         0.01%       1.646ms         0.02%       3.764ms     156.821us       0.000us         0.00%      38.245ms       1.594ms           0 B           0 B      18.75 GB      18.75 GB            24  \n",
      "## Call CompiledFxGraph fwq7bmxvx3unoa3vs5dubkrjrvoi...         0.00%       0.000us         0.00%       0.000us       0.000us      37.550ms         1.81%      37.550ms     722.118us           0 B           0 B           0 B           0 B            52  \n",
      "            triton_poi_fused_embedding_dense_backward_2         0.01%       2.586ms         0.02%       4.319ms      18.299us      37.168ms         1.79%      37.168ms     157.490us           0 B           0 B           0 B           0 B           236  \n",
      "            triton_poi_fused_embedding_dense_backward_2         0.00%       0.000us         0.00%       0.000us       0.000us      37.168ms         1.79%      37.168ms     162.304us           0 B           0 B           0 B           0 B           229  \n",
      "ampere_bf16_s16816gemm_bf16_128x128_ldg8_f2f_stages_...         0.00%       0.000us         0.00%       0.000us       0.000us      36.834ms         1.77%      36.834ms       2.046ms           0 B           0 B           0 B           0 B            18  \n",
      "ampere_bf16_s1688gemm_bf16_128x128_ldg8_f2f_stages_3...         0.00%       0.000us         0.00%       0.000us       0.000us      36.101ms         1.74%      36.101ms       2.124ms           0 B           0 B           0 B           0 B            17  \n",
      "## Call CompiledFxGraph fvingb54prth3cicubokrz6if6r2...         0.00%       0.000us         0.00%       0.000us       0.000us      36.101ms         1.74%      36.101ms       2.124ms           0 B           0 B           0 B           0 B            17  \n",
      "                               cudaEventRecordWithFlags         0.46%     112.346ms         0.46%     112.346ms       3.160us      35.421ms         1.71%      35.421ms       0.996us           0 B           0 B           0 B           0 B         35552  \n",
      "triton_per_fused__softmax__to_copy_exp_mul_permute_p...         0.05%      12.632ms         0.08%      20.031ms      23.400us      32.501ms         1.56%      32.521ms      37.992us           0 B           0 B           0 B           0 B           856  \n",
      "triton_per_fused__softmax__to_copy_exp_mul_permute_p...         0.00%       0.000us         0.00%       0.000us       0.000us      32.501ms         1.56%      32.501ms      43.980us           0 B           0 B           0 B           0 B           739  \n",
      "void cutlass::Kernel2<cutlass_80_tensorop_bf16_s1681...         0.00%       0.000us         0.00%       0.000us       0.000us      31.042ms         1.49%      31.042ms       1.725ms           0 B           0 B           0 B           0 B            18  \n",
      "## Call CompiledFxGraph fp4iuldgh7qj4cb4w4sp4av7iyaj...         0.06%      13.899ms         0.69%     169.337ms       2.352ms       0.000us         0.00%      27.585ms     383.121us           0 B           0 B     106.88 MB      86.62 MB            72  \n",
      "## Call CompiledFxGraph fdm6uat3bajwoljdrckudcw6tjbp...         0.05%      12.895ms         0.63%     154.656ms       2.148ms       0.000us         0.00%      26.815ms     372.430us           0 B           0 B     -31.22 MB     -31.22 MB            72  \n",
      "            triton_poi_fused_embedding_dense_backward_0         0.01%       2.520ms         0.02%       4.224ms      17.898us      24.565ms         1.18%      24.565ms     104.088us           0 B           0 B           0 B           0 B           236  \n",
      "            triton_poi_fused_embedding_dense_backward_0         0.00%       0.000us         0.00%       0.000us       0.000us      24.565ms         1.18%      24.565ms     107.270us           0 B           0 B           0 B           0 B           229  \n",
      "void cutlass::Kernel2<cutlass_80_wmma_tensorop_bf16_...         0.00%       0.000us         0.00%       0.000us       0.000us      23.296ms         1.12%      23.296ms     319.128us           0 B           0 B           0 B           0 B            73  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.06%      15.254ms         0.08%      20.672ms      24.149us      22.542ms         1.09%      22.542ms      26.334us           0 B           0 B           0 B           0 B           856  \n",
      "triton_per_fused__softmax__softmax_backward_data__to...         0.00%       0.000us         0.00%       0.000us       0.000us      22.542ms         1.09%      22.542ms      30.627us           0 B           0 B           0 B           0 B           736  \n",
      "                                  Lazy Function Loading         0.06%      15.514ms         0.06%      15.514ms      25.226us      21.258ms         1.02%      21.258ms      34.566us           0 B           0 B           0 B           0 B           615  \n",
      "                                         cudaEventQuery         0.08%      18.941ms         0.08%      18.941ms       0.533us      20.651ms         0.99%      20.651ms       0.581us           0 B           0 B           0 B           0 B         35552  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 24.493s\n",
      "Self CUDA time total: 2.077s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"device_time_total\", row_limit=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3aeba444-19db-477f-8440-dfb05733b6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>count</th>\n",
       "      <th>node_id</th>\n",
       "      <th>is_async</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>use_device</th>\n",
       "      <th>cpu_time_total</th>\n",
       "      <th>device_time_total</th>\n",
       "      <th>self_cpu_time_total</th>\n",
       "      <th>self_device_time_total</th>\n",
       "      <th>...</th>\n",
       "      <th>cpu_memory_usage</th>\n",
       "      <th>device_memory_usage</th>\n",
       "      <th>self_cpu_memory_usage</th>\n",
       "      <th>self_device_memory_usage</th>\n",
       "      <th>cpu_children</th>\n",
       "      <th>cpu_parent</th>\n",
       "      <th>device_type</th>\n",
       "      <th>is_legacy</th>\n",
       "      <th>flops</th>\n",
       "      <th>is_user_annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>aten::copy_</td>\n",
       "      <td>10716</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>564855.953</td>\n",
       "      <td>482483.527</td>\n",
       "      <td>186835.510</td>\n",
       "      <td>482464.744</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;FunctionEvent id=17 name=Activity Buffer Req...</td>\n",
       "      <td>&lt;FunctionEvent id=15 name=aten::_to_copy overl...</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>aten::_to_copy</td>\n",
       "      <td>6408</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>584840.836</td>\n",
       "      <td>450528.386</td>\n",
       "      <td>51657.894</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>11424</td>\n",
       "      <td>150392143872</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;FunctionEvent id=16 name=aten::empty_strided...</td>\n",
       "      <td>&lt;FunctionEvent id=14 name=aten::to overload_na...</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aten::to</td>\n",
       "      <td>8508</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>604355.725</td>\n",
       "      <td>450528.386</td>\n",
       "      <td>19514.889</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>11424</td>\n",
       "      <td>150392143872</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;FunctionEvent id=15 name=aten::_to_copy over...</td>\n",
       "      <td>None</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>aten::bmm</td>\n",
       "      <td>4032</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>148978.121</td>\n",
       "      <td>243491.243</td>\n",
       "      <td>122162.940</td>\n",
       "      <td>243491.243</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>45600669696</td>\n",
       "      <td>0</td>\n",
       "      <td>45600669696</td>\n",
       "      <td>[&lt;FunctionEvent id=302 name=cudaDeviceGetAttri...</td>\n",
       "      <td>&lt;FunctionEvent id=108 name=aten::einsum overlo...</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>autograd::engine::evaluate_function: SoftmaxBa...</td>\n",
       "      <td>600</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>49287.896</td>\n",
       "      <td>242334.867</td>\n",
       "      <td>5418.976</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-29434576896</td>\n",
       "      <td>0</td>\n",
       "      <td>-58850279424</td>\n",
       "      <td>[&lt;FunctionEvent id=5980 name=SoftmaxBackward0 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>aten::slice</td>\n",
       "      <td>1704</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>11913.564</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9207.549</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;FunctionEvent id=36 name=aten::as_strided ov...</td>\n",
       "      <td>None</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>aten::as_strided</td>\n",
       "      <td>47739</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>77996.598</td>\n",
       "      <td>0.000</td>\n",
       "      <td>77996.598</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>&lt;FunctionEvent id=29 name=aten::expand overloa...</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::random_</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>21.621</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.621</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::empty</td>\n",
       "      <td>13307</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>86342.867</td>\n",
       "      <td>0.000</td>\n",
       "      <td>86342.867</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>3678076</td>\n",
       "      <td>13019180544</td>\n",
       "      <td>3678076</td>\n",
       "      <td>13019180544</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Optimizer.zero_grad#AdamW.zero_grad</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>cuda</td>\n",
       "      <td>946.880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>946.880</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-165863424</td>\n",
       "      <td>0</td>\n",
       "      <td>-165863424</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>DeviceType.CPU</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>318 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   key  count  node_id  \\\n",
       "17                                         aten::copy_  10716       -1   \n",
       "15                                      aten::_to_copy   6408       -1   \n",
       "14                                            aten::to   8508       -1   \n",
       "60                                           aten::bmm   4032       -1   \n",
       "204  autograd::engine::evaluate_function: SoftmaxBa...    600       -1   \n",
       "..                                                 ...    ...      ...   \n",
       "29                                         aten::slice   1704       -1   \n",
       "25                                    aten::as_strided  47739       -1   \n",
       "1                                        aten::random_      1       -1   \n",
       "0                                          aten::empty  13307       -1   \n",
       "317                Optimizer.zero_grad#AdamW.zero_grad      3       -1   \n",
       "\n",
       "     is_async  is_remote use_device  cpu_time_total  device_time_total  \\\n",
       "17      False      False       cuda      564855.953         482483.527   \n",
       "15      False      False       cuda      584840.836         450528.386   \n",
       "14      False      False       cuda      604355.725         450528.386   \n",
       "60      False      False       cuda      148978.121         243491.243   \n",
       "204     False      False       cuda       49287.896         242334.867   \n",
       "..        ...        ...        ...             ...                ...   \n",
       "29      False      False       cuda       11913.564              0.000   \n",
       "25      False      False       cuda       77996.598              0.000   \n",
       "1       False      False       cuda          21.621              0.000   \n",
       "0       False      False       cuda       86342.867              0.000   \n",
       "317     False      False       cuda         946.880              0.000   \n",
       "\n",
       "     self_cpu_time_total  self_device_time_total  ... cpu_memory_usage  \\\n",
       "17            186835.510              482464.744  ...                0   \n",
       "15             51657.894                   0.000  ...            11424   \n",
       "14             19514.889                   0.000  ...            11424   \n",
       "60            122162.940              243491.243  ...                0   \n",
       "204             5418.976                   0.000  ...                0   \n",
       "..                   ...                     ...  ...              ...   \n",
       "29              9207.549                   0.000  ...                0   \n",
       "25             77996.598                   0.000  ...                0   \n",
       "1                 21.621                   0.000  ...                0   \n",
       "0              86342.867                   0.000  ...          3678076   \n",
       "317              946.880                   0.000  ...                0   \n",
       "\n",
       "    device_memory_usage self_cpu_memory_usage  self_device_memory_usage  \\\n",
       "17                    0                     0                         0   \n",
       "15         150392143872                     0                         0   \n",
       "14         150392143872                     0                         0   \n",
       "60          45600669696                     0               45600669696   \n",
       "204        -29434576896                     0              -58850279424   \n",
       "..                  ...                   ...                       ...   \n",
       "29                    0                     0                         0   \n",
       "25                    0                     0                         0   \n",
       "1                     0                     0                         0   \n",
       "0           13019180544               3678076               13019180544   \n",
       "317          -165863424                     0                -165863424   \n",
       "\n",
       "                                          cpu_children  \\\n",
       "17   [<FunctionEvent id=17 name=Activity Buffer Req...   \n",
       "15   [<FunctionEvent id=16 name=aten::empty_strided...   \n",
       "14   [<FunctionEvent id=15 name=aten::_to_copy over...   \n",
       "60   [<FunctionEvent id=302 name=cudaDeviceGetAttri...   \n",
       "204  [<FunctionEvent id=5980 name=SoftmaxBackward0 ...   \n",
       "..                                                 ...   \n",
       "29   [<FunctionEvent id=36 name=aten::as_strided ov...   \n",
       "25                                                  []   \n",
       "1                                                   []   \n",
       "0                                                   []   \n",
       "317                                                 []   \n",
       "\n",
       "                                            cpu_parent     device_type  \\\n",
       "17   <FunctionEvent id=15 name=aten::_to_copy overl...  DeviceType.CPU   \n",
       "15   <FunctionEvent id=14 name=aten::to overload_na...  DeviceType.CPU   \n",
       "14                                                None  DeviceType.CPU   \n",
       "60   <FunctionEvent id=108 name=aten::einsum overlo...  DeviceType.CPU   \n",
       "204                                               None  DeviceType.CPU   \n",
       "..                                                 ...             ...   \n",
       "29                                                None  DeviceType.CPU   \n",
       "25   <FunctionEvent id=29 name=aten::expand overloa...  DeviceType.CPU   \n",
       "1                                                 None  DeviceType.CPU   \n",
       "0                                                 None  DeviceType.CPU   \n",
       "317                                               None  DeviceType.CPU   \n",
       "\n",
       "     is_legacy flops is_user_annotation  \n",
       "17       False     0              False  \n",
       "15       False     0              False  \n",
       "14       False     0              False  \n",
       "60       False     0              False  \n",
       "204      False     0              False  \n",
       "..         ...   ...                ...  \n",
       "29       False     0              False  \n",
       "25       False     0              False  \n",
       "1        False     0              False  \n",
       "0        False     0              False  \n",
       "317      False     0               True  \n",
       "\n",
       "[318 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_print.sort_values('device_time_total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c867099-2d1c-4c13-aa43-f2c688367ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'count', 'node_id', 'is_async', 'is_remote', 'use_device',\n",
       "       'cpu_time_total', 'device_time_total', 'self_cpu_time_total',\n",
       "       'self_device_time_total', 'input_shapes', 'overload_name', 'stack',\n",
       "       'scope', 'cpu_memory_usage', 'device_memory_usage',\n",
       "       'self_cpu_memory_usage', 'self_device_memory_usage', 'cpu_children',\n",
       "       'cpu_parent', 'device_type', 'is_legacy', 'flops',\n",
       "       'is_user_annotation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch._inductor.debug import compile_debug\n",
    "\n",
    "# Wrap your model/function with compile_debug\n",
    "compile_debug(your_function)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ef4e6de-9e47-4d21-a5e9-fd3b2ed44b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'count', 'node_id', 'is_async', 'is_remote', 'use_device',\n",
       "       'cpu_time_total', 'device_time_total', 'self_cpu_time_total',\n",
       "       'self_device_time_total', 'input_shapes', 'overload_name', 'stack',\n",
       "       'scope', 'cpu_memory_usage', 'device_memory_usage',\n",
       "       'self_cpu_memory_usage', 'self_device_memory_usage', 'cpu_children',\n",
       "       'cpu_parent', 'device_type', 'is_legacy', 'flops',\n",
       "       'is_user_annotation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_print.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a479631-3ffb-4329-bcee-dfd6ca413335",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logits = trainer.model(xx, start_pos=0)\n",
    "loss = F.cross_entropy(\n",
    "    logits.view(-1, logits.size(-1)),\n",
    "    yy.view(-1),\n",
    "    ignore_index=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3c8ba0e2-4741-48bb-a7f6-8f2b60f7e9c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee83b9-fe97-44e6-9c3e-11c241a3fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "[4, 1024, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3798d86f-dd3b-40dc-af69-9421c27eb399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<NllLossBackward0 at 0x7b6231cbbfd0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bc4437c-65c2-40ee-abc7-18fcbc563b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024, 102400])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7d5ea6b-776c-4a56-b404-0c16aff12313",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.float32\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.float32\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.float32\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.float32\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.bfloat16\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for k, v in trainer.model.named_parameters():\n",
    "    print(v.dtype)\n",
    "    if v.grad_fn:\n",
    "        print((k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7719edd-af44-4971-855c-005dda00baef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d448fc9-cc97-4fc4-baa7-49c8eacca3f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): ParallelEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0-3): 4 x Block(\n",
       "      (attn): MLA(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MLP(\n",
       "        (w1): ColumnParallelLinear()\n",
       "        (w2): RowParallelLinear()\n",
       "        (w3): ColumnParallelLinear()\n",
       "      )\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (attn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (head): ColumnParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45ae2547-8849-4ee5-940f-490f64f74ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/llm-models/llm-models/models/deepseek/train.py:218: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.args.use_amp, dtype=torch.bfloat16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "loss\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:290\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m     param_group[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] = lr\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m running_loss += loss\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Update weights after accumulation steps\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:229\u001b[39m, in \u001b[36mTrainer.train_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d7e8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a11eb58d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12356'\n",
    "dist.init_process_group(backend='nccl', rank=0, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b86b86e5-a3cd-4ee3-ac33-52f0b0f382e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00597c75-9b8e-4253-8be0-6623ae96be82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for step, batch in enumerate(trainer.train_loader):\n",
    "    count += 1\n",
    "    if count > 4:\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0db892e5-2483-4ef3-8a5e-e83c3a1911d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0825809-1f27-4a13-89e4-239eb25ed312",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randint(0, 10000, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "798f7ebf-1520-4b89-876f-d4b9d6d5bd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = batch\n",
    "x = x.to(trainer.device, non_blocking=True)\n",
    "y = y.to(trainer.device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1dd78d0-e9cb-4dba-823a-6e5f2071b79c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m logits = trainer.model(x, start_pos=\u001b[32m0\u001b[39m)\n\u001b[32m      3\u001b[39m loss = F.cross_entropy(\n\u001b[32m      4\u001b[39m                 logits.view(-\u001b[32m1\u001b[39m, logits.size(-\u001b[32m1\u001b[39m)),\n\u001b[32m      5\u001b[39m                 y.view(-\u001b[32m1\u001b[39m),\n\u001b[32m      6\u001b[39m                 ignore_index=-\u001b[32m1\u001b[39m\n\u001b[32m      7\u001b[39m             )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "logits = trainer.model(x, start_pos=0)\n",
    "\n",
    "loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)),\n",
    "                y.view(-1),\n",
    "                ignore_index=-1\n",
    "            )\n",
    "\n",
    "loss.backward(retain_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "49540cc7-8e7a-4eb0-a896-2c2b5f15ec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)),\n",
    "                y.view(-1),\n",
    "                ignore_index=-1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9cd151d4-3f47-4cb7-ae39-64021879eb2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff01bd6f-6e24-4b3f-89cb-18b22881b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enum_to_value(obj):\n",
    "    if isinstance(obj, Enum):\n",
    "        return obj.value\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: enum_to_value(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [enum_to_value(v) for v in obj]\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c330e33-890e-4a06-92af-ac000ab30b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 1263,    13, 40355,  ...,   465,   835,   290],\n",
      "        [  284, 13502,  2405,  ...,   635, 11040,    13],\n",
      "        [  356,   460,   526,  ...,   257,  7812,  7838],\n",
      "        [   11,   644,   460,  ...,   284,  1441,   262]]), tensor([[ 1263,    13, 40355,  ...,   465,   835,   290],\n",
      "        [  284, 13502,  2405,  ...,   635, 11040,    13],\n",
      "        [  356,   460,   526,  ...,   257,  7812,  7838],\n",
      "        [   11,   644,   460,  ...,   284,  1441,   262]])]\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(trainer.train_loader):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40ce698d-5631-493f-af49-b6f9d913e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = batch\n",
    "x = x.to(trainer.device, non_blocking=True)\n",
    "y = y.to(trainer.device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b257830e-f70f-44d5-a13a-2ac4c7672617",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mlogits\u001b[49m.shape\n",
      "\u001b[31mNameError\u001b[39m: name 'logits' is not defined"
     ]
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "418c1d04-2cbf-4e54-affe-cb0dfce3a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits1 = trainer.model(x, start_pos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8bf8d128-c5fe-461b-b2c4-1828c64add4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = F.cross_entropy(\n",
    "                logits1.view(-1, logits1.size(-1)),\n",
    "                y.view(-1),\n",
    "                ignore_index=-1\n",
    "            )\n",
    "\n",
    "loss1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e0820a8-0fd4-448e-ac1b-7dc5dee595c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits2 = trainer.model(x, start_pos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52e158dc-e744-487c-b57b-71d0597c71f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m loss2 = F.cross_entropy(\n\u001b[32m      2\u001b[39m                 logits2.view(-\u001b[32m1\u001b[39m, logits2.size(-\u001b[32m1\u001b[39m)),\n\u001b[32m      3\u001b[39m                 y.view(-\u001b[32m1\u001b[39m),\n\u001b[32m      4\u001b[39m                 ignore_index=-\u001b[32m1\u001b[39m\n\u001b[32m      5\u001b[39m             )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mloss2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss2 = F.cross_entropy(\n",
    "                logits2.view(-1, logits2.size(-1)),\n",
    "                y.view(-1),\n",
    "                ignore_index=-1\n",
    "            )\n",
    "\n",
    "loss2.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "103b6f98-f6ac-4ad9-a909-757c743b4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = F.cross_entropy(\n",
    "                logits1.view(-1, logits1.size(-1)),\n",
    "                y.view(-1),\n",
    "                ignore_index=-1\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c82d0631-c2c2-4ed0-98f2-72e95e19f086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): ParallelEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0): Block(\n",
       "      (attn): MLA(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MLP(\n",
       "        (w1): ColumnParallelLinear()\n",
       "        (w2): RowParallelLinear()\n",
       "        (w3): ColumnParallelLinear()\n",
       "      )\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (attn_norm): RMSNorm()\n",
       "    )\n",
       "    (1-3): 3 x Block(\n",
       "      (attn): MLA(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MoE(\n",
       "        (gate): Gate()\n",
       "        (experts): ModuleList(\n",
       "          (0-15): 16 x Expert(\n",
       "            (w1): Linear()\n",
       "            (w2): Linear()\n",
       "            (w3): Linear()\n",
       "          )\n",
       "        )\n",
       "        (shared_experts): MLP(\n",
       "          (w1): ColumnParallelLinear()\n",
       "          (w2): RowParallelLinear()\n",
       "          (w3): ColumnParallelLinear()\n",
       "        )\n",
       "      )\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (attn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (head): ColumnParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcf78ba-8b33-4d97-8ff8-e66e93ac19b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0d55f-e649-44e2-afb0-5942ff819292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9268ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 33,000,576\n",
      "Trainable parameters: 33,000,576\n",
      "Loading *tokenized* TinyStories dataset split from: './processed_tinystories/train'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/llm-models/llm-models/models/deepseek/train.py:165: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.args.use_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized dataset loaded. Total chunks: 459757\n",
      "Loading *tokenized* TinyStories dataset split from: './processed_tinystories/validation'...\n",
      "Tokenized dataset loaded. Total chunks: 4619\n"
     ]
    }
   ],
   "source": [
    "trainer = train.Trainer(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b554b58-4a1e-4f42-a509-e80d6d944445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer_model = model.Transformer(trainer.args.model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3168435-50ec-4b7a-94b3-83c011b6edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepspeed.init_distributed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b8d7efc-a3ed-4b34-b1fc-e3a51be6c80a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): ParallelEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0): Block(\n",
       "      (attn): MLA(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MLP(\n",
       "        (w1): ColumnParallelLinear()\n",
       "        (w2): RowParallelLinear()\n",
       "        (w3): ColumnParallelLinear()\n",
       "      )\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (attn_norm): RMSNorm()\n",
       "    )\n",
       "    (1-3): 3 x Block(\n",
       "      (attn): MLA(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MoE(\n",
       "        (experts): MoE(\n",
       "          (deepspeed_moe): MOELayer(\n",
       "            (gate): TopKGate(\n",
       "              (wg): Linear(in_features=128, out_features=16, bias=False)\n",
       "            )\n",
       "            (experts): Experts(\n",
       "              (deepspeed_experts): ModuleList(\n",
       "                (0-15): 16 x Expert(\n",
       "                  (block): Block(\n",
       "                    (attn): ExpertMLA(\n",
       "                      (wq): Linear()\n",
       "                      (wkv_a): Linear()\n",
       "                      (kv_norm): RMSNorm()\n",
       "                      (wkv_b): Linear()\n",
       "                      (wo): Linear()\n",
       "                    )\n",
       "                    (attn_norm): RMSNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (shared_experts): MLP(\n",
       "          (w1): ColumnParallelLinear()\n",
       "          (w2): RowParallelLinear()\n",
       "          (w3): ColumnParallelLinear()\n",
       "        )\n",
       "      )\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (attn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (head): ColumnParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad0c8d1c-b3ab-49ab-afb0-2548f87dc6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e45e64b-d006-4b3e-b9e2-113ba068f234",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): ParallelEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0): Block(\n",
       "      (attn): MLA(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MLP(\n",
       "        (w1): ColumnParallelLinear()\n",
       "        (w2): RowParallelLinear()\n",
       "        (w3): ColumnParallelLinear()\n",
       "      )\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (attn_norm): RMSNorm()\n",
       "    )\n",
       "    (1-3): 3 x Block(\n",
       "      (attn): MLA(\n",
       "        (wq): ColumnParallelLinear()\n",
       "        (wkv_a): Linear()\n",
       "        (kv_norm): RMSNorm()\n",
       "        (wkv_b): ColumnParallelLinear()\n",
       "        (wo): RowParallelLinear()\n",
       "      )\n",
       "      (ffn): MoE(\n",
       "        (experts): MoE(\n",
       "          (deepspeed_moe): MOELayer(\n",
       "            (gate): TopKGate(\n",
       "              (wg): Linear(in_features=128, out_features=16, bias=False)\n",
       "            )\n",
       "            (experts): Experts(\n",
       "              (deepspeed_experts): ModuleList(\n",
       "                (0-15): 16 x Expert(\n",
       "                  (block): Block(\n",
       "                    (attn): ExpertMLA(\n",
       "                      (wq): Linear()\n",
       "                      (wkv_a): Linear()\n",
       "                      (kv_norm): RMSNorm()\n",
       "                      (wkv_b): Linear()\n",
       "                      (wo): Linear()\n",
       "                    )\n",
       "                    (attn_norm): RMSNorm()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (shared_experts): MLP(\n",
       "          (w1): ColumnParallelLinear()\n",
       "          (w2): RowParallelLinear()\n",
       "          (w3): ColumnParallelLinear()\n",
       "        )\n",
       "      )\n",
       "      (ffn_norm): RMSNorm()\n",
       "      (attn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (head): ColumnParallelLinear()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_model.to(trainer.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd33023a-7dab-4a4b-b08c-c7c6648672e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_model.mask.device\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dc91469-6a44-440f-a998-9b63cb1c2c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(model)\n",
    "trainer_model = model.Transformer(trainer.args.model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6ed2d35-1d12-4897-b3da-3a36ee59fd33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experts(\n",
       "  (deepspeed_experts): ModuleList(\n",
       "    (0-15): 16 x Expert(\n",
       "      (block): Block(\n",
       "        (attn): ExpertMLA(\n",
       "          (wq): Linear()\n",
       "          (wkv_a): Linear()\n",
       "          (kv_norm): RMSNorm()\n",
       "          (wkv_b): Linear()\n",
       "          (wo): Linear()\n",
       "        )\n",
       "        (attn_norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_model.layers[1].ffn.experts.deepspeed_moe.experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ab62604-6525-4cf0-941a-ba9fedf137ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepspeed.moe.layer import MOELayer\n",
    "\n",
    "def get_all_moe_layers(model):\n",
    "    # This will traverse the entire Transformer/Block/MoE/MOELayer tree\n",
    "    moe_layers = []\n",
    "    print(len(list(model.named_modules())))\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, MOELayer):\n",
    "            moe_layers.append(module)\n",
    "    return moe_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "565c3869-9bcc-4a08-844e-62fab82ee108",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experts(\n",
       "  (deepspeed_experts): ModuleList(\n",
       "    (0-15): 16 x Expert(\n",
       "      (block): Block(\n",
       "        (attn): ExpertMLA(\n",
       "          (wq): Linear()\n",
       "          (wkv_a): Linear()\n",
       "          (kv_norm): RMSNorm()\n",
       "          (wkv_b): Linear()\n",
       "          (wo): Linear()\n",
       "        )\n",
       "        (attn_norm): RMSNorm()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_moe_layers(trainer_model)[0].experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aed5d5f6-9df4-4b00-b8a2-4a67ed70a467",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('',\n",
       " Transformer(\n",
       "   (embed): ParallelEmbedding()\n",
       "   (layers): ModuleList(\n",
       "     (0): Block(\n",
       "       (attn): MLA(\n",
       "         (wq): ColumnParallelLinear()\n",
       "         (wkv_a): Linear()\n",
       "         (kv_norm): RMSNorm()\n",
       "         (wkv_b): ColumnParallelLinear()\n",
       "         (wo): RowParallelLinear()\n",
       "       )\n",
       "       (ffn): MLP(\n",
       "         (w1): ColumnParallelLinear()\n",
       "         (w2): RowParallelLinear()\n",
       "         (w3): ColumnParallelLinear()\n",
       "       )\n",
       "       (ffn_norm): RMSNorm()\n",
       "       (attn_norm): RMSNorm()\n",
       "     )\n",
       "     (1-3): 3 x Block(\n",
       "       (attn): MLA(\n",
       "         (wq): ColumnParallelLinear()\n",
       "         (wkv_a): Linear()\n",
       "         (kv_norm): RMSNorm()\n",
       "         (wkv_b): ColumnParallelLinear()\n",
       "         (wo): RowParallelLinear()\n",
       "       )\n",
       "       (ffn): MoE(\n",
       "         (experts): MoE(\n",
       "           (deepspeed_moe): MOELayer(\n",
       "             (gate): TopKGate(\n",
       "               (wg): Linear(in_features=128, out_features=16, bias=False)\n",
       "             )\n",
       "             (experts): Experts(\n",
       "               (deepspeed_experts): ModuleList(\n",
       "                 (0-15): 16 x Expert(\n",
       "                   (block): Block(\n",
       "                     (attn): ExpertMLA(\n",
       "                       (wq): Linear()\n",
       "                       (wkv_a): Linear()\n",
       "                       (kv_norm): RMSNorm()\n",
       "                       (wkv_b): Linear()\n",
       "                       (wo): Linear()\n",
       "                     )\n",
       "                     (attn_norm): RMSNorm()\n",
       "                   )\n",
       "                 )\n",
       "               )\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (shared_experts): MLP(\n",
       "           (w1): ColumnParallelLinear()\n",
       "           (w2): RowParallelLinear()\n",
       "           (w3): ColumnParallelLinear()\n",
       "         )\n",
       "       )\n",
       "       (ffn_norm): RMSNorm()\n",
       "       (attn_norm): RMSNorm()\n",
       "     )\n",
       "   )\n",
       "   (norm): RMSNorm()\n",
       "   (head): ColumnParallelLinear()\n",
       " ))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(trainer_model.named_modules())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "57aa2709-7030-45ac-90f6-4e16b65e17ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m trainer.model = trainer_model\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from deepspeed.moe.layer import MOELayer\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodel\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MoE\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "# trainer.model = trainer_model\n",
    "# from deepspeed.moe.layer import MOELayer\n",
    "from model import MoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a73932cb-cab8-4527-9d9c-3713ff7726d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'models.deepseek.model.MoE'>\n",
      "<class 'deepspeed.moe.layer.MoE'>\n",
      "<class 'models.deepseek.model.MoE'>\n",
      "<class 'deepspeed.moe.layer.MoE'>\n",
      "<class 'models.deepseek.model.MoE'>\n",
      "<class 'deepspeed.moe.layer.MoE'>\n"
     ]
    }
   ],
   "source": [
    "for name, module in trainer.model.named_modules():\n",
    "    # if isinstance(module, model.MoE):\n",
    "    if 'MoE' in str(type(module)):\n",
    "        print(type(module))\n",
    "        # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9c65152-c359-4319-ace5-5f203c4ffe6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "models.deepseek.model.MoE"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.MoE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "874ffcc0-4254-44d3-8f95-1393c08a897e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ColumnParallelLinear' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-dev/lib/python3.12/site-packages/torch/nn/modules/module.py:1964\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1963\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1964\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1965\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1966\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'ColumnParallelLinear' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "module.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85347635-dd3d-4319-9038-1352273be110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.collect_moe_aux_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaa806ef-c4da-43e7-8e0d-94a2896bb0b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1024, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([4, 1024, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([4, 1024, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n",
      "torch.Size([1, 1, 512, 128])\n"
     ]
    }
   ],
   "source": [
    "logits1 = trainer_model(x, start_pos=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37b8c782-b607-46c8-9e5c-c1153d67c05f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k, v in trainer_model.named_parameters():\n",
    "    if 'cuda' not in str(v.device):\n",
    "        print(k)\n",
    "        print(v.device)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c643bc3c-f014-4a88-b0fc-73af1cb6b58a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/llm-models/llm-models/models/deepseek/train.py:218: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=self.args.use_amp, dtype=torch.bfloat16):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss\n",
      "loss\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:290\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    287\u001b[39m     param_group[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] = lr\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Training step\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    291\u001b[39m running_loss += loss\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Update weights after accumulation steps\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:229\u001b[39m, in \u001b[36mTrainer.train_step\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66bda053-d219-4393-9cb7-d0b4074d1fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m trainer.model.named_parameters():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm/lib/python3.12/site-packages/torch/nn/parameter.py:74\u001b[39m, in \u001b[36mParameter.__repr__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mParameter containing:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__repr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm/lib/python3.12/site-packages/torch/_tensor.py:590\u001b[39m, in \u001b[36mTensor.__repr__\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    586\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    587\u001b[39m         Tensor.\u001b[34m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents=tensor_contents\n\u001b[32m    588\u001b[39m     )\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tensor_str\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm/lib/python3.12/site-packages/torch/_tensor_str.py:726\u001b[39m, in \u001b[36m_str\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(), torch.utils._python_dispatch._disable_current_modes():\n\u001b[32m    725\u001b[39m     guard = torch._C._DisableFuncTorch()  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm/lib/python3.12/site-packages/torch/_tensor_str.py:647\u001b[39m, in \u001b[36m_str_intern\u001b[39m\u001b[34m(inp, tensor_contents)\u001b[39m\n\u001b[32m    645\u001b[39m                     tensor_str = _tensor_str(\u001b[38;5;28mself\u001b[39m.to_dense(), indent)\n\u001b[32m    646\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m                     tensor_str = \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layout != torch.strided:\n\u001b[32m    650\u001b[39m     suffixes.append(\u001b[33m\"\u001b[39m\u001b[33mlayout=\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layout))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm/lib/python3.12/site-packages/torch/_tensor_str.py:379\u001b[39m, in \u001b[36m_tensor_str\u001b[39m\u001b[34m(self, indent)\u001b[39m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[32m    376\u001b[39m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[32m    377\u001b[39m     )\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     formatter = _Formatter(\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm/lib/python3.12/site-packages/torch/_tensor_str.py:415\u001b[39m, in \u001b[36mget_summarized_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    413\u001b[39m     start = [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, PRINT_OPTS.edgeitems)]\n\u001b[32m    414\u001b[39m     end = [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - PRINT_OPTS.edgeitems, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))]\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (start + end)])\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm/lib/python3.12/site-packages/torch/_tensor_str.py:405\u001b[39m, in \u001b[36mget_summarized_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dim == \u001b[32m1\u001b[39m:\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.size(\u001b[32m0\u001b[39m) > \u001b[32m2\u001b[39m * PRINT_OPTS.edgeitems:\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43medgeitems\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43medgeitems\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    409\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for name, param in trainer.model.named_parameters():\n",
    "    print(param)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffba93cf-b986-4805-b93d-640f10ae7bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273394814022960"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(trainer.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e74d4-d8b6-4858-9abd-b6035c5e580f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc992e6-7653-48f6-8eb1-d8d259a69c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd79a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# --- Configuration ---\n",
    "MODEL_NAME = \"gpt2\"\n",
    "CONTEXT_LENGTH = 1024\n",
    "PROCESSED_DATA_DIR = \"./processed_tinystories\"\n",
    "\n",
    "def tokenize_and_group_dataset(split: str):\n",
    "    \"\"\"Loads a split, tokenizes it, and groups it into fixed-size chunks.\"\"\"\n",
    "    \n",
    "    # 1. Load Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    # 2. Load Raw Dataset\n",
    "    raw_dataset = load_dataset(\"roneneldan/TinyStories\", split=split)\n",
    "\n",
    "    # 3. Tokenization\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], truncation=False) # No truncation yet\n",
    "    \n",
    "    tokenized_datasets = raw_dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"],\n",
    "        num_proc=os.cpu_count(),\n",
    "    )\n",
    "\n",
    "    # 4. Grouping and Chunking\n",
    "    def group_texts(examples):\n",
    "        # Concatenate all lists of token IDs in the batch\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        \n",
    "        # Drop the last chunk\n",
    "        total_length = (total_length // CONTEXT_LENGTH) * CONTEXT_LENGTH\n",
    "        \n",
    "        # Split the concatenated list into chunks of CONTEXT_LENGTH\n",
    "        result = {\n",
    "            k: [t[i : i + CONTEXT_LENGTH] for i in range(0, total_length, CONTEXT_LENGTH)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        # For CLM, labels are the input IDs\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "\n",
    "    lm_dataset = tokenized_datasets.map(\n",
    "        group_texts,\n",
    "        batched=True,\n",
    "        num_proc=os.cpu_count(),\n",
    "    )\n",
    "    \n",
    "    # 5. Save the processed dataset\n",
    "    output_path = os.path.join(PROCESSED_DATA_DIR, split)\n",
    "    lm_dataset.save_to_disk(output_path)\n",
    "    print(f\"Processed dataset saved to: {output_path}\")\n",
    "\n",
    "    return lm_dataset\n",
    "\n",
    "# Run this block once to create the processed data files\n",
    "if not os.path.exists(PROCESSED_DATA_DIR):\n",
    "    os.makedirs(PROCESSED_DATA_DIR)\n",
    "    \n",
    "    print(\"\\n--- Starting Pre-processing for all splits ---\")\n",
    "    tokenize_and_group_dataset(\"train\")\n",
    "    tokenize_and_group_dataset(\"validation\")\n",
    "    # TinyStories also has a 'test' split if needed: tokenize_and_group_dataset(\"test\")\n",
    "    print(\"--- Pre-processing Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa0b0fe-4e36-4ec0-a40a-2d4858accf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/llm-models/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c61a58-c6de-43a2-93f3-74f94cc7ddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'gpt2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "split = 'train'\n",
    "\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "# 2. Load Raw Dataset\n",
    "raw_dataset = load_dataset(\"roneneldan/TinyStories\", split=split)\n",
    "\n",
    "# 3. Tokenization\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=False) # No truncation yet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4c8bbc-a0e8-4875-91cf-4cf7bb28926e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = raw_dataset.map(\n",
    "        tokenize_function,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\"],\n",
    "        num_proc=os.cpu_count(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ea7c11-8c19-4a03-bbb2-080df53d78cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "065dcc23-73fb-428c-a417-77ccbd5da200",
   "metadata": {},
   "outputs": [
    {
     "ename": "RemoteEntryNotFoundError",
     "evalue": "404 Client Error. (Request ID: Root=1-6939c3ad-41a5479f633cd8c13bea7ca3;2614ec0e-0f21-41dd-ae9f-1d4b9b16b6fb)\n\nEntry Not Found for url: https://huggingface.co/api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=false&expand=false.\nadditional_chat_templates does not exist on \"main\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:657\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '404 Not Found' for url 'https://huggingface.co/api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=false&expand=false'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRemoteEntryNotFoundError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenize_and_group_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/data.py:28\u001b[39m, in \u001b[36mtokenize_and_group_dataset\u001b[39m\u001b[34m(split)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Loads a split, tokenizes it, and groups it into fixed-size chunks.\"\"\"\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 1. Load Tokenizer\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer.pad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     30\u001b[39m     tokenizer.pad_token = tokenizer.eos_token\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:1175\u001b[39m, in \u001b[36mAutoTokenizer.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m   1172\u001b[39m tokenizer_class_py, tokenizer_class_fast = TOKENIZER_MAPPING[\u001b[38;5;28mtype\u001b[39m(config)]\n\u001b[32m   1174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_fast \u001b[38;5;129;01mand\u001b[39;00m (use_fast \u001b[38;5;129;01mor\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer_class_fast\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1177\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class_py \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2039\u001b[39m, in \u001b[36mPreTrainedTokenizerBase.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[39m\n\u001b[32m   2035\u001b[39m             vocab_files[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mchat_template_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = (\n\u001b[32m   2036\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_TEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate_file.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   2037\u001b[39m             )\n\u001b[32m   2038\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2039\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m template \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlist_repo_templates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2040\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2041\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2042\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2043\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2045\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   2046\u001b[39m         template = template.removesuffix(\u001b[33m\"\u001b[39m\u001b[33m.jinja\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2047\u001b[39m         vocab_files[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mchat_template_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCHAT_TEMPLATE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.jinja\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/transformers/utils/hub.py:167\u001b[39m, in \u001b[36mlist_repo_templates\u001b[39m\u001b[34m(repo_id, local_files_only, revision, cache_dir, token)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m local_files_only:\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremoveprefix\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCHAT_TEMPLATE_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlist_repo_tree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpath_in_repo\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCHAT_TEMPLATE_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mendswith\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.jinja\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (GatedRepoError, RepositoryNotFoundError, RevisionNotFoundError):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m  \u001b[38;5;66;03m# valid errors => do not catch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3156\u001b[39m, in \u001b[36mlist_repo_tree\u001b[39m\u001b[34m(self, repo_id, path_in_repo, recursive, expand, revision, repo_type, token)\u001b[39m\n\u001b[32m   3062\u001b[39m \u001b[38;5;129m@validate_hf_hub_args\u001b[39m\n\u001b[32m   3063\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlist_repo_tree\u001b[39m(\n\u001b[32m   3064\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3072\u001b[39m     token: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   3073\u001b[39m ) -> Iterable[Union[RepoFile, RepoFolder]]:\n\u001b[32m   3074\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3075\u001b[39m \u001b[33;03m    List a repo tree's files and folders and get information about them.\u001b[39;00m\n\u001b[32m   3076\u001b[39m \n\u001b[32m   3077\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   3078\u001b[39m \u001b[33;03m        repo_id (`str`):\u001b[39;00m\n\u001b[32m   3079\u001b[39m \u001b[33;03m            A namespace (user or an organization) and a repo name separated by a `/`.\u001b[39;00m\n\u001b[32m   3080\u001b[39m \u001b[33;03m        path_in_repo (`str`, *optional*):\u001b[39;00m\n\u001b[32m   3081\u001b[39m \u001b[33;03m            Relative path of the tree (folder) in the repo, for example:\u001b[39;00m\n\u001b[32m   3082\u001b[39m \u001b[33;03m            `\"checkpoints/1fec34a/results\"`. Will default to the root tree (folder) of the repository.\u001b[39;00m\n\u001b[32m   3083\u001b[39m \u001b[33;03m        recursive (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[32m   3084\u001b[39m \u001b[33;03m            Whether to list tree's files and folders recursively.\u001b[39;00m\n\u001b[32m   3085\u001b[39m \u001b[33;03m        expand (`bool`, *optional*, defaults to `False`):\u001b[39;00m\n\u001b[32m   3086\u001b[39m \u001b[33;03m            Whether to fetch more information about the tree's files and folders (e.g. last commit and files' security scan results). This\u001b[39;00m\n\u001b[32m   3087\u001b[39m \u001b[33;03m            operation is more expensive for the server so only 50 results are returned per page (instead of 1000).\u001b[39;00m\n\u001b[32m   3088\u001b[39m \u001b[33;03m            As pagination is implemented in `huggingface_hub`, this is transparent for you except for the time it\u001b[39;00m\n\u001b[32m   3089\u001b[39m \u001b[33;03m            takes to get the results.\u001b[39;00m\n\u001b[32m   3090\u001b[39m \u001b[33;03m        revision (`str`, *optional*):\u001b[39;00m\n\u001b[32m   3091\u001b[39m \u001b[33;03m            The revision of the repository from which to get the tree. Defaults to `\"main\"` branch.\u001b[39;00m\n\u001b[32m   3092\u001b[39m \u001b[33;03m        repo_type (`str`, *optional*):\u001b[39;00m\n\u001b[32m   3093\u001b[39m \u001b[33;03m            The type of the repository from which to get the tree (`\"model\"`, `\"dataset\"` or `\"space\"`.\u001b[39;00m\n\u001b[32m   3094\u001b[39m \u001b[33;03m            Defaults to `\"model\"`.\u001b[39;00m\n\u001b[32m   3095\u001b[39m \u001b[33;03m        token (`bool` or `str`, *optional*):\u001b[39;00m\n\u001b[32m   3096\u001b[39m \u001b[33;03m            A valid user access token (string). Defaults to the locally saved\u001b[39;00m\n\u001b[32m   3097\u001b[39m \u001b[33;03m            token, which is the recommended method for authentication (see\u001b[39;00m\n\u001b[32m   3098\u001b[39m \u001b[33;03m            https://huggingface.co/docs/huggingface_hub/quick-start#authentication).\u001b[39;00m\n\u001b[32m   3099\u001b[39m \u001b[33;03m            To disable authentication, pass `False`.\u001b[39;00m\n\u001b[32m   3100\u001b[39m \n\u001b[32m   3101\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m   3102\u001b[39m \u001b[33;03m        `Iterable[Union[RepoFile, RepoFolder]]`:\u001b[39;00m\n\u001b[32m   3103\u001b[39m \u001b[33;03m            The information about the tree's files and folders, as an iterable of [`RepoFile`] and [`RepoFolder`] objects. The order of the files and folders is\u001b[39;00m\n\u001b[32m   3104\u001b[39m \u001b[33;03m            not guaranteed.\u001b[39;00m\n\u001b[32m   3105\u001b[39m \n\u001b[32m   3106\u001b[39m \u001b[33;03m    Raises:\u001b[39;00m\n\u001b[32m   3107\u001b[39m \u001b[33;03m        [`~utils.RepositoryNotFoundError`]:\u001b[39;00m\n\u001b[32m   3108\u001b[39m \u001b[33;03m            If repository is not found (error 404): wrong repo_id/repo_type, private but not authenticated or repo\u001b[39;00m\n\u001b[32m   3109\u001b[39m \u001b[33;03m            does not exist.\u001b[39;00m\n\u001b[32m   3110\u001b[39m \u001b[33;03m        [`~utils.RevisionNotFoundError`]:\u001b[39;00m\n\u001b[32m   3111\u001b[39m \u001b[33;03m            If revision is not found (error 404) on the repo.\u001b[39;00m\n\u001b[32m   3112\u001b[39m \u001b[33;03m        [`~utils.EntryNotFoundError`]:\u001b[39;00m\n\u001b[32m   3113\u001b[39m \u001b[33;03m            If the tree (folder) does not exist (error 404) on the repo.\u001b[39;00m\n\u001b[32m   3114\u001b[39m \n\u001b[32m   3115\u001b[39m \u001b[33;03m    Examples:\u001b[39;00m\n\u001b[32m   3116\u001b[39m \n\u001b[32m   3117\u001b[39m \u001b[33;03m        Get information about a repo's tree.\u001b[39;00m\n\u001b[32m   3118\u001b[39m \u001b[33;03m        ```py\u001b[39;00m\n\u001b[32m   3119\u001b[39m \u001b[33;03m        >>> from huggingface_hub import list_repo_tree\u001b[39;00m\n\u001b[32m   3120\u001b[39m \u001b[33;03m        >>> repo_tree = list_repo_tree(\"lysandre/arxiv-nlp\")\u001b[39;00m\n\u001b[32m   3121\u001b[39m \u001b[33;03m        >>> repo_tree\u001b[39;00m\n\u001b[32m   3122\u001b[39m \u001b[33;03m        <generator object HfApi.list_repo_tree at 0x7fa4088e1ac0>\u001b[39;00m\n\u001b[32m   3123\u001b[39m \u001b[33;03m        >>> list(repo_tree)\u001b[39;00m\n\u001b[32m   3124\u001b[39m \u001b[33;03m        [\u001b[39;00m\n\u001b[32m   3125\u001b[39m \u001b[33;03m            RepoFile(path='.gitattributes', size=391, blob_id='ae8c63daedbd4206d7d40126955d4e6ab1c80f8f', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[32m   3126\u001b[39m \u001b[33;03m            RepoFile(path='README.md', size=391, blob_id='43bd404b159de6fba7c2f4d3264347668d43af25', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[32m   3127\u001b[39m \u001b[33;03m            RepoFile(path='config.json', size=554, blob_id='2f9618c3a19b9a61add74f70bfb121335aeef666', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[32m   3128\u001b[39m \u001b[33;03m            RepoFile(\u001b[39;00m\n\u001b[32m   3129\u001b[39m \u001b[33;03m                path='flax_model.msgpack', size=497764107, blob_id='8095a62ccb4d806da7666fcda07467e2d150218e',\u001b[39;00m\n\u001b[32m   3130\u001b[39m \u001b[33;03m                lfs={'size': 497764107, 'sha256': 'd88b0d6a6ff9c3f8151f9d3228f57092aaea997f09af009eefd7373a77b5abb9', 'pointer_size': 134}, last_commit=None, security=None\u001b[39;00m\n\u001b[32m   3131\u001b[39m \u001b[33;03m            ),\u001b[39;00m\n\u001b[32m   3132\u001b[39m \u001b[33;03m            RepoFile(path='merges.txt', size=456318, blob_id='226b0752cac7789c48f0cb3ec53eda48b7be36cc', lfs=None, last_commit=None, security=None),\u001b[39;00m\n\u001b[32m   3133\u001b[39m \u001b[33;03m            RepoFile(\u001b[39;00m\n\u001b[32m   3134\u001b[39m \u001b[33;03m                path='pytorch_model.bin', size=548123560, blob_id='64eaa9c526867e404b68f2c5d66fd78e27026523',\u001b[39;00m\n\u001b[32m   3135\u001b[39m \u001b[33;03m                lfs={'size': 548123560, 'sha256': '9be78edb5b928eba33aa88f431551348f7466ba9f5ef3daf1d552398722a5436', 'pointer_size': 134}, last_commit=None, security=None\u001b[39;00m\n\u001b[32m   3136\u001b[39m \u001b[33;03m            ),\u001b[39;00m\n\u001b[32m   3137\u001b[39m \u001b[33;03m            RepoFile(path='vocab.json', size=898669, blob_id='b00361fece0387ca34b4b8b8539ed830d644dbeb', lfs=None, last_commit=None, security=None)]\u001b[39;00m\n\u001b[32m   3138\u001b[39m \u001b[33;03m        ]\u001b[39;00m\n\u001b[32m   3139\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m   3140\u001b[39m \n\u001b[32m   3141\u001b[39m \u001b[33;03m        Get even more information about a repo's tree (last commit and files' security scan results)\u001b[39;00m\n\u001b[32m   3142\u001b[39m \u001b[33;03m        ```py\u001b[39;00m\n\u001b[32m   3143\u001b[39m \u001b[33;03m        >>> from huggingface_hub import list_repo_tree\u001b[39;00m\n\u001b[32m   3144\u001b[39m \u001b[33;03m        >>> repo_tree = list_repo_tree(\"prompthero/openjourney-v4\", expand=True)\u001b[39;00m\n\u001b[32m   3145\u001b[39m \u001b[33;03m        >>> list(repo_tree)\u001b[39;00m\n\u001b[32m   3146\u001b[39m \u001b[33;03m        [\u001b[39;00m\n\u001b[32m   3147\u001b[39m \u001b[33;03m            RepoFolder(\u001b[39;00m\n\u001b[32m   3148\u001b[39m \u001b[33;03m                path='feature_extractor',\u001b[39;00m\n\u001b[32m   3149\u001b[39m \u001b[33;03m                tree_id='aa536c4ea18073388b5b0bc791057a7296a00398',\u001b[39;00m\n\u001b[32m   3150\u001b[39m \u001b[33;03m                last_commit={\u001b[39;00m\n\u001b[32m   3151\u001b[39m \u001b[33;03m                    'oid': '47b62b20b20e06b9de610e840282b7e6c3d51190',\u001b[39;00m\n\u001b[32m   3152\u001b[39m \u001b[33;03m                    'title': 'Upload diffusers weights (#48)',\u001b[39;00m\n\u001b[32m   3153\u001b[39m \u001b[33;03m                    'date': datetime.datetime(2023, 3, 21, 9, 5, 27, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[32m   3154\u001b[39m \u001b[33;03m                }\u001b[39;00m\n\u001b[32m   3155\u001b[39m \u001b[33;03m            ),\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3156\u001b[39m \u001b[33;03m            RepoFolder(\u001b[39;00m\n\u001b[32m   3157\u001b[39m \u001b[33;03m                path='safety_checker',\u001b[39;00m\n\u001b[32m   3158\u001b[39m \u001b[33;03m                tree_id='65aef9d787e5557373fdf714d6c34d4fcdd70440',\u001b[39;00m\n\u001b[32m   3159\u001b[39m \u001b[33;03m                last_commit={\u001b[39;00m\n\u001b[32m   3160\u001b[39m \u001b[33;03m                    'oid': '47b62b20b20e06b9de610e840282b7e6c3d51190',\u001b[39;00m\n\u001b[32m   3161\u001b[39m \u001b[33;03m                    'title': 'Upload diffusers weights (#48)',\u001b[39;00m\n\u001b[32m   3162\u001b[39m \u001b[33;03m                    'date': datetime.datetime(2023, 3, 21, 9, 5, 27, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[32m   3163\u001b[39m \u001b[33;03m                }\u001b[39;00m\n\u001b[32m   3164\u001b[39m \u001b[33;03m            ),\u001b[39;00m\n\u001b[32m   3165\u001b[39m \u001b[33;03m            RepoFile(\u001b[39;00m\n\u001b[32m   3166\u001b[39m \u001b[33;03m                path='model_index.json',\u001b[39;00m\n\u001b[32m   3167\u001b[39m \u001b[33;03m                size=582,\u001b[39;00m\n\u001b[32m   3168\u001b[39m \u001b[33;03m                blob_id='d3d7c1e8c3e78eeb1640b8e2041ee256e24c9ee1',\u001b[39;00m\n\u001b[32m   3169\u001b[39m \u001b[33;03m                lfs=None,\u001b[39;00m\n\u001b[32m   3170\u001b[39m \u001b[33;03m                last_commit={\u001b[39;00m\n\u001b[32m   3171\u001b[39m \u001b[33;03m                    'oid': 'b195ed2d503f3eb29637050a886d77bd81d35f0e',\u001b[39;00m\n\u001b[32m   3172\u001b[39m \u001b[33;03m                    'title': 'Fix deprecation warning by changing `CLIPFeatureExtractor` to `CLIPImageProcessor`. (#54)',\u001b[39;00m\n\u001b[32m   3173\u001b[39m \u001b[33;03m                    'date': datetime.datetime(2023, 5, 15, 21, 41, 59, tzinfo=datetime.timezone.utc)\u001b[39;00m\n\u001b[32m   3174\u001b[39m \u001b[33;03m                },\u001b[39;00m\n\u001b[32m   3175\u001b[39m \u001b[33;03m                security={\u001b[39;00m\n\u001b[32m   3176\u001b[39m \u001b[33;03m                    'safe': True,\u001b[39;00m\n\u001b[32m   3177\u001b[39m \u001b[33;03m                    'av_scan': {'virusFound': False, 'virusNames': None},\u001b[39;00m\n\u001b[32m   3178\u001b[39m \u001b[33;03m                    'pickle_import_scan': None\u001b[39;00m\n\u001b[32m   3179\u001b[39m \u001b[33;03m                }\u001b[39;00m\n\u001b[32m   3180\u001b[39m \u001b[33;03m            )\u001b[39;00m\n\u001b[32m   3181\u001b[39m \u001b[33;03m            ...\u001b[39;00m\n\u001b[32m   3182\u001b[39m \u001b[33;03m        ]\u001b[39;00m\n\u001b[32m   3183\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m   3184\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   3185\u001b[39m     repo_type = repo_type \u001b[38;5;129;01mor\u001b[39;00m constants.REPO_TYPE_MODEL\n\u001b[32m   3186\u001b[39m     revision = quote(revision, safe=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m constants.DEFAULT_REVISION\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/huggingface_hub/utils/_pagination.py:37\u001b[39m, in \u001b[36mpaginate\u001b[39m\u001b[34m(path, params, headers)\u001b[39m\n\u001b[32m     35\u001b[39m session = get_session()\n\u001b[32m     36\u001b[39m r = session.get(path, params=params, headers=headers)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m r.json()\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Follow pages\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Next link already contains query params\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:671\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mRemoteEntryNotFoundError\u001b[39m: 404 Client Error. (Request ID: Root=1-6939c3ad-41a5479f633cd8c13bea7ca3;2614ec0e-0f21-41dd-ae9f-1d4b9b16b6fb)\n\nEntry Not Found for url: https://huggingface.co/api/models/openai-community/gpt2/tree/main/additional_chat_templates?recursive=false&expand=false.\nadditional_chat_templates does not exist on \"main\""
     ]
    }
   ],
   "source": [
    "ds = data.tokenize_and_group_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de4dba0d-b99a-42d0-9f34-5e14ffc19a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_LENGTH = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ad0d12-9a87-4b92-a9be-0f40d701e537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|| 2119719/2119719 [12:34<00:00, 2807.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 4. Grouping and Chunking\n",
    "def group_texts(examples):\n",
    "    # Concatenate all lists of token IDs in the batch\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    \n",
    "    # Drop the last chunk\n",
    "    total_length = (total_length // CONTEXT_LENGTH) * CONTEXT_LENGTH\n",
    "    \n",
    "    # Split the concatenated list into chunks of CONTEXT_LENGTH\n",
    "    result = {\n",
    "        k: [t[i : i + CONTEXT_LENGTH] for i in range(0, total_length, CONTEXT_LENGTH)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # For CLM, labels are the input IDs\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_dataset = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171e30e-8817-41ef-a574-37cd21a89a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dataset = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    num_proc=os.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bed3a74-7266-413e-9678-327e6fa5fb3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.'}\n",
      "{'text': 'Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\\n\\nOne day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the tree and watched the leaves fall on him. He laughed and beeped his horn.\\n\\nBeep played with the falling leaves all day. When it was time to go home, Beep knew he needed more fuel. He went to the fuel place and got more healthy fuel. Now, Beep was ready to go fast and play again the next day. And Beep lived happily ever after.'}\n",
      "{'text': 'One day, a little fish named Fin was swimming near the shore. He saw a big crab and wanted to be friends. \"Hi, I am Fin. Do you want to play?\" asked the little fish. The crab looked at Fin and said, \"No, I don\\'t want to play. I am cold and I don\\'t feel fine.\"\\n\\nFin felt sad but wanted to help the crab feel better. He swam away and thought of a plan. He remembered that the sun could make things warm. So, Fin swam to the top of the water and called to the sun, \"Please, sun, help my new friend feel fine and not freeze!\"\\n\\nThe sun heard Fin\\'s call and shone its warm light on the shore. The crab started to feel better and not so cold. He saw Fin and said, \"Thank you, little fish, for making me feel fine. I don\\'t feel like I will freeze now. Let\\'s play together!\" And so, Fin and the crab played and became good friends.'}\n",
      "{'text': 'Once upon a time, in a land full of trees, there was a little cherry tree. The cherry tree was very sad because it did not have any friends. All the other trees were big and strong, but the cherry tree was small and weak. The cherry tree was envious of the big trees.\\n\\nOne day, the cherry tree felt a tickle in its branches. It was a little spring wind. The wind told the cherry tree not to be sad. The wind said, \"You are special because you have sweet cherries that everyone loves.\" The cherry tree started to feel a little better.\\n\\nAs time went on, the cherry tree grew more and more cherries. All the animals in the land came to eat the cherries and play under the cherry tree. The cherry tree was happy because it had many friends now. The cherry tree learned that being different can be a good thing. And they all lived happily ever after.'}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for text in raw_dataset:\n",
    "    print(text)\n",
    "    batch_data = text\n",
    "    i += 1\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873ae25f-d84e-4c7d-8825-d1368e597e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    \"\"\"\n",
    "    Concatenates all texts and splits them into fixed-size chunks. \n",
    "    This is standard practice for CLM training (e.g., training a GPT-2 model).\n",
    "    \"\"\"\n",
    "    # Concatenate all lists of token IDs in the batch\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    \n",
    "    # Drop the last chunk if it's smaller than the context length\n",
    "    total_length = (total_length // CONTEXT_LENGTH) * CONTEXT_LENGTH\n",
    "    \n",
    "    # Split the concatenated list into chunks of CONTEXT_LENGTH\n",
    "    result = {\n",
    "        k: [t[i : i + CONTEXT_LENGTH] for i in range(0, total_length, CONTEXT_LENGTH)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    \n",
    "    # For Causal Language Modeling (CLM), the 'labels' are the 'input_ids'.\n",
    "    # The Hugging Face Trainer handles the required shifting for loss calculation.\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe05d39b-a259-452e-8db1-141e6e21897a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "800e9da9-1b68-460f-920e-8f07230cba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyStoriesTokenizedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class that loads the *pre-processed*, tokenized, \n",
    "    and chunked TinyStories dataset from disk.\n",
    "    \n",
    "    It returns a dictionary suitable for a Hugging Face Trainer or custom PyTorch loop.\n",
    "    \"\"\"\n",
    "    def __init__(self, split: str = \"train\", processed_data_dir: str = \"./processed_tinystories\"):\n",
    "        \"\"\"\n",
    "        Initializes the dataset by loading the specified split from a local directory.\n",
    "\n",
    "        Args:\n",
    "            split (str): The dataset split to load ('train', 'validation').\n",
    "            processed_data_dir (str): The directory where the pre-processed data is saved.\n",
    "        \"\"\"\n",
    "        file_path = os.path.join(processed_data_dir, split)\n",
    "        print(f\"Loading *tokenized* TinyStories dataset split from: '{file_path}'...\")\n",
    "        \n",
    "        # Load the pre-processed dataset from disk\n",
    "        try:\n",
    "            # We load the processed Arrow Table (Dataset)\n",
    "            trainer.dataset = lm_dataset\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                f\"Could not load processed dataset split '{split}'. \"\n",
    "                f\"Did you run the pre-processing script first? Error: {e}\"\n",
    "            )\n",
    "\n",
    "        trainer.split = split\n",
    "        print(f\"Tokenized dataset loaded. Total chunks: {len(trainer.dataset)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of fixed-length chunks (examples) in the dataset.\n",
    "        \"\"\"\n",
    "        return len(trainer.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        \"\"\"\n",
    "        Retrieves the token IDs and labels for the chunk at the given index.\n",
    "\n",
    "        Args:\n",
    "            idx (int): The index of the chunk to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing 'input_ids' and 'labels' tensors.\n",
    "        \"\"\"\n",
    "        # Retrieve the example from the Hugging Face Dataset\n",
    "        example = trainer.dataset[idx]\n",
    "        \n",
    "        # Convert the lists of integers (token IDs) into PyTorch Tensors\n",
    "        # These are the necessary keys for Causal Language Modeling training\n",
    "        return {\n",
    "            'input_ids': torch.tensor(example['input_ids'], dtype=torch.long),\n",
    "            'labels': torch.tensor(example['labels'], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02b55f16-908f-48c9-bda9-2813c0cd2ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading *tokenized* TinyStories dataset split from: './processed_tinystories/train'...\n",
      "Tokenized dataset loaded. Total chunks: 459751\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TinyStoriesTokenizedDataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0813d9e6-ae19-491a-9ad4-201b47c0f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14c8e964-240f-4f7c-8113-79338760848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = DistributedSampler(\n",
    "            train_dataset,\n",
    "            num_replicas=1,\n",
    "            rank=0,\n",
    "            shuffle=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b91caf75-4229-4167-bb4c-d78a000ba617",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/projects/llm-models/llm/lib/python3.12/site-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=8,\n",
    "            sampler=train_sampler,\n",
    "            shuffle=(train_sampler is None),\n",
    "            num_workers=8,\n",
    "            pin_memory=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "116955b2-efeb-4f0d-9fad-37bf52f6eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[20037,  1816,   284,  ...,   640,    11,   612],\n",
      "        [ 2613,    13,  1119,  ...,   606,   290,   531],\n",
      "        [  290,   766,   508,  ...,   739,   257, 24484],\n",
      "        ...,\n",
      "        [  257,  3704,    13,  ...,   389,   407,  3148],\n",
      "        [  290,  3835,   290,  ..., 35113,   526,   198],\n",
      "        [10718,  1306,   284,  ...,    11, 11735,    13]]), 'labels': tensor([[20037,  1816,   284,  ...,   640,    11,   612],\n",
      "        [ 2613,    13,  1119,  ...,   606,   290,   531],\n",
      "        [  290,   766,   508,  ...,   739,   257, 24484],\n",
      "        ...,\n",
      "        [  257,  3704,    13,  ...,   389,   407,  3148],\n",
      "        [  290,  3835,   290,  ..., 35113,   526,   198],\n",
      "        [10718,  1306,   284,  ...,    11, 11735,    13]])}\n"
     ]
    }
   ],
   "source": [
    "for t in train_loader:\n",
    "    print(t)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fdafa1-468d-4e85-887c-9ec86d204efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
