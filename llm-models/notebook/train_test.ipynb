{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a5e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/pytorch/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd25c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "current = os.getcwd()\n",
    "parent = os.path.dirname(current)\n",
    "sys.path.append(parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58dc61ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeepseek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeepseek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdeepseek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/data.py:3\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IterableDataset\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from models.deepseek import model\n",
    "\n",
    "from models.deepseek import train\n",
    "\n",
    "from models.deepseek import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b78f56e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models.deepseek.train' from '/home/ubuntu/projects/llm-models/llm-models/models/deepseek/train.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf85d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = model.ModelArgs(expert_type=model.ExpertType(2),\n",
    "                             dim=512, inter_dim=1365, moe_inter_dim=256,\n",
    "                             kv_lora_rank=128, qk_nope_head_dim=32, qk_rope_head_dim=16, \n",
    "                             v_head_dim=32, \n",
    "                             n_routed_experts=4, n_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f454f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = train.TrainingArgs(\n",
    "    model_args=model_args,\n",
    "    batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    max_steps=100000,\n",
    "    learning_rate=3e-4,\n",
    "    checkpoint_dir=\"./checkpoints\",\n",
    "    data_dir=\"./data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82d7e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a11eb58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '12355'\n",
    "dist.init_process_group(backend='nccl', rank=0, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9268ca1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "trying to initialize the default process group twice!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m trainer = \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:114\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArgs):\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m.args = args\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msetup_distributed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28mself\u001b[39m.setup_model()\n\u001b[32m    116\u001b[39m     \u001b[38;5;28mself\u001b[39m.setup_optimizer()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/llm-models/llm-models/models/deepseek/train.py:134\u001b[39m, in \u001b[36mTrainer.setup_distributed\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    132\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mMASTER_ADDR\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33mlocalhost\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    133\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mMASTER_PORT\u001b[39m\u001b[33m'\u001b[39m] = \u001b[33m'\u001b[39m\u001b[33m12355\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[43mdist\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnccl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28mself\u001b[39m.world_size = dist.get_world_size()\n\u001b[32m    136\u001b[39m \u001b[38;5;28mself\u001b[39m.rank = dist.get_rank()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pytorch/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:81\u001b[39m, in \u001b[36m_exception_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     83\u001b[39m         msg_dict = _get_msg_dict(func.\u001b[34m__name__\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pytorch/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:95\u001b[39m, in \u001b[36m_time_logger.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _T:\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m _WaitCounter(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpytorch.wait_counter.c10d.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m).guard():\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         func_return = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func_return\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/pytorch/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1646\u001b[39m, in \u001b[36minit_process_group\u001b[39m\u001b[34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options, device_id)\u001b[39m\n\u001b[32m   1643\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _default_pg_init_method\n\u001b[32m   1645\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m GroupMember.WORLD \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1646\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mtrying to initialize the default process group twice!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1648\u001b[39m set_pytorch_distributed_envs_from_justknobs()\n\u001b[32m   1650\u001b[39m \u001b[38;5;66;03m# Depending on the import order, some trace_rules functions may be evaluated\u001b[39;00m\n\u001b[32m   1651\u001b[39m \u001b[38;5;66;03m# during the import phase. In such a case, these functions may not correctly\u001b[39;00m\n\u001b[32m   1652\u001b[39m \u001b[38;5;66;03m# add the distributed related rules due to import circular dependency.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1656\u001b[39m \u001b[38;5;66;03m# Since this API must be called before all distributed code being compiled,\u001b[39;00m\n\u001b[32m   1657\u001b[39m \u001b[38;5;66;03m# clearing the cache here should be safe.\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: trying to initialize the default process group twice!"
     ]
    }
   ],
   "source": [
    "trainer = train.Trainer(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd79a96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
